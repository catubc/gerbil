{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import scipy.misc\n",
    "#import skimage.filter\n",
    "\n",
    "import parmap\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128, 160, 10)\n"
     ]
    }
   ],
   "source": [
    "#fname_predictions = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/predictions.npy'\n",
    "fname_predictions = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/predictions_10k_new.npy'\n",
    "\n",
    "predictions = np.load(fname_predictions)[:,:,:,:10]\n",
    "print (predictions.shape)\n",
    "\n",
    "# ids = [2, 50, 111]\n",
    "# plt.imshow(predictions[0].sum(2))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load surfaces\n",
    "# id_ = 100\n",
    "\n",
    "# fname_surfaces = fname_predictions[:-4]+'_surfaces.npy'\n",
    "# surfaces = np.load(fname_surfaces)\n",
    "# print (surfaces.shape)\n",
    "# plt.imshow(surfaces[id_])\n",
    "\n",
    "# # load assembled animals\n",
    "# traces_cc = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npz')\n",
    "\n",
    "# tracesx = traces_cc['tracesx']\n",
    "# print (tracesx.shape)\n",
    "# tracesy = traces_cc['tracesy']\n",
    "# plt.scatter(tracesx[:,id_]/8, tracesy[:,id_]/8, c='red')\n",
    "\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final surfaces:  (10000, 128, 160)\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#################### CONVERT PREDICTIONS TO SURFCACES ##############\n",
    "####################################################################\n",
    "\n",
    "fname_surfaces = fname_predictions[:-4]+'_surfaces.npy'\n",
    "\n",
    "if os.path.exists(fname_surfaces)==False:\n",
    "\n",
    "    n_frames = predictions.shape[0]\n",
    "    surfaces = np.zeros((n_frames,predictions.shape[1],predictions.shape[2]),'float32')\n",
    "    #predictions = np.zeros((n_frames,128,160,14),'float32')\n",
    "\n",
    "    threshold = 0.5\n",
    "    features = np.arange(10)\n",
    "    for n in range(n_frames):\n",
    "        if n%100==0:\n",
    "            print (n)\n",
    "        sums = np.zeros((predictions.shape[1],predictions.shape[2]),'float32')\n",
    "        #for k in range(14):\n",
    "        for k in features:\n",
    "            temp= predictions[n,:,:,k]\n",
    "            temp = (temp -np.min(temp))/ (np.max(temp)-np.min(temp))\n",
    "            temp = 1 / (np.exp(-temp) + 1)  # confidence map transformation as per Anqi's sugestion\n",
    "\n",
    "            idx = np.where(temp<threshold)\n",
    "            temp[idx]=0\n",
    "            sums+=temp\n",
    "        surfaces[n]= sums\n",
    "\n",
    "    np.save(fname_surfaces, surfaces)\n",
    "\n",
    "else:\n",
    "    surfaces = np.load(fname_surfaces)\n",
    "\n",
    "print (\" Final surfaces: \", surfaces.shape)\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE; water shed:  (10000, 128, 160)\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#################### EXTRACT PATCHES VIA WATERSHED ##############\n",
    "####################################################################\n",
    "\n",
    "def extract_patches_watershed_parallel(image, min_pixels):\n",
    "#img_array1 = []\n",
    "#for ctr in range(surfaces.shape[0]):\n",
    "\n",
    "    #if ctr%100==0:\n",
    "    #    print (\"frame; \", ctr)\n",
    "    #temp = predictions[ctr].sum(2)\n",
    "    #temp = (temp-np.min(temp))/(np.max(temp)-np.min(temp))\n",
    "    #image = temp.copy()*10\n",
    "    #image=surfaces[ctr]\n",
    "\n",
    "    #binarize = image>0.5\n",
    "    #bin_neg = image<1\n",
    "    #image = binarize\n",
    "    \n",
    "    #image = binarize.copy()\n",
    "    if False:\n",
    "        thresh = np.max(image)//2\n",
    "        idx = np.where(image<thresh)\n",
    "        image[idx]=0\n",
    "        \n",
    "    if True:\n",
    "        distance = ndi.distance_transform_edt(image)\n",
    "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)),\n",
    "                                    labels=image)\n",
    "        markers = ndi.label(local_maxi)[0]\n",
    "        labels = watershed(-distance, markers, mask=image)\n",
    "\n",
    "    else:\n",
    "        # Now we want to separate the two objects in image\n",
    "        # Generate the markers as local maxima of the distance to the background\n",
    "        distance = ndi.distance_transform_edt(image)\n",
    "        local_maxi = peak_local_max(distance, indices=False, \n",
    "                                    footprint=np.ones((3, 3)),\n",
    "                                    labels=image)\n",
    "        markers = ndi.label(local_maxi)[0]\n",
    "        labels = watershed(-distance, markers, mask=image)\n",
    "        #labels = watershed(-surfaces[ctr], markers, mask=image)\n",
    "\n",
    "    \n",
    "    # REMOVE PATCHES BELOW MIN # PIXEL THRESHOLD\n",
    "    #print (np.unique(labels))\n",
    "    for k in np.unique(labels):\n",
    "        idx = np.where(labels==k)\n",
    "        if idx[0].shape[0]<min_pixels:\n",
    "            labels[idx]=0        \n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "fname_watershed = fname_predictions[:-4]+\"_watershed.npy\"\n",
    "\n",
    "if os.path.exists(fname_watershed)==False:\n",
    "    \n",
    "    surfaces = np.load(fname_surfaces)\n",
    "    min_pixels = 50\n",
    "    images = surfaces[:250]\n",
    "    #plt.imshow(images[0])\n",
    "    result = parmap.map(extract_patches_watershed_parallel, \n",
    "                        images, \n",
    "                        min_pixels,\n",
    "                        pm_pbar=True,\n",
    "                        pm_processes=8)\n",
    "\n",
    "    result = np.array(result)\n",
    "    print (\"Watershed patches: \", result.shape)\n",
    "    np.save(fname_watershed, result)\n",
    "\n",
    "else:\n",
    "    result = np.load(fname_watershed)\n",
    "    \n",
    "print (\"DONE; water shed: \", result.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128, 160, 10)\n",
      "/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/predictions_10k_new_watershed.npy\n",
      "watershed :  (10000, 128, 160)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "#test watershed again\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "print (predictions.shape)\n",
    "#image = predictions[0].sum(2)\n",
    "\n",
    "root_dir = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/training_images/'\n",
    "\n",
    "fname_video = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "original_vid = cv2.VideoCapture(fname_video)\n",
    "    \n",
    "#predictions = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/predictions_test.npy')\n",
    "#predictions = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/predictions.npy')\n",
    "start = 0\n",
    "number = 10000\n",
    "n_animals = 6\n",
    "features = np.arange(10)\n",
    "threshold = 0.5\n",
    "\n",
    "plotting = False\n",
    "\n",
    "original_vid.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "ids=np.arange(start,start+number,1)\n",
    "\n",
    "fname_watershed = fname_predictions[:-4]+\"_watershed.npy\"\n",
    "print (fname_watershed)\n",
    "\n",
    "if os.path.exists(fname_watershed)==False:\n",
    "    label_array = []\n",
    "    for ctr, id_ in tqdm(enumerate(ids)):\n",
    "\n",
    "        # Anqi's sigmoid transformation\n",
    "        pred_s = predictions[id_]\n",
    "        pred_s = 1 / (np.exp(-pred_s) + 1)  # confidence map\n",
    "\n",
    "        surface = np.zeros((predictions.shape[1],predictions.shape[2]),'float32')\n",
    "        #for k in range(14):\n",
    "        for k in features:\n",
    "            temp= pred_s[:,:,k]\n",
    "\n",
    "            # normalize data before adding together\n",
    "            temp = (temp -np.min(temp))/ (np.max(temp)-np.min(temp))\n",
    "\n",
    "            # additional step suggested by Anqi; possible to add it to final image also\n",
    "            #temp = 1 / (np.exp(-temp) + 1)  # confidence map transformation as per Anqi's sugestion\n",
    "\n",
    "            idx = np.where(temp<threshold)\n",
    "            temp[idx]=0\n",
    "            surface+=temp\n",
    "\n",
    "        image = surface.copy()\n",
    "\n",
    "        #print (\"image; \", image.shape)\n",
    "\n",
    "\n",
    "        thresh_flex = 0.2 * np.max(image)\n",
    "        image = gaussian_filter(image, sigma=1.5)\n",
    "        ctr2 = 0\n",
    "        while True:\n",
    "            binarize = image.copy()>thresh_flex\n",
    "\n",
    "            #binarize = image>(np.max(image)/1.2)\n",
    "            #bin_neg = image>np\n",
    "\n",
    "            distance = ndi.distance_transform_edt(binarize)\n",
    "           # print (\"distance: \", distance.shape)\n",
    "            local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((1, 1)),\n",
    "                                        labels=binarize)\n",
    "            markers = ndi.label(local_maxi)[0]\n",
    "            labels = watershed(-distance, \n",
    "                               markers, \n",
    "                               mask=binarize)\n",
    "\n",
    "            #print (\" ctr: \", ctr,  \"  # animalsL \", np.unique(labels).shape[0], ctr2)\n",
    "            if np.unique(labels).shape[0]<n_animals and ctr2<15:\n",
    "                thresh_flex = thresh_flex*.9\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            ctr2+=1\n",
    "\n",
    "        # REMOVE PATCHES BELOW MIN # PIXEL THRESHOLD\n",
    "        #print (np.unique(labels))\n",
    "        min_pixels = 5\n",
    "\n",
    "        while True:\n",
    "            for k in np.unique(labels):\n",
    "                idx = np.where(labels==k)\n",
    "                if idx[0].shape[0]<min_pixels:\n",
    "                    labels[idx]=0\n",
    "\n",
    "            if np.unique(labels).shape[0]<(n_animals+2):\n",
    "                break\n",
    "            min_pixels = min_pixels*1.5\n",
    "\n",
    "        #ax=plt.subplot(2,2,1)\n",
    "        #plt.imshow(distance)\n",
    "\n",
    "\n",
    "        if plotting:\n",
    "            if  number==10:\n",
    "                ax=plt.subplot(2,5,ctr+1)\n",
    "            else:\n",
    "                ax=plt.subplot(10,10,ctr+1)\n",
    "\n",
    "            labels = labels*(255/np.max(labels))\n",
    "            ret, frame = original_vid.read()\n",
    "            img_out = np.vstack((labels, frame[::8,::8].mean(2)))\n",
    "            plt.imshow(img_out)\n",
    "            plt.ylabel(str(id_))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "        label_array.append(labels)\n",
    "    if plotting:    \n",
    "        plt.show()\n",
    "    label_array = np.array(label_array)\n",
    "    np.save(fname_watershed, label_array)\n",
    "else:\n",
    "    label_array=np.load(fname_watershed)\n",
    "    \n",
    "print (\"watershed : \", label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames;  [   0    1    2 ... 9997 9998 9999]\n",
      "matches;  10000\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "########## TIME_BASED CONNECTED COMPONNET 1: FIND OVERLAPS OVER TIME #######\n",
    "############################################################################\n",
    "\n",
    "def intersect2D(a, b):\n",
    "  \"\"\"\n",
    "  Find row intersection between 2D numpy arrays, a and b.\n",
    "  Returns another numpy array with shared rows\n",
    "  \"\"\"\n",
    "  return np.array([x for x in set(tuple(x) for x in a) & set(tuple(x) for x in b)])\n",
    "\n",
    "# \n",
    "surfaces_watershed = np.load(fname_predictions[:-4]+\"_watershed.npy\")\n",
    "\n",
    "# identify periods of time where the identity does not switch\n",
    "locs = [[0, 215], \n",
    "        [2180, 2468], \n",
    "        [4400, 4500],\n",
    "        [5376, 5583],\n",
    "        [0, 3000],\n",
    "        [0,10000]\n",
    "       ]\n",
    "\n",
    "# SELECT A SEGMENT OF TIME\n",
    "frames = np.arange(locs[5][0], \n",
    "                   locs[5][1],1)\n",
    "print (\"Frames; \", frames)\n",
    "\n",
    "# \n",
    "fname_matches = fname_predictions[:-4]+\"_matches_\"+str(frames[0])+\"_\"+str(frames[-1])+\".npy\"\n",
    "\n",
    "if os.path.exists(fname_matches)==False:\n",
    "#if True:\n",
    "    min_overlap_percentage = 0.5\n",
    "    min_overlap_pixels = 50\n",
    "    matches = []\n",
    "    \n",
    "    # add ids of the first frame as-is\n",
    "    matches.append(np.unique(surfaces_watershed[frames[0]]))  #Pad \n",
    "\n",
    "    max_patch = 500 # max size of a patch to exclude background matching\n",
    "    \n",
    "    # loop over all frames\n",
    "    for ctr_k, k in enumerate(frames[1:]):  #skip first match\n",
    "        matches.append([])\n",
    "        if k%10==0:\n",
    "            print (\"Frame: \", k)\n",
    "            \n",
    "        # find patch \n",
    "        im = surfaces_watershed[k]\n",
    "\n",
    "        # \n",
    "        ids = np.unique(im)\n",
    "        for ctr, id_ in enumerate(ids):\n",
    "            matches[ctr_k+1].append([])\n",
    "            #if id_==0:\n",
    "            #    continue\n",
    "            idx1 = np.array(np.where(im==id_)).T\n",
    "\n",
    "            match_id = None\n",
    "\n",
    "            # exclude large patches from analysis:\n",
    "            if idx1.shape[0]<max_patch:\n",
    "                # loop over previous frame blobs\n",
    "                max_match = 0\n",
    "                for p in np.unique(surfaces_watershed[k-1]):\n",
    "                    idx2 = np.array(np.where(surfaces_watershed[k-1]==p)).T\n",
    "                    if idx2.shape[0]>max_patch:\n",
    "                        continue\n",
    "                    \n",
    "                    # don't allow for matches to the background for IDs that were pev missed;\n",
    "                    i = intersect2D(idx1,idx2)\n",
    "\n",
    "                    #if i.shape[0]>max_match and i.shape[0]>(min_overlap*i.shape[0]):\n",
    "                    if i.shape[0]>max_match and i.shape[0]>min_overlap_pixels:\n",
    "                        match_id = p\n",
    "                        max_match = i.shape[0]\n",
    "\n",
    "            matches[ctr_k+1][ctr].append(match_id)\n",
    "        \n",
    "            #print(\"k :\", k, ' ctr: ', ctr, \" match_id: \", match_id)\n",
    "    np.save(fname_matches, matches)\n",
    "else:\n",
    "    matches = np.load(fname_matches, allow_pickle=True)\n",
    "    \n",
    "print (\"matches; \", len(matches))\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain IDS:  [0 3 4 5]\n",
      "PLOTING:  True\n",
      "frame:  1 new val:  6\n",
      "TRACKER:  0 [[], 6, 3, 4, 5]\n",
      "TRACKER:  1 [[], 6, 3, 4, 5]\n",
      "frame:  3 new val:  7\n",
      "frame:  3 new val:  8\n",
      "TRACKER:  2 [[], 7, 8, 3, 4, 5]\n",
      "frame:  4 new val:  9\n",
      "TRACKER:  3 [[], 9, 3, 4, 5]\n",
      "TRACKER:  4 [[], 9, 3, 4, 5]\n",
      "TRACKER:  5 [[], 9, 3, 4, 5]\n",
      "TRACKER:  6 [[], 9, 3, 4, 5]\n",
      "frame:  8 new val:  10\n",
      "TRACKER:  7 [[], 10, 3, 4, 5]\n",
      "frame:  9 new val:  11\n",
      "TRACKER:  8 [[], 11, 3, 4, 5]\n",
      "frame:  10 new val:  12\n",
      "TRACKER:  9 [[], 12, 3, 4, 5]\n",
      "frame:  11 new val:  13\n",
      "TRACKER:  10 [[], 13, 3, 4, 5]\n",
      "TRACKER:  11 [[], 13, 3, 4, 5]\n",
      "frame:  13 new val:  14\n",
      "TRACKER:  12 [[], 14, 3, 4, 5]\n",
      "frame:  14 new val:  15\n",
      "TRACKER:  13 [[], 15, 3, 4, 5]\n",
      "frame:  15 new val:  16\n",
      "frame:  15 new val:  17\n",
      "TRACKER:  14 [[], 16, 3, 17, 4, 5]\n",
      "frame:  16 new val:  18\n",
      "TRACKER:  15 [[], 18, 3, 4, 5]\n",
      "frame:  17 new val:  19\n",
      "TRACKER:  16 [[], 19, 3, 4, 5]\n",
      "TRACKER:  17 [[], 19, 3, 4, 5]\n",
      "TRACKER:  18 [[], 19, 3, 4, 5]\n",
      "frame:  20 new val:  20\n",
      "TRACKER:  19 [[], 20, 3, 4, 5]\n",
      "frame:  21 new val:  21\n",
      "TRACKER:  20 [[], 21, 3, 4, 5]\n",
      "frame:  22 new val:  22\n",
      "TRACKER:  21 [[], 22, 3, 4, 5]\n",
      "TRACKER:  22 [[], 22, 3, 4, 5]\n",
      "TRACKER:  23 [[], 22, 3, 4, 5]\n",
      "TRACKER:  24 [[], 22, 3, 4, 5]\n",
      "frame:  26 new val:  23\n",
      "TRACKER:  25 [[], 23, 3, 4, 5]\n",
      "frame:  27 new val:  24\n",
      "TRACKER:  26 [[], 24, 3, 4, 5]\n",
      "TRACKER:  27 [[], 24, 3, 4, 5]\n",
      "TRACKER:  28 [[], 24, 3, 4, 5]\n",
      "TRACKER:  29 [[], 24, 3, 4, 5]\n",
      "TRACKER:  30 [[], 24, 3, 4, 5]\n",
      "TRACKER:  31 [[], 24, 3, 4, 5]\n",
      "TRACKER:  32 [[], 24, 3, 4, 5]\n",
      "TRACKER:  33 [[], 24, 3, 4, 5]\n",
      "frame:  35 new val:  25\n",
      "TRACKER:  34 [[], 25, 3, 4, 5]\n",
      "frame:  36 new val:  26\n",
      "TRACKER:  35 [[], 26, 3, 4, 5]\n",
      "TRACKER:  36 [[], 26, 3, 4, 5]\n",
      "frame:  38 new val:  27\n",
      "TRACKER:  37 [[], 26, 27, 4, 5]\n",
      "TRACKER:  38 [[], 26, 27, 4, 5]\n",
      "TRACKER:  39 [[], 26, 27, 4, 5]\n",
      "TRACKER:  40 [[], 26, 27, 4, 5]\n",
      "TRACKER:  41 [[], 26, 27, 4, 5]\n",
      "TRACKER:  42 [[], 26, 27, 4, 5]\n",
      "frame:  44 new val:  28\n",
      "TRACKER:  43 [[], 28, 27, 4, 5]\n",
      "frame:  45 new val:  29\n",
      "TRACKER:  44 [[], 29, 27, 4, 5]\n",
      "TRACKER:  45 [[], 29, 27, 4, 5]\n",
      "TRACKER:  46 [[], 29, 27, 4, 5]\n",
      "TRACKER:  47 [[], 29, 27, 4, 5]\n",
      "TRACKER:  48 [[], 29, 27, 4, 5]\n",
      "frame:  50 new val:  30\n",
      "TRACKER:  49 [[], 29, 27, 30, 4, 5]\n",
      "frame:  51 new val:  31\n",
      "frame:  51 new val:  32\n",
      "TRACKER:  50 [[], 29, 31, 32, 4, 5]\n",
      "TRACKER:  51 [[], 29, 32, 4, 5]\n",
      "TRACKER:  52 [[], 29, 32, 4, 5]\n",
      "frame:  54 new val:  33\n",
      "frame:  54 new val:  34\n",
      "frame:  54 new val:  35\n",
      "TRACKER:  53 [[], 33, 4, 34, 35, 5]\n",
      "frame:  55 new val:  36\n",
      "frame:  55 new val:  37\n",
      "TRACKER:  54 [[], 36, 4, 37, 5]\n",
      "TRACKER:  55 [[], 36, 4, 37, 5]\n",
      "TRACKER:  56 [[], 36, 4, 37, 5]\n",
      "TRACKER:  57 [[], 36, 4, 37, 5]\n",
      "TRACKER:  58 [[], 36, 4, 37, 5]\n",
      "TRACKER:  59 [[], 36, 4, 37, 5]\n",
      "TRACKER:  60 [[], 36, 4, 37, 5]\n",
      "TRACKER:  61 [[], 36, 4, 37, 5]\n",
      "TRACKER:  62 [[], 36, 4, 37, 5]\n",
      "frame:  64 new val:  38\n",
      "TRACKER:  63 [[], 38, 4, 37, 5]\n",
      "frame:  65 new val:  39\n",
      "TRACKER:  64 [[], 39, 4, 37, 5]\n",
      "frame:  66 new val:  40\n",
      "frame:  66 new val:  41\n",
      "TRACKER:  65 [[], 40, 41, 4, 37, 5]\n",
      "frame:  67 new val:  42\n",
      "TRACKER:  66 [[], 42, 4, 37, 5]\n",
      "frame:  68 new val:  43\n",
      "frame:  68 new val:  44\n",
      "TRACKER:  67 [[], 43, 44, 4, 37, 5]\n",
      "frame:  69 new val:  45\n",
      "TRACKER:  68 [[], 45, 4, 37, 5]\n",
      "TRACKER:  69 [[], 45, 4, 37, 5]\n",
      "TRACKER:  70 [[], 45, 4, 37, 5]\n",
      "TRACKER:  71 [[], 45, 4, 37, 5]\n",
      "TRACKER:  72 [[], 45, 4, 37, 5]\n",
      "TRACKER:  73 [[], 45, 4, 37, 5]\n",
      "TRACKER:  74 [[], 45, 4, 37, 5]\n",
      "TRACKER:  75 [[], 45, 4, 37, 5]\n",
      "TRACKER:  76 [[], 45, 4, 37, 5]\n",
      "TRACKER:  77 [[], 45, 4, 37, 5]\n",
      "TRACKER:  78 [[], 45, 4, 5, 37]\n",
      "TRACKER:  79 [[], 45, 4, 5, 37]\n",
      "TRACKER:  80 [[], 45, 4, 5, 37]\n",
      "TRACKER:  81 [[], 45, 4, 5, 37]\n",
      "TRACKER:  82 [[], 45, 4, 5, 37]\n",
      "TRACKER:  83 [[], 45, 4, 5, 37]\n",
      "TRACKER:  84 [[], 45, 4, 5, 37]\n",
      "TRACKER:  85 [[], 45, 4, 5, 37]\n",
      "frame:  87 new val:  46\n",
      "TRACKER:  86 [[], 46, 4, 5, 37]\n",
      "frame:  88 new val:  47\n",
      "TRACKER:  87 [[], 47, 4, 5, 37]\n",
      "TRACKER:  88 [[], 47, 4, 5, 37]\n",
      "TRACKER:  89 [[], 47, 4, 5, 37]\n",
      "TRACKER:  90 [[], 47, 4, 5, 37]\n",
      "TRACKER:  91 [[], 47, 4, 5, 37]\n",
      "TRACKER:  92 [[], 47, 4, 5, 37]\n",
      "TRACKER:  93 [[], 47, 4, 5, 37]\n",
      "TRACKER:  94 [[], 47, 4, 5, 37]\n",
      "TRACKER:  95 [[], 47, 4, 5, 37]\n",
      "frame:  97 new val:  48\n",
      "TRACKER:  96 [[], 47, 48, 4, 5, 37]\n",
      "TRACKER:  97 [[], 47, 4, 5, 37]\n",
      "TRACKER:  98 [[], 47, 4, 5, 37]\n",
      "TRACKER:  99 [[], 47, 4, 5, 37]\n",
      "TRACKER:  100 [[], 47, 4, 5, 37]\n",
      "TRACKER:  101 [[], 47, 4, 5, 37]\n",
      "TRACKER:  102 [[], 47, 4, 5, 37]\n",
      "TRACKER:  103 [[], 47, 4, 5, 37]\n",
      "TRACKER:  104 [[], 4, 47, 5, 37]\n",
      "TRACKER:  105 [[], 4, 47, 5, 37]\n",
      "TRACKER:  106 [[], 4, 47, 5, 37]\n",
      "TRACKER:  107 [[], 4, 47, 5, 37]\n",
      "TRACKER:  108 [[], 47, 4, 5, 37]\n",
      "TRACKER:  109 [[], 4, 47, 5, 37]\n",
      "TRACKER:  110 [[], 4, 47, 5, 37]\n",
      "TRACKER:  111 [[], 47, 4, 5, 37]\n",
      "frame:  113 new val:  49\n",
      "TRACKER:  112 [[], 47, 4, 5, 49]\n",
      "frame:  114 new val:  50\n",
      "TRACKER:  113 [[], 47, 4, 5, 50]\n",
      "TRACKER:  114 [[], 47, 4, 5, 50]\n",
      "TRACKER:  115 [[], 47, 4, 5, 50]\n",
      "frame:  117 new val:  51\n",
      "TRACKER:  116 [[], 51, 4, 5, 50]\n",
      "frame:  118 new val:  52\n",
      "TRACKER:  117 [[], 52, 4, 5, 50]\n",
      "frame:  119 new val:  53\n",
      "frame:  119 new val:  54\n",
      "TRACKER:  118 [[], 53, 54, 4, 5, 50]\n",
      "frame:  120 new val:  55\n",
      "TRACKER:  119 [[], 55, 4, 5, 50]\n",
      "TRACKER:  120 [[], 55, 4, 5, 50]\n",
      "frame:  122 new val:  56\n",
      "frame:  122 new val:  57\n",
      "TRACKER:  121 [[], 55, 4, 5, 56, 57]\n",
      "frame:  123 new val:  58\n",
      "TRACKER:  122 [[], 55, 4, 5, 58]\n",
      "frame:  124 new val:  59\n",
      "TRACKER:  123 [[], 55, 4, 5, 59]\n",
      "frame:  125 new val:  60\n",
      "TRACKER:  124 [[], 55, 4, 5, 60]\n",
      "frame:  126 new val:  61\n",
      "TRACKER:  125 [[], 55, 4, 5, 61]\n",
      "TRACKER:  126 [[], 55, 4, 5]\n",
      "TRACKER:  127 [[], 55, 4, 5]\n",
      "TRACKER:  128 [[], 55, 4, 5]\n",
      "TRACKER:  129 [[], 55, 4, 5]\n",
      "TRACKER:  130 [[], 55, 4, 5]\n",
      "TRACKER:  131 [[], 55, 4, 5, 5]\n",
      "TRACKER:  132 [[], 55, 4, 5, 5]\n",
      "TRACKER:  133 [[], 55, 4, 5, 5]\n",
      "TRACKER:  134 [[], 55, 4, 5]\n",
      "TRACKER:  135 [[], 55, 4, 5]\n",
      "TRACKER:  136 [[], 55, 4, 5]\n",
      "TRACKER:  137 [[], 55, 4, 5, 5]\n",
      "TRACKER:  138 [[], 55, 4, 5, 5]\n",
      "TRACKER:  139 [[], 55, 4, 5, 5]\n",
      "frame:  141 new val:  62\n",
      "TRACKER:  140 [[], 62, 4, 5, 5]\n",
      "frame:  142 new val:  63\n",
      "TRACKER:  141 [[], 63, 4, 5, 5]\n",
      "frame:  143 new val:  64\n",
      "TRACKER:  142 [[], 64, 4, 5, 5]\n",
      "frame:  144 new val:  65\n",
      "TRACKER:  143 [[], 65, 4, 5, 5]\n",
      "frame:  145 new val:  66\n",
      "TRACKER:  144 [[], 66, 4, 5, 5]\n",
      "TRACKER:  145 [[], 66, 4, 5, 5]\n",
      "TRACKER:  146 [[], 66, 4, 5, 5]\n",
      "frame:  148 new val:  67\n",
      "TRACKER:  147 [[], 67, 4, 5, 5]\n",
      "frame:  149 new val:  68\n",
      "TRACKER:  148 [[], 68, 4, 5, 5]\n",
      "TRACKER:  149 [[], 68, 4, 5, 5]\n",
      "TRACKER:  150 [[], 68, 4, 5, 5]\n",
      "TRACKER:  151 [[], 68, 4, 5, 5]\n",
      "TRACKER:  152 [[], 4, 68, 5, 5]\n",
      "TRACKER:  153 [[], 4, 68, 5, 5]\n",
      "TRACKER:  154 [[], 4, 68, 5, 5]\n",
      "TRACKER:  155 [[], 4, 68, 5, 5]\n",
      "TRACKER:  156 [[], 4, 68, 5, 5]\n",
      "TRACKER:  157 [[], 4, 68, 5, 5]\n",
      "frame:  159 new val:  69\n",
      "TRACKER:  158 [[], 4, 69, 5, 5]\n",
      "frame:  160 new val:  70\n",
      "TRACKER:  159 [[], 4, 70, 5, 5]\n",
      "TRACKER:  160 [[], 4, 70, 5, 5]\n",
      "TRACKER:  161 [[], 4, 70, 5, 5]\n",
      "TRACKER:  162 [[], 4, 70, 5, 5]\n",
      "TRACKER:  163 [[], 4, 70, 5, 5]\n",
      "TRACKER:  164 [[], 4, 70, 5, 5]\n",
      "TRACKER:  165 [[], 4, 70, 5, 5]\n",
      "TRACKER:  166 [[], 4, 70, 5, 5]\n",
      "TRACKER:  167 [[], 4, 70, 5, 5]\n",
      "TRACKER:  168 [[], 4, 70, 5, 5]\n",
      "TRACKER:  169 [[], 4, 70, 5, 5]\n",
      "TRACKER:  170 [[], 4, 70, 5, 5]\n",
      "TRACKER:  171 [[], 4, 70, 5, 5]\n",
      "TRACKER:  172 [[], 4, 70, 5, 5]\n",
      "TRACKER:  173 [[], 4, 70, 5, 5]\n",
      "TRACKER:  174 [[], 4, 70, 5, 5]\n",
      "TRACKER:  175 [[], 4, 70, 5, 5]\n",
      "TRACKER:  176 [[], 4, 70, 5, 5]\n",
      "TRACKER:  177 [[], 4, 70, 5, 5]\n",
      "TRACKER:  178 [[], 4, 70, 5, 5]\n",
      "TRACKER:  179 [[], 4, 70, 5]\n",
      "frame:  181 new val:  71\n",
      "TRACKER:  180 [[], 4, 70, 71, 5, 5]\n",
      "frame:  182 new val:  72\n",
      "TRACKER:  181 [[], 4, 70, 72, 5]\n",
      "TRACKER:  182 [[], 4, 70, 72, 5]\n",
      "TRACKER:  183 [[], 4, 70, 72, 5]\n",
      "frame:  185 new val:  73\n",
      "frame:  185 new val:  74\n",
      "frame:  185 new val:  75\n",
      "TRACKER:  184 [[], 4, 73, 74, 75, 5]\n",
      "frame:  186 new val:  76\n",
      "frame:  186 new val:  77\n",
      "TRACKER:  185 [[], 4, 76, 77, 5]\n",
      "frame:  187 new val:  78\n",
      "TRACKER:  186 [[], 4, 76, 77, 78, 5]\n",
      "frame:  188 new val:  79\n",
      "TRACKER:  187 [[], 4, 76, 79, 5]\n",
      "frame:  189 new val:  80\n",
      "TRACKER:  188 [[], 4, 76, 80, 5]\n",
      "frame:  190 new val:  81\n",
      "frame:  190 new val:  82\n",
      "TRACKER:  189 [[], 4, 76, 81, 82, 5]\n",
      "TRACKER:  190 [[], 4, 76, 81, 5]\n",
      "TRACKER:  191 [[], 4, 76, 81, 5]\n",
      "TRACKER:  192 [[], 4, 76, 81, 5]\n",
      "TRACKER:  193 [[], 4, 76, 81, 5]\n",
      "TRACKER:  194 [[], 4, 76, 81, 5]\n",
      "TRACKER:  195 [[], 4, 76, 81, 5]\n",
      "TRACKER:  196 [[], 4, 76, 81, 5]\n",
      "frame:  198 new val:  83\n",
      "TRACKER:  197 [[], 4, 76, 83, 5]\n",
      "TRACKER:  198 [[], 4, 76, 83, 5]\n",
      "TRACKER:  199 [[], 4, 76, 83, 5]\n",
      "TRACKER:  200 [[], 4, 76, 83, 5]\n",
      "TRACKER:  201 [[], 4, 76, 5]\n",
      "TRACKER:  202 [[], 4, 76, 5]\n",
      "TRACKER:  203 [[], 4, 76, 5]\n",
      "TRACKER:  204 [[], 4, 76, 5]\n",
      "TRACKER:  205 [[], 4, 76, 5]\n",
      "TRACKER:  206 [[], 4, 76, 5]\n",
      "TRACKER:  207 [[], 4, 76, 5]\n",
      "TRACKER:  208 [[], 4, 76, 5]\n",
      "TRACKER:  209 [[], 4, 76, 5]\n",
      "TRACKER:  210 [[], 4, 76, 5]\n",
      "TRACKER:  211 [[], 4, 76, 5]\n",
      "TRACKER:  212 [[], 4, 76, 5]\n",
      "TRACKER:  213 [[], 4, 76, 5]\n",
      "TRACKER:  214 [[], 4, 76, 5]\n",
      "TRACKER:  215 [[], 4, 76, 5]\n",
      "TRACKER:  216 [[], 4, 76, 5]\n",
      "TRACKER:  217 [[], 4, 76, 5]\n",
      "TRACKER:  218 [[], 4, 76, 5]\n",
      "TRACKER:  219 [[], 4, 76, 76, 5]\n",
      "TRACKER:  220 [[], 4, 76, 5]\n",
      "frame:  222 new val:  84\n",
      "frame:  222 new val:  85\n",
      "TRACKER:  221 [[], 4, 76, 84, 85, 5]\n",
      "frame:  223 new val:  86\n",
      "frame:  223 new val:  87\n",
      "TRACKER:  222 [[], 76, 86, 87, 5]\n",
      "frame:  224 new val:  88\n",
      "frame:  224 new val:  89\n",
      "TRACKER:  223 [[], 88, 76, 89, 5]\n",
      "TRACKER:  224 [[], 88, 76, 5]\n",
      "frame:  226 new val:  90\n",
      "frame:  226 new val:  91\n",
      "TRACKER:  225 [[], 88, 76, 90, 91, 5]\n",
      "frame:  227 new val:  92\n",
      "TRACKER:  226 [[], 88, 76, 92, 5]\n",
      "frame:  228 new val:  93\n",
      "TRACKER:  227 [[], 88, 76, 93, 5]\n",
      "TRACKER:  228 [[], 88, 76, 5]\n",
      "TRACKER:  229 [[], 88, 76, 5]\n",
      "TRACKER:  230 [[], 88, 76, 5]\n",
      "TRACKER:  231 [[], 88, 76, 5]\n",
      "TRACKER:  232 [[], 88, 76, 5]\n",
      "TRACKER:  233 [[], 88, 76, 5]\n",
      "TRACKER:  234 [[], 88, 76, 5]\n",
      "TRACKER:  235 [[], 88, 76, 5]\n",
      "TRACKER:  236 [[], 88, 76, 5]\n",
      "TRACKER:  237 [[], 88, 76, 5]\n",
      "TRACKER:  238 [[], 88, 76, 5]\n",
      "TRACKER:  239 [[], 88, 76, 5]\n",
      "TRACKER:  240 [[], 88, 76, 5]\n",
      "TRACKER:  241 [[], 88, 76, 5]\n",
      "TRACKER:  242 [[], 88, 76, 5]\n",
      "TRACKER:  243 [[], 88, 76, 5]\n",
      "TRACKER:  244 [[], 88, 76, 5]\n",
      "TRACKER:  245 [[], 88, 76, 5]\n",
      "TRACKER:  246 [[], 88, 76, 5]\n",
      "TRACKER:  247 [[], 88, 76, 5]\n",
      "TRACKER:  248 [[], 88, 76, 5]\n",
      "TRACKER:  249 [[], 88, 76, 5]\n",
      "TRACKER:  250 [[], 88, 76, 5]\n",
      "TRACKER:  251 [[], 88, 76, 5]\n",
      "TRACKER:  252 [[], 88, 76, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame:  254 new val:  94\n",
      "TRACKER:  253 [[], 76, 94, 88, 5]\n",
      "TRACKER:  254 [[], 88, 76, 5]\n",
      "TRACKER:  255 [[], 88, 76, 5]\n",
      "TRACKER:  256 [[], 88, 76, 5]\n",
      "frame:  258 new val:  95\n",
      "frame:  258 new val:  96\n",
      "TRACKER:  257 [[], 95, 88, 96, 5]\n",
      "frame:  259 new val:  97\n",
      "TRACKER:  258 [[], 88, 97, 5]\n",
      "frame:  260 new val:  98\n",
      "frame:  260 new val:  99\n",
      "TRACKER:  259 [[], 98, 88, 99, 5]\n",
      "frame:  261 new val:  100\n",
      "TRACKER:  260 [[], 100, 88, 5]\n",
      "TRACKER:  261 [[], 100, 88, 5]\n",
      "TRACKER:  262 [[], 100, 88, 5]\n",
      "TRACKER:  263 [[], 100, 88, 5]\n",
      "frame:  265 new val:  101\n",
      "frame:  265 new val:  102\n",
      "TRACKER:  264 [[], 101, 88, 102, 5]\n",
      "frame:  266 new val:  103\n",
      "TRACKER:  265 [[], 88, 103, 5]\n",
      "TRACKER:  266 [[], 88, 103, 5]\n",
      "TRACKER:  267 [[], 88, 103, 5]\n",
      "TRACKER:  268 [[], 103, 88, 5]\n",
      "frame:  270 new val:  104\n",
      "TRACKER:  269 [[], 103, 104, 88, 5]\n",
      "TRACKER:  270 [[], 88, 103, 5]\n",
      "frame:  272 new val:  105\n",
      "TRACKER:  271 [[], 103, 88, 105, 5]\n",
      "TRACKER:  272 [[], 103, 88, 5]\n",
      "TRACKER:  273 [[], 88, 103, 5]\n",
      "TRACKER:  274 [[], 103, 88, 5]\n",
      "frame:  276 new val:  106\n",
      "frame:  276 new val:  107\n",
      "TRACKER:  275 [[], 106, 88, 107, 5]\n",
      "frame:  277 new val:  108\n",
      "TRACKER:  276 [[], 108, 88, 5]\n",
      "TRACKER:  277 [[], 108, 88, 5]\n",
      "TRACKER:  278 [[], 108, 88, 5]\n",
      "TRACKER:  279 [[], 108, 88, 5]\n",
      "TRACKER:  280 [[], 108, 88, 5]\n",
      "frame:  282 new val:  109\n",
      "frame:  282 new val:  110\n",
      "TRACKER:  281 [[], 109, 88, 110, 5]\n",
      "frame:  283 new val:  111\n",
      "frame:  283 new val:  112\n",
      "TRACKER:  282 [[], 111, 88, 112, 5]\n",
      "frame:  284 new val:  113\n",
      "frame:  284 new val:  114\n",
      "TRACKER:  283 [[], 113, 88, 114, 5]\n",
      "frame:  285 new val:  115\n",
      "TRACKER:  284 [[], 115, 88, 5]\n",
      "TRACKER:  285 [[], 115, 88, 5]\n",
      "TRACKER:  286 [[], 115, 88, 5]\n",
      "TRACKER:  287 [[], 115, 88, 5]\n",
      "frame:  289 new val:  116\n",
      "frame:  289 new val:  117\n",
      "TRACKER:  288 [[], 116, 88, 117, 5]\n",
      "frame:  290 new val:  118\n",
      "TRACKER:  289 [[], 118, 88, 5]\n",
      "frame:  291 new val:  119\n",
      "frame:  291 new val:  120\n",
      "TRACKER:  290 [[], 118, 119, 120, 5]\n",
      "frame:  292 new val:  121\n",
      "TRACKER:  291 [[], 118, 121, 5]\n",
      "frame:  293 new val:  122\n",
      "frame:  293 new val:  123\n",
      "frame:  293 new val:  124\n",
      "frame:  293 new val:  125\n",
      "TRACKER:  292 [[], 122, 123, 124, 125, 5]\n",
      "frame:  294 new val:  126\n",
      "frame:  294 new val:  127\n",
      "frame:  294 new val:  128\n",
      "frame:  294 new val:  129\n",
      "TRACKER:  293 [[], 126, 127, 128, 129, 5]\n",
      "frame:  295 new val:  130\n",
      "frame:  295 new val:  131\n",
      "frame:  295 new val:  132\n",
      "frame:  295 new val:  133\n",
      "TRACKER:  294 [[], 130, 131, 132, 133, 5]\n",
      "frame:  296 new val:  134\n",
      "frame:  296 new val:  135\n",
      "TRACKER:  295 [[], 134, 135, 5]\n",
      "frame:  297 new val:  136\n",
      "frame:  297 new val:  137\n",
      "frame:  297 new val:  138\n",
      "frame:  297 new val:  139\n",
      "TRACKER:  296 [[], 136, 137, 138, 139, 5]\n",
      "frame:  298 new val:  140\n",
      "frame:  298 new val:  141\n",
      "frame:  298 new val:  142\n",
      "frame:  298 new val:  143\n",
      "TRACKER:  297 [[], 140, 141, 142, 143, 5]\n",
      "frame:  299 new val:  144\n",
      "frame:  299 new val:  145\n",
      "frame:  299 new val:  146\n",
      "frame:  299 new val:  147\n",
      "TRACKER:  298 [[], 144, 145, 146, 147, 5]\n",
      "frame:  300 new val:  148\n",
      "frame:  300 new val:  149\n",
      "frame:  300 new val:  150\n",
      "frame:  300 new val:  151\n",
      "TRACKER:  299 [[], 148, 149, 150, 151, 5]\n",
      "frame:  301 new val:  152\n",
      "frame:  301 new val:  153\n",
      "TRACKER:  300 [[], 152, 153, 5]\n",
      "TRACKER:  301 [[], 152, 153, 5]\n",
      "TRACKER:  302 [[], 152, 153, 5]\n",
      "frame:  304 new val:  154\n",
      "frame:  304 new val:  155\n",
      "TRACKER:  303 [[], 152, 154, 155, 5]\n",
      "frame:  305 new val:  156\n",
      "frame:  305 new val:  157\n",
      "TRACKER:  304 [[], 152, 156, 157, 5]\n",
      "TRACKER:  305 [[], 152, 156, 157, 5]\n",
      "TRACKER:  306 [[], 152, 156, 5]\n",
      "frame:  308 new val:  158\n",
      "frame:  308 new val:  159\n",
      "TRACKER:  307 [[], 152, 158, 159, 5]\n",
      "frame:  309 new val:  160\n",
      "frame:  309 new val:  161\n",
      "TRACKER:  308 [[], 152, 160, 161, 5]\n",
      "frame:  310 new val:  162\n",
      "frame:  310 new val:  163\n",
      "frame:  310 new val:  164\n",
      "TRACKER:  309 [[], 152, 162, 163, 164, 5]\n",
      "frame:  311 new val:  165\n",
      "frame:  311 new val:  166\n",
      "frame:  311 new val:  167\n",
      "frame:  311 new val:  168\n",
      "TRACKER:  310 [[], 165, 166, 167, 168, 5]\n",
      "frame:  312 new val:  169\n",
      "frame:  312 new val:  170\n",
      "TRACKER:  311 [[], 169, 170, 5]\n",
      "frame:  313 new val:  171\n",
      "frame:  313 new val:  172\n",
      "TRACKER:  312 [[], 169, 171, 172, 5]\n",
      "frame:  314 new val:  173\n",
      "frame:  314 new val:  174\n",
      "TRACKER:  313 [[], 169, 173, 174, 5]\n",
      "frame:  315 new val:  175\n",
      "frame:  315 new val:  176\n",
      "TRACKER:  314 [[], 169, 175, 176, 5]\n",
      "frame:  316 new val:  177\n",
      "frame:  316 new val:  178\n",
      "TRACKER:  315 [[], 169, 177, 178, 5]\n",
      "frame:  317 new val:  179\n",
      "frame:  317 new val:  180\n",
      "TRACKER:  316 [[], 169, 179, 180, 5]\n",
      "frame:  318 new val:  181\n",
      "TRACKER:  317 [[], 169, 181, 5]\n",
      "TRACKER:  318 [[], 169, 181, 5]\n",
      "TRACKER:  319 [[], 169, 181, 5]\n",
      "TRACKER:  320 [[], 169, 181, 5]\n",
      "frame:  322 new val:  182\n",
      "frame:  322 new val:  183\n",
      "TRACKER:  321 [[], 169, 182, 183, 5]\n",
      "frame:  323 new val:  184\n",
      "TRACKER:  322 [[], 169, 184, 5]\n",
      "TRACKER:  323 [[], 169, 184, 5]\n",
      "frame:  325 new val:  185\n",
      "TRACKER:  324 [[], 169, 184, 185, 5]\n",
      "TRACKER:  325 [[], 169, 184, 5]\n",
      "TRACKER:  326 [[], 169, 184, 5]\n",
      "TRACKER:  327 [[], 169, 184, 5]\n",
      "TRACKER:  328 [[], 169, 184, 5]\n",
      "TRACKER:  329 [[], 169, 184, 5]\n",
      "TRACKER:  330 [[], 169, 184, 5]\n",
      "TRACKER:  331 [[], 169, 184, 5]\n",
      "TRACKER:  332 [[], 169, 184, 5]\n",
      "TRACKER:  333 [[], 169, 184, 5]\n",
      "TRACKER:  334 [[], 169, 184, 5]\n",
      "TRACKER:  335 [[], 169, 184, 5]\n",
      "TRACKER:  336 [[], 169, 184, 5]\n",
      "TRACKER:  337 [[], 169, 184, 5]\n",
      "frame:  339 new val:  186\n",
      "TRACKER:  338 [[], 169, 186, 5]\n",
      "frame:  340 new val:  187\n",
      "TRACKER:  339 [[], 169, 187, 5]\n",
      "TRACKER:  340 [[], 169, 187, 5]\n",
      "TRACKER:  341 [[], 169, 187, 5]\n",
      "TRACKER:  342 [[], 169, 187, 5]\n",
      "TRACKER:  343 [[], 169, 187, 5]\n",
      "frame:  345 new val:  188\n",
      "TRACKER:  344 [[], 188, 187, 5]\n",
      "frame:  346 new val:  189\n",
      "TRACKER:  345 [[], 189, 187, 5]\n",
      "frame:  347 new val:  190\n",
      "frame:  347 new val:  191\n",
      "TRACKER:  346 [[], 190, 191, 187, 5]\n",
      "frame:  348 new val:  192\n",
      "frame:  348 new val:  193\n",
      "TRACKER:  347 [[], 192, 193, 187, 5]\n",
      "frame:  349 new val:  194\n",
      "frame:  349 new val:  195\n",
      "TRACKER:  348 [[], 194, 195, 187, 5]\n",
      "frame:  350 new val:  196\n",
      "frame:  350 new val:  197\n",
      "TRACKER:  349 [[], 196, 197, 187, 5]\n",
      "frame:  351 new val:  198\n",
      "frame:  351 new val:  199\n",
      "frame:  351 new val:  200\n",
      "TRACKER:  350 [[], 198, 199, 200, 5]\n",
      "frame:  352 new val:  201\n",
      "frame:  352 new val:  202\n",
      "TRACKER:  351 [[], 201, 202, 5]\n",
      "frame:  353 new val:  203\n",
      "frame:  353 new val:  204\n",
      "TRACKER:  352 [[], 203, 204, 5]\n",
      "frame:  354 new val:  205\n",
      "frame:  354 new val:  206\n",
      "frame:  354 new val:  207\n",
      "TRACKER:  353 [[], 205, 206, 207, 5]\n",
      "frame:  355 new val:  208\n",
      "frame:  355 new val:  209\n",
      "TRACKER:  354 [[], 208, 209, 5]\n",
      "frame:  356 new val:  210\n",
      "frame:  356 new val:  211\n",
      "TRACKER:  355 [[], 210, 211, 5]\n",
      "frame:  357 new val:  212\n",
      "frame:  357 new val:  213\n",
      "TRACKER:  356 [[], 212, 213, 5]\n",
      "frame:  358 new val:  214\n",
      "TRACKER:  357 [[], 214, 213, 5]\n",
      "frame:  359 new val:  215\n",
      "TRACKER:  358 [[], 215, 213, 5]\n",
      "frame:  360 new val:  216\n",
      "TRACKER:  359 [[], 216, 213, 5]\n",
      "frame:  361 new val:  217\n",
      "frame:  361 new val:  218\n",
      "TRACKER:  360 [[], 217, 218, 5]\n",
      "frame:  362 new val:  219\n",
      "frame:  362 new val:  220\n",
      "TRACKER:  361 [[], 219, 220, 5]\n",
      "TRACKER:  362 [[], 220, 5]\n",
      "TRACKER:  363 [[], 220, 220, 5]\n",
      "frame:  365 new val:  221\n",
      "TRACKER:  364 [[], 221, 220, 5]\n",
      "frame:  366 new val:  222\n",
      "TRACKER:  365 [[], 222, 220, 5]\n",
      "frame:  367 new val:  223\n",
      "frame:  367 new val:  224\n",
      "TRACKER:  366 [[], 223, 224, 5]\n",
      "frame:  368 new val:  225\n",
      "frame:  368 new val:  226\n",
      "TRACKER:  367 [[], 225, 226, 5]\n",
      "TRACKER:  368 [[], 226, 5]\n",
      "TRACKER:  369 [[], 226, 5]\n",
      "frame:  371 new val:  227\n",
      "frame:  371 new val:  228\n",
      "frame:  371 new val:  229\n",
      "frame:  371 new val:  230\n",
      "TRACKER:  370 [[], 227, 228, 229, 230, 5]\n",
      "frame:  372 new val:  231\n",
      "frame:  372 new val:  232\n",
      "TRACKER:  371 [[], 231, 232, 5]\n",
      "TRACKER:  372 [[], 231, 232, 5]\n",
      "TRACKER:  373 [[], 231, 232, 5]\n",
      "TRACKER:  374 [[], 231, 5]\n",
      "frame:  376 new val:  233\n",
      "TRACKER:  375 [[], 233, 231, 5]\n",
      "TRACKER:  376 [[], 231, 5]\n",
      "TRACKER:  377 [[], 231, 231, 5]\n",
      "frame:  379 new val:  234\n",
      "TRACKER:  378 [[], 234, 231, 5]\n",
      "frame:  380 new val:  235\n",
      "TRACKER:  379 [[], 235, 231, 5]\n",
      "frame:  381 new val:  236\n",
      "frame:  381 new val:  237\n",
      "frame:  381 new val:  238\n",
      "TRACKER:  380 [[], 236, 237, 238, 5]\n",
      "frame:  382 new val:  239\n",
      "frame:  382 new val:  240\n",
      "TRACKER:  381 [[], 239, 240, 5]\n",
      "frame:  383 new val:  241\n",
      "TRACKER:  382 [[], 241, 240, 5]\n",
      "frame:  384 new val:  242\n",
      "TRACKER:  383 [[], 242, 240, 5]\n",
      "frame:  385 new val:  243\n",
      "frame:  385 new val:  244\n",
      "TRACKER:  384 [[], 243, 244, 5, 5]\n",
      "frame:  386 new val:  245\n",
      "TRACKER:  385 [[], 245, 5]\n",
      "TRACKER:  386 [[], 245, 245, 5]\n",
      "frame:  388 new val:  246\n",
      "TRACKER:  387 [[], 246, 245, 5]\n",
      "TRACKER:  388 [[], 245, 5]\n",
      "TRACKER:  389 [[], 245, 5]\n",
      "TRACKER:  390 [[], 245, 5]\n",
      "TRACKER:  391 [[], 245, 245, 5]\n",
      "TRACKER:  392 [[], 245, 5]\n",
      "TRACKER:  393 [[], 245, 5]\n",
      "TRACKER:  394 [[], 245, 5]\n",
      "frame:  396 new val:  247\n",
      "frame:  396 new val:  248\n",
      "TRACKER:  395 [[], 247, 248, 5, 5]\n",
      "frame:  397 new val:  249\n",
      "frame:  397 new val:  250\n",
      "TRACKER:  396 [[], 249, 250, 5, 5]\n",
      "frame:  398 new val:  251\n",
      "TRACKER:  397 [[], 251, 5]\n",
      "DONE LOADING TRACKER\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "########## TIME_BASED CONNECTED COMPONNET 2: EXTRACT NETWORKS ####\n",
    "##################################################################\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "clrs = ['red','blue','cyan','green','yellow','pink','magenta','black','lightgreen','lightblue']\n",
    "\n",
    "def find_next_id(tracker):\n",
    "    \n",
    "    temp = functools.reduce(operator.iconcat, tracker, [])\n",
    "    temp = [x for x in temp if x]\n",
    "\n",
    "    temp2 = np.sort(np.unique(temp))\n",
    "    for k in range(1, np.max(temp2)+1):\n",
    "        idx = np.where(temp2==k)[0]\n",
    "        #print (\"K: \", k, temp2)\n",
    "        if idx.shape[0]==0:\n",
    "            return k\n",
    "            break\n",
    "\n",
    "    #print (\"Missing val: \", k, \"  from : \", temp2)\n",
    "    #print (\"k :\", k)\n",
    "    #print ('')\n",
    "\n",
    "    return k+1\n",
    "\n",
    "\n",
    "fname_tracker = fname_matches[:-4]+\"_tracker.npy\"\n",
    "if True:\n",
    "    frames = np.arange(400)\n",
    "#if os.path.exists(fname_tracker)==False:\n",
    "    chains = []\n",
    "    # \n",
    "    chain_ids = np.unique(matches[0])\n",
    "    print (\"Chain IDS: \", chain_ids)\n",
    "\n",
    "    max_network_id = np.max(chain_ids)+1\n",
    "\n",
    "    plotting = True\n",
    "\n",
    "    print (\"PLOTING: \", plotting)\n",
    "    if plotting:\n",
    "        fig=plt.figure(figsize=(40,20))\n",
    "        ax1=plt.subplot(1,1,1)\n",
    "        #ax2=plt.subplot(2,1,2)\n",
    "\n",
    "    tracker = []\n",
    "    tracker.append(chain_ids)\n",
    "\n",
    "    for ctr_k, k in enumerate(range(frames[0]+1,frames[-1], 1)):\n",
    "\n",
    "        prev_ids = np.unique(surfaces_watershed[k-1])\n",
    "        local_ids = np.unique(surfaces_watershed[k])\n",
    "\n",
    "        # add a list to contain all the chain ids for this frame:\n",
    "        tracker.append([])\n",
    "        for l in range(local_ids.shape[0]):\n",
    "            tracker[ctr_k+1].append([])\n",
    "\n",
    "        #max_network_id = np.max(tracker[:,k-1])+1\n",
    "\n",
    "        #for p in range(len(matches[k])):\n",
    "        for ctr, p in enumerate(range(len(local_ids))):\n",
    "            idx0 = np.where(surfaces_watershed[k]==local_ids[p])\n",
    "\n",
    "            # SKIP THE DEFAULT BACKGROUND PATCH\n",
    "            if idx0[0].shape[0]>500:\n",
    "                continue\n",
    "\n",
    "            prev_id = np.array(matches[ctr_k+1][p]).squeeze()\n",
    "            current_id = local_ids[p]\n",
    "            #current_id = ctr\n",
    "    #         print ([k-1, k])\n",
    "    #         print (\"prev id: \", prev_id)\n",
    "    #         print (current_id)\n",
    "\n",
    "            # if patch matches a prev_id\n",
    "            #print (\"k: \", k, \" prev_ID: \", prev_id)\n",
    "            if prev_id != None:\n",
    "                # inherit the chain ID of the previous val\n",
    "                idx = np.argwhere(prev_ids==prev_id)[0]\n",
    "\n",
    "                # if more than one match, just select either as they have same value;\n",
    "                if idx.shape[0]>0:\n",
    "                    idx=idx[0]\n",
    "                tracker[ctr_k+1][ctr]=tracker[ctr_k][idx]\n",
    "\n",
    "            # start a new chain with a new ID\n",
    "            else:\n",
    "\n",
    "                next_id = find_next_id(tracker)\n",
    "\n",
    "                next_id = max_network_id \n",
    "\n",
    "                tracker[ctr_k+1][ctr]=next_id\n",
    "\n",
    "                max_network_id +=1\n",
    "                print (\"frame: \", k, \"new val: \", next_id)\n",
    "\n",
    "            if prev_id != None and plotting:\n",
    "                #plt.plot([k-1, k], \n",
    "                #         [prev_id, current_id])\n",
    "                ax1.plot([k-1, k], \n",
    "                         [tracker[ctr_k][idx], tracker[ctr_k+1][ctr]],\n",
    "                        linewidth=4,\n",
    "                        c=clrs[tracker[ctr_k][idx]%10])\n",
    "\n",
    "#                 ax2.plot([k-1, k], \n",
    "#                          [tracker[ctr_k][idx], tracker[ctr_k+1][ctr]],\n",
    "#                         linewidth=4,\n",
    "#                         c=clrs[tracker[ctr_k][idx]%4])\n",
    "#                          #c=clrs[prev_id])\n",
    "    #             chains.append(\n",
    "    #                         [[k-1, k], \n",
    "    #                          [prev_id, current_id]])\n",
    "\n",
    "    #             cc2[prev_id, current_id, k-1]+=1\n",
    "                #chains[]\n",
    "        print (\"TRACKER: \",ctr_k,  tracker[ctr_k+1])\n",
    "        #print ('')\n",
    "\n",
    "    tracker = np.array(tracker)\n",
    "    if plotting:\n",
    "        ax1.set_xlabel(\"Frame #\", fontsize=50)\n",
    "        ax1.tick_params(labelsize=50, length=6, width=2, colors='black',\n",
    "                       grid_color='r', grid_alpha=0.5)\n",
    "        #ax1.set_xticks([])\n",
    "        ax1.tick_params(labelsize=50, length=6, width=2, colors='black',\n",
    "                       grid_color='r', grid_alpha=0.5)\n",
    "        ax1.set_ylabel(\"CC Network ID\", fontsize=50)\n",
    "        ax1.set_ylabel(\"CC Network ID\", fontsize=50)\n",
    "        ax1.set_xlim(0,frames[-1])\n",
    "        ax1.set_xlim(0,frames[-1])\n",
    "        #plt.savefig('/home/cat/networks1.png')\n",
    "        #plt.close()\n",
    "        plt.show()\n",
    "\n",
    "    np.save(fname_tracker, \n",
    "            tracker)\n",
    "else:\n",
    "    tracker = np.load(fname_tracker, allow_pickle=True)\n",
    "\n",
    "print (\"DONE LOADING TRACKER\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([   0,    1,    2, ..., 1664, 1665, 1666]), array([1667, 1668, 1669, ..., 3331, 3332, 3333]), array([3334, 3335, 3336, ..., 4998, 4999, 5000]), array([5001, 5002, 5003, ..., 6665, 6666, 6667]), array([6668, 6669, 6670, ..., 8331, 8332, 8333]), array([8334, 8335, 8336, ..., 9997, 9998, 9999])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel_launcher.py:104: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  0%|          | 0/6 [00:08<?, ?it/s]Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/parmap/parmap.py\", line 105, in _func_star_single\n",
      "    **func_item_args[3])\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-43-7b2fdd149058>\", line 129, in extract_images\n",
      "    plt.savefig(out_fname[:-4]+'.png')\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 724, in savefig\n",
      "    fig.canvas.draw_idle()   # need this if 'transparent=True' to reset colors\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/backend_bases.py\", line 1947, in draw_idle\n",
      "    self.draw(*args, **kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/parmap/parmap.py\", line 105, in _func_star_single\n",
      "    **func_item_args[3])\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\", line 393, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"<ipython-input-43-7b2fdd149058>\", line 129, in extract_images\n",
      "    plt.savefig(out_fname[:-4]+'.png')\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/parmap/parmap.py\", line 105, in _func_star_single\n",
      "    **func_item_args[3])\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 724, in savefig\n",
      "    fig.canvas.draw_idle()   # need this if 'transparent=True' to reset colors\n",
      "  File \"<ipython-input-43-7b2fdd149058>\", line 129, in extract_images\n",
      "    plt.savefig(out_fname[:-4]+'.png')\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/backend_bases.py\", line 1947, in draw_idle\n",
      "    self.draw(*args, **kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/figure.py\", line 1736, in draw\n",
      "    renderer, self, artists, self.suppressComposite)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 724, in savefig\n",
      "    fig.canvas.draw_idle()   # need this if 'transparent=True' to reset colors\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/image.py\", line 137, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/backend_bases.py\", line 1947, in draw_idle\n",
      "    self.draw(*args, **kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\", line 393, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\", line 393, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/axes/_base.py\", line 2630, in draw\n",
      "    mimage._draw_list_compositing_images(renderer, self, artists)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/image.py\", line 137, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/figure.py\", line 1736, in draw\n",
      "    renderer, self, artists, self.suppressComposite)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/axis.py\", line 1227, in draw\n",
      "    ticks_to_draw = self._update_ticks()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/image.py\", line 137, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/axis.py\", line 1111, in _update_ticks\n",
      "    minor_locs = self.get_minorticklocs()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/axis.py\", line 1358, in get_minorticklocs\n",
      "    lo, hi = sorted(transform.transform(self.get_view_interval()))\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/axes/_base.py\", line 2630, in draw\n",
      "    mimage._draw_list_compositing_images(renderer, self, artists)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/image.py\", line 137, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/image.py\", line 626, in draw\n",
      "    renderer, renderer.get_image_magnification())\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/figure.py\", line 1736, in draw\n",
      "    renderer, self, artists, self.suppressComposite)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/image.py\", line 917, in make_image\n",
      "    magnification, unsampled=unsampled)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/image.py\", line 499, in _make_image\n",
      "    out_alpha = _resample(self, mask, out_shape, t, resample=True)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/image.py\", line 202, in _resample\n",
      "    image_obj.get_filterrad())\n",
      "KeyboardInterrupt\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/image.py\", line 137, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/axes/_base.py\", line 2590, in draw\n",
      "    self._update_title_position(renderer)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/axes/_base.py\", line 2538, in _update_title_position\n",
      "    if title.get_window_extent(renderer).ymin < top:\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/text.py\", line 895, in get_window_extent\n",
      "    tx, ty = self._get_xy_display()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/text.py\", line 228, in _get_xy_display\n",
      "    return self.get_transform().transform((x, y))\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/transforms.py\", line 1405, in transform\n",
      "    res = self.transform_affine(self.transform_non_affine(values))\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/transforms.py\", line 2365, in transform_affine\n",
      "    return self.get_affine().transform(points)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/matplotlib/transforms.py\", line 2393, in get_affine\n",
      "    self._a.get_affine().get_matrix()))\n",
      "  File \"<__array_function__ internals>\", line 6, in dot\n",
      "KeyboardInterrupt\n",
      "\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-9:\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/parmap/parmap.py\u001b[0m in \u001b[0;36m_map_or_starmap\u001b[0;34m(function, iterable, args, kwargs, map_or_starmap)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0m_do_pbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/parmap/parmap.py\u001b[0m in \u001b[0;36m_do_pbar\u001b[0;34m(async_result, num_tasks, chunksize, refresh_time)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone_now\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0masync_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefresh_time\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update every two seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7b2fdd149058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    144\u001b[0m                \u001b[0msurfaces_watershed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                \u001b[0mpm_pbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                pm_processes=n_cores)\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     extract_images(frames, \n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/parmap/parmap.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(function, iterable, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m        \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpm_pbar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map_or_starmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"map\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/parmap/parmap.py\u001b[0m in \u001b[0;36m_map_or_starmap\u001b[0;34m(function, iterable, args, kwargs, map_or_starmap)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0m_do_pbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclose_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "########## TIME_BASED CONNECTED COMPONNET 3: SAVE IMAGES FOR CLASSIFIER #######\n",
    "###############################################################################\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "#plt.savefig('/tmp/test.png'\n",
    "            \n",
    "video_name ='/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "root_dir = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/training_images/'\n",
    "\n",
    "frame_id= frames[0]\n",
    "original_vid.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "\n",
    "#print (\"FRames: \", frames)\n",
    "#print (\"CHAINS: \", tracker)\n",
    "\n",
    "tracker_flat = flat_list = [item for sublist in tracker for item in sublist]\n",
    "min_chain = 0\n",
    "\n",
    "width = 100\n",
    "padding = 30\n",
    "ctr_img = 0\n",
    "#ctr_k = 0\n",
    "\n",
    "def extract_images(frame_ids,\n",
    "                   surfaces_watershed,\n",
    "                  ):\n",
    "\n",
    "    video_name ='/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "    original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "    # set start at frame_id 1\n",
    "    frame_start = frame_ids[0]\n",
    "    original_vid.set(cv2.CAP_PROP_POS_FRAMES, frame_start)\n",
    "\n",
    "    for ctr_k, k in enumerate(frame_ids):\n",
    "\n",
    "        ret, frame = original_vid.read()\n",
    "\n",
    "        # FIND UNIQUE PATCHES\n",
    "        local_ids = np.unique(surfaces_watershed[k])\n",
    "        img1 = surfaces_watershed[k].copy()  # original copy; do not alter;\n",
    "\n",
    "        for p, id_ in enumerate(local_ids):\n",
    "\n",
    "            idx0 = np.where(surfaces_watershed[k]==id_)\n",
    "\n",
    "            # SKIP THE DEFAULT BACKGROUND PATCH\n",
    "            if idx0[0].shape[0]>500:\n",
    "                continue\n",
    "\n",
    "            chain_id = tracker[frame_ids[ctr_k]][p]\n",
    "\n",
    "            # CHECK IF CHAIN ID BELONGS TO A LARGER CHAIN\n",
    "            # SAVE ALL CHAINS FOR NOW\n",
    "            if False:\n",
    "                idxc = np.where(tracker_flat==chain_id)[0] \n",
    "                if idxc.shape[0]<min_chain:\n",
    "                    continue\n",
    "\n",
    "            #img = img_array1[frame_id].copy()\n",
    "            img = img1.copy()\n",
    "\n",
    "            # ZERO OUT ALL NON ID_ values for PCA ROTATION COMPUTATION\n",
    "            idx1 = np.where(img1==id_)\n",
    "            idx2 = np.where(img1!=id_)\n",
    "            img[idx1]=1\n",
    "            img[idx2]=0\n",
    "\n",
    "            # FIND CENTRES\n",
    "            centrex = int(np.nanmean(idx1[0]))*8\n",
    "            centrey = int(np.nanmean(idx1[1]))*8\n",
    "            #print (\"cenres:\", centrex, centrey,\n",
    "            #      centrex//8, centrey//8)\n",
    "\n",
    "            # GRAB CENTRED PATCH\n",
    "            frame_patch = frame[centrex-width-padding:centrex+width+padding, \n",
    "                                centrey-width-padding:centrey+width+padding][:,:,1]\n",
    "\n",
    "            # EXCLUDE PATCHES THAT ARE NOT RIGHT SIZE DUE TO CLIPPING;\n",
    "            # TODO: fix this so it is not required\n",
    "            if frame_patch.shape[0]!= (width*2 + padding*2):\n",
    "                continue\n",
    "            if frame_patch.shape[1]!= (width*2 + padding*2):\n",
    "                continue\n",
    "\n",
    "\n",
    "            # FIND ROTATION USING PCA\n",
    "            y, x = np.nonzero(img)\n",
    "            x = x - np.mean(x)\n",
    "            y = y - np.mean(y)\n",
    "            coords = np.vstack([x, y])\n",
    "\n",
    "            cov = np.cov(coords)\n",
    "            evals, evecs = np.linalg.eig(cov)\n",
    "\n",
    "            sort_indices = np.argsort(evals)[::-1]\n",
    "            x_v1, y_v1 = evecs[:, sort_indices[0]]  # Eigenvector with largest eigenvalue\n",
    "            x_v2, y_v2 = evecs[:, sort_indices[1]]\n",
    "\n",
    "            # ROTATE PATCH\n",
    "            theta = np.arctan((x_v1)/(y_v1))  \n",
    "\n",
    "            # ROTATE RAW DATA\n",
    "            try:\n",
    "                frame_rotated = rotate_image(frame_patch, -theta*180/3.14159)\n",
    "                frame_rotated = frame_rotated[padding:-padding, padding: -padding]\n",
    "            except:\n",
    "                print (\"Couldn't rotate or clip image\")\n",
    "                continue\n",
    "                pass\n",
    "            #print (\" frame_patch: \", frame_patch.shape, \n",
    "            #       \"  frame rotated: \", frame_rotated.shape)\n",
    "\n",
    "            #print (\"   \", frame_rotated.shape)\n",
    "            out_fname = root_dir+str(chain_id)+'/frame_'+str(k)+\"_id_\"+str(p)+'.npy'\n",
    "\n",
    "            try: \n",
    "                os.mkdir(root_dir+str(chain_id))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            fig=plt.figure(figsize=(10,10))\n",
    "            plt.imshow(frame_rotated)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.savefig(out_fname[:-4]+'.png')\n",
    "            plt.close()\n",
    "\n",
    "            np.save(out_fname[:-4]+'.npy', frame_rotated)\n",
    "            #np.save(out_fname, frame_rotated)\n",
    "\n",
    "            #ctr_img+=1\n",
    "            \n",
    "n_cores = 6            \n",
    "frame_ids_split = np.array_split(frames, n_cores)\n",
    "print (frame_ids_split)\n",
    "if True:\n",
    "    \n",
    "    parmap.map(extract_images,\n",
    "               frame_ids_split,\n",
    "               surfaces_watershed,\n",
    "               pm_pbar=True,\n",
    "               pm_processes=n_cores)\n",
    "else:\n",
    "    extract_images(frames, \n",
    "           surfaces_watershed)\n",
    "\n",
    "        \n",
    "print (frame.shape)\n",
    "#img1 = img_array1[frame_id]\n",
    "\n",
    "#aspect = 'equal'\n",
    "#n_rows = np.unique(img1).shape[0]\n",
    "#for :\n",
    "#    img = img_array1[frame_id].copy()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test arrays from all the data saved;\n",
    "\n",
    "\n",
    "def load_gerbil_all_data(animal_dir,\n",
    "                        animal_id):\n",
    "    \n",
    "    from skimage.measure import block_reduce\n",
    "    \n",
    "    names = ['female','male','pup1','pup2']\n",
    "\n",
    "    import glob\n",
    "\n",
    "    \n",
    "    if True:\n",
    "        data = []\n",
    "        fnames = glob.glob(animal_dir+'/**/*',recursive = True)\n",
    "        #print (\"Fnames; \", fnames)\n",
    "        for fname in fnames:\n",
    "            if '.npy' in fname:\n",
    "                data.append(np.load(fname))\n",
    "        data = np.array(data)\n",
    "        print (\"data: \", \n",
    "               data.shape)\n",
    "\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    #data = np.load(animal_dir+\"id_\"+str(k)+'.npy')\n",
    "        \n",
    "    # scale data down:\n",
    "    #image = np.arange(3*3*4).reshape(3, 3, 4)\n",
    "    data_downsampled = []\n",
    "    for p in range(data.shape[0]):\n",
    "        temp = data[p]\n",
    "       # print (\"temp start: \", temp.shape)\n",
    "        temp = block_reduce(data[p], \n",
    "                            block_size=(6,6), \n",
    "                            func=np.mean)\n",
    "        #print (\"temp finish: \", temp.shape)\n",
    "        data_downsampled.append(temp)\n",
    "    x_test = np.array(data_downsampled)\n",
    "    print (x_test.shape)\n",
    "    y_test = np.zeros(x_test.shape[0])+ animal_id\n",
    "    \n",
    "    #x_test = np.vstack(x_test)\n",
    "    x_test = np.int32((x_test,x_test,x_test)).transpose(1,2,3,0)\n",
    "    y_test = np.hstack(y_test)[:,None]\n",
    "        \n",
    "    print (\"x test: \", x_test.shape,\n",
    "           \"y test: \", y_test.shape)\n",
    "    return x_test, y_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]5.16it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]5.60it/s]\n",
      " 13%|█▎        | 65/500 [00:11<02:13,  3.26it/s]/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel_launcher.py:78: RuntimeWarning: divide by zero encountered in double_scalars\n",
      " 16%|█▌        | 80/500 [00:15<01:54,  3.66it/s]/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel_launcher.py:78: RuntimeWarning: divide by zero encountered in double_scalars\n",
      " 26%|██▌       | 130/500 [00:24<01:09,  5.34it/s]\n",
      " 26%|██▌       | 129/500 [00:29<01:26,  4.30it/s]\n",
      " 41%|████      | 203/500 [00:48<01:10,  4.21it/s]\n",
      "100%|██████████| 500/500 [01:48<00:00,  4.60it/s]\n",
      "100%|██████████| 6/6 [01:49<00:00, 18.28s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/parmap/parmap.py\", line 105, in _func_star_single\n    **func_item_args[3])\n  File \"<ipython-input-20-1ce205efee3d>\", line 34, in save_cropped_images\n    chain_id = tracker[ctr_k][p]\nIndexError: index 4 is out of bounds for axis 0 with size 4\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1ce205efee3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    146\u001b[0m            \u001b[0mtracker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m            \u001b[0mpm_pbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m            pm_processes=n_proc)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     save_cropped_images(frames,\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/parmap/parmap.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(function, iterable, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m        \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpm_pbar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map_or_starmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"map\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/parmap/parmap.py\u001b[0m in \u001b[0;36m_map_or_starmap\u001b[0;34m(function, iterable, args, kwargs, map_or_starmap)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0m_do_pbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclose_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "# \n",
    "# def save_cropped_images(frames, \n",
    "#                        surfaces_watershed,\n",
    "#                        tracker):\n",
    "      \n",
    "#     video_name ='/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "#     original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "#     root_dir = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/training_images/'\n",
    "\n",
    "#     # LOAD NEXT VIDEO FRAME; MUST ASSIGN IN SEQUENCE SO iterator can work properly\n",
    "#     frame_id = frames[0]\n",
    "#     #print (frames, frame_id)\n",
    "#     original_vid.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "    \n",
    "#     # loop over asigned frames\n",
    "#     ctr_img=0\n",
    "#     for ctr_k, k in enumerate(tqdm(frames)):\n",
    "\n",
    "#         ret, frame = original_vid.read()\n",
    "\n",
    "#         # FIND UNIQUE PATCHES\n",
    "#         local_ids = np.unique(surfaces_watershed[k])\n",
    "#         img1 = surfaces_watershed[k].copy()  # original copy; do not alter;\n",
    "\n",
    "#         for p, id_ in enumerate(local_ids):\n",
    "\n",
    "#             idx0 = np.where(surfaces_watershed[k]==id_)\n",
    "\n",
    "#             # SKIP THE DEFAULT BACKGROUND PATCH\n",
    "#             if idx0[0].shape[0]>500:\n",
    "#                 continue\n",
    "\n",
    "#             chain_id = tracker[ctr_k][p]\n",
    "\n",
    "#             # CHECK IF CHAIN ID BELONGS TO A LARGER CHAIN\n",
    "#             idxc = np.where(tracker_flat==chain_id)[0]\n",
    "#             if idxc.shape[0]<min_chain:\n",
    "#                 continue\n",
    "\n",
    "#             #img = img_array1[frame_id].copy()\n",
    "#             img = img1.copy()\n",
    "\n",
    "#             # ZERO OUT ALL NON ID_ values for PCA ROTATION COMPUTATION\n",
    "#             idx1 = np.where(img1==id_)\n",
    "#             idx2 = np.where(img1!=id_)\n",
    "#             img[idx1]=1\n",
    "#             img[idx2]=0\n",
    "\n",
    "#             # FIND CENTRES\n",
    "#             centrex = int(np.nanmean(idx1[0]))*8\n",
    "#             centrey = int(np.nanmean(idx1[1]))*8\n",
    "#             #print (\"cenres:\", centrex, centrey,\n",
    "#             #      centrex//8, centrey//8)\n",
    "\n",
    "#             # GRAB CENTRED PATCH\n",
    "#             frame_patch = frame[centrex-width-padding:centrex+width+padding, \n",
    "#                                 centrey-width-padding:centrey+width+padding][:,:,1]\n",
    "\n",
    "#             if frame_patch.shape[0]!= (width*2 + padding*2):\n",
    "#                 continue\n",
    "#             if frame_patch.shape[1]!= (width*2 + padding*2):\n",
    "#                 continue\n",
    "#             # \n",
    "#             y, x = np.nonzero(img)\n",
    "#             x = x - np.mean(x)\n",
    "#             y = y - np.mean(y)\n",
    "#             coords = np.vstack([x, y])\n",
    "\n",
    "#             cov = np.cov(coords)\n",
    "#             evals, evecs = np.linalg.eig(cov)\n",
    "\n",
    "#             sort_indices = np.argsort(evals)[::-1]\n",
    "#             x_v1, y_v1 = evecs[:, sort_indices[0]]  # Eigenvector with largest eigenvalue\n",
    "#             x_v2, y_v2 = evecs[:, sort_indices[1]]\n",
    "\n",
    "#             # ROTATE PATCH\n",
    "#             theta = np.arctan((x_v1)/(y_v1))  \n",
    "\n",
    "#             # ROTATE RAW DATA\n",
    "#             try:\n",
    "#                 frame_rotated = rotate_image(frame_patch, -theta*180/3.14159)\n",
    "#                 frame_rotated = frame_rotated[padding:-padding, padding: -padding]\n",
    "#             except:\n",
    "#                 print (\"Couldn't rotate or clip image\")\n",
    "#                 continue\n",
    "#                 pass\n",
    "#             #print (\" frame_patch: \", frame_patch.shape, \n",
    "#             #       \"  frame rotated: \", frame_rotated.shape)\n",
    "\n",
    "#             #print (\"   \", frame_rotated.shape)\n",
    "#             out_fname = root_dir+str(chain_id)+'/frame_'+str(k)+\"_id_\"+str(p)+'.npy'\n",
    "\n",
    "#             try: \n",
    "#                 os.mkdir(root_dir+str(chain_id))\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "\n",
    "#             fig=plt.figure(figsize=(10,10))\n",
    "#             plt.imshow(frame_rotated)\n",
    "#             plt.xticks([])\n",
    "#             plt.yticks([])\n",
    "#             plt.savefig(out_fname[:-4]+'.png')\n",
    "#             plt.close()\n",
    "\n",
    "#             np.save(out_fname[:-4]+'.npy', frame_rotated)\n",
    "#             #np.save(out_fname, frame_rotated)\n",
    "\n",
    "\n",
    "\n",
    "#             ctr_img+=1\n",
    "        \n",
    "# matplotlib.use('Agg')\n",
    "# #plt.savefig('/tmp/test.png'\n",
    "            \n",
    "# video_name ='/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "# original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "# root_dir = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/training_images/'\n",
    "\n",
    "# frame_id= frames[0]\n",
    "# original_vid.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "\n",
    "# #print (\"FRames: \", frames)\n",
    "# #print (\"CHAINS: \", tracker)\n",
    "\n",
    "# tracker_flat = flat_list = [item for sublist in tracker for item in sublist]\n",
    "# min_chain = 50\n",
    "\n",
    "# width = 100\n",
    "# padding = 30\n",
    "# ctr_img = 0\n",
    "# #ctr_k = 0\n",
    "\n",
    "\n",
    "# import parmap\n",
    "# n_proc=6\n",
    "# frames_split = np.array_split(frames, n_proc)\n",
    "# #print (frames_split)\n",
    "    \n",
    "# if True:\n",
    "#     parmap.map(save_cropped_images,\n",
    "#                frames_split, \n",
    "#            surfaces_watershed,\n",
    "#            tracker,\n",
    "#            pm_pbar=True,\n",
    "#            pm_processes=n_proc)\n",
    "# else:\n",
    "#     save_cropped_images(frames,\n",
    "#             surfaces_watershed,\n",
    "#            tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "############## MAKE CLASSIFIER TRAINING DATA #########################\n",
    "######################################################################\n",
    "import numpy as np\n",
    "\n",
    "root_animals = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/training_images_cc/segments_training/'\n",
    "\n",
    "names = ['female','male','pup1','pup2', 'block']\n",
    "\n",
    "import glob\n",
    "\n",
    "# RECURSIVE LOADING OF ALL DATA\n",
    "data = []\n",
    "for ctr, name in enumerate(names):\n",
    "    data.append([])\n",
    "\n",
    "    fnames = glob.glob(root_animals+name+'/**/*',recursive = True)\n",
    "    for fname in fnames:\n",
    "        if '.npy' in fname:\n",
    "            data[ctr].append(np.load(fname))\n",
    "\n",
    "# SAVE THE DATASETS TO DISK          \n",
    "for k in range(len(names)):\n",
    "    print (names[k], len(data[k]))\n",
    "    temp = np.array(data[k])\n",
    "    print (temp.shape)\n",
    "    idx_rand = np.random.choice(np.arange(temp.shape[0]), \n",
    "                                #595, \n",
    "                                int(temp.shape[0]*.9),\n",
    "                                replace=False)\n",
    "    print (k, idx_rand.shape)\n",
    "    temp = np.array(temp[idx_rand])\n",
    "    print (temp.shape)\n",
    "    np.save(root_animals+\"id_\"+str(k)+'_train.npy', temp)\n",
    "    \n",
    "    # save test datasets; \n",
    "    temp = np.array(data[k])\n",
    "    idx = np.arange(temp.shape[0])\n",
    "    idx_test = np.delete(idx, idx_rand)\n",
    "    print (\"Idx test: \", idx_test.shape)\n",
    "    \n",
    "    temp = temp[idx_test]\n",
    "    print (\"saved test: \", temp.shape)\n",
    "    np.save(root_animals+\"id_\"+str(k)+'_test.npy', temp)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female 2922\n",
      "(2922, 200, 200)\n",
      "0 (2629,)\n",
      "(2629, 200, 200)\n",
      "Idx test:  (293,)\n",
      "saved test:  (293, 200, 200)\n",
      "male 1416\n",
      "(1416, 200, 200)\n",
      "1 (1274,)\n",
      "(1274, 200, 200)\n",
      "Idx test:  (142,)\n",
      "saved test:  (142, 200, 200)\n",
      "pup1 2113\n",
      "(2113, 200, 200)\n",
      "2 (1901,)\n",
      "(1901, 200, 200)\n",
      "Idx test:  (212,)\n",
      "saved test:  (212, 200, 200)\n",
      "pup2 1154\n",
      "(1154, 200, 200)\n",
      "3 (1038,)\n",
      "(1038, 200, 200)\n",
      "Idx test:  (116,)\n",
      "saved test:  (116, 200, 200)\n",
      "block 540\n",
      "(540, 200, 200)\n",
      "4 (486,)\n",
      "(486, 200, 200)\n",
      "Idx test:  (54,)\n",
      "saved test:  (54, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE MATCHES\n",
    "clrs = ['red','blue','cyan','green','yellow','pink','magenta','white','lightgreen','lightblue']\n",
    "\n",
    "\n",
    "# for k in frames:  #skip first match\n",
    "#     print (\"frame: \", k)\n",
    "#     im = surfaces_watershed[k]\n",
    "#     idx0 = np.where(im==0)\n",
    "#     #print (\"idx0: \", idx0)\n",
    "#     im[idx0]==np.nan\n",
    "    \n",
    "#     # \n",
    "#     ids = np.unique(im)\n",
    "#     #print (ids)\n",
    "#     for ctr, id_ in enumerate(ids):\n",
    "#         if id_==0:\n",
    "#             continue\n",
    "\n",
    "#         #\n",
    "#         idx = np.where(im==id_)\n",
    "#         centrex = np.mean(idx[0])\n",
    "#         centrey = np.mean(idx[1])\n",
    "#         print (centrex.shape, centrex)\n",
    "        \n",
    "#         #centrey = np.mean(im[idx[:,1]])\n",
    "\n",
    "#         match_id = np.array(matches[k][ctr]).squeeze()\n",
    "#         print (\"matchid: \", match_id)\n",
    "        \n",
    "#         plt.scatter(k, centrex+centrey, \n",
    "#                     c=clrs[match_id%10])\n",
    "        \n",
    "# plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 6 7]\n",
      "[0 3 5 6]\n",
      "[[0], [4], [6], [7]]\n"
     ]
    }
   ],
   "source": [
    "# id_ = 145\n",
    "# print (np.unique(surfaces_watershed[id_-1]))\n",
    "# print (np.unique(surfaces_watershed[id_]))\n",
    "# print (matches[id_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "# #################### EXTRACT PATCHES AND ALIGN THEM ##############\n",
    "# ##################################################################\n",
    "\n",
    "# #import skimage.filter\n",
    "\n",
    "\n",
    "# fig=plt.figure()\n",
    "\n",
    "\n",
    "# #img = misc.imread('oval.png', flatten=1)\n",
    "\n",
    "# video_name ='/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "\n",
    "\n",
    "# original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "# frame_id= 900\n",
    "# original_vid.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "# ret, frame = original_vid.read()\n",
    "\n",
    "# img1 = img_array1[frame_id]\n",
    "\n",
    "# aspect = 'equal'\n",
    "# n_rows = np.unique(img1).shape[0]\n",
    "# for ctr_id, id_ in enumerate(np.unique(img1)):\n",
    "    \n",
    "#     img = img_array1[frame_id].copy()\n",
    "    \n",
    "#     #id_ = 5\n",
    "#     print (\"ctr_ID: \", ctr_id)\n",
    "\n",
    "#     # PLOT FRAME\n",
    "#     ax=plt.subplot(n_rows,5,1+ctr_id*5)\n",
    "#     plt.imshow(frame)\n",
    "#     print (frame.shape)\n",
    "    \n",
    "#     # PLOT FRAME \n",
    "#     ax=plt.subplot(n_rows,5,2+ctr_id*5)\n",
    "#     plt.imshow(img, aspect=aspect)\n",
    "\n",
    "    \n",
    "#     # ZERO OUT ALL NON ID_ values for PCA ROTATION COMPUTATION\n",
    "#     print (np.unique(img1))\n",
    "#     idx1 = np.where(img1==id_)\n",
    "#     idx2 = np.where(img1!=id_)\n",
    "#     img[idx1]=1\n",
    "#     img[idx2]=0\n",
    "\n",
    "\n",
    "#     width = 125\n",
    "#     padding = 30\n",
    "#     print (\"idx1: \", idx1[0],\n",
    "#                     idx1[1])\n",
    "#     centrex = int(np.nanmean(idx1[0]))*8\n",
    "#     centrey = int(np.nanmean(idx1[1]))*8\n",
    "#     print (\"cenres:\", centrex, centrey,\n",
    "#           centrex//8, centrey//8)\n",
    "\n",
    "#     #frame_patch = np.zeros((200,200),'int32')\n",
    "#     frame_patch = frame[centrex-width-padding:centrex+width+padding, centrey-width-padding:centrey+width+padding][:,:,1]\n",
    "\n",
    "#     ax=plt.subplot(n_rows,5,3+ctr_id*5)\n",
    "#     plt.imshow(frame_patch,aspect=aspect)\n",
    "    \n",
    "    \n",
    "#     #\n",
    "#     y, x = np.nonzero(img)\n",
    "#     x = x - np.mean(x)\n",
    "#     y = y - np.mean(y)\n",
    "#     coords = np.vstack([x, y])\n",
    "\n",
    "#     cov = np.cov(coords)\n",
    "#     evals, evecs = np.linalg.eig(cov)\n",
    "\n",
    "#     sort_indices = np.argsort(evals)[::-1]\n",
    "#     x_v1, y_v1 = evecs[:, sort_indices[0]]  # Eigenvector with largest eigenvalue\n",
    "#     x_v2, y_v2 = evecs[:, sort_indices[1]]\n",
    "\n",
    "\n",
    "#     # PLOT THE PATCH WITH ANIMAL IN IT\n",
    "#     ax=plt.subplot(n_rows,5,4+ctr_id*5)\n",
    "#     scale = 20\n",
    "#     plt.plot([x_v1*-scale*2, x_v1*scale*2],\n",
    "#              [y_v1*-scale*2, y_v1*scale*2], color='red')\n",
    "#     plt.plot([x_v2*-scale, x_v2*scale],\n",
    "#              [y_v2*-scale, y_v2*scale], color='blue')\n",
    "#     plt.plot(x, y, 'k.')\n",
    "#     plt.axis('equal')\n",
    "#     plt.gca().invert_yaxis()  # Match the image system with origin at top left\n",
    "\n",
    "#     #fig=plt.figure()\n",
    "\n",
    "#     theta = np.arctan((x_v1)/(y_v1))  \n",
    "#     rotation_mat = np.matrix([[np.cos(theta), -np.sin(theta)],\n",
    "#                           [np.sin(theta), np.cos(theta)]])\n",
    "#     transformed_mat = rotation_mat * coords\n",
    "\n",
    "#     # plot the transformed blob\n",
    "#     x_transformed, y_transformed = transformed_mat.A\n",
    "#     plt.plot(x_transformed, y_transformed, 'g.')\n",
    "\n",
    "\n",
    "#     # ROTATE RAW DATA\n",
    "#     ax=plt.subplot(n_rows, 5,5+ctr_id*5)\n",
    "#     try: \n",
    "#         frame_rotated = rotate_image(frame_patch, -theta*180/3.14159)\n",
    "#         frame_rotated = frame_rotated[padding:-padding, padding: -padding]\n",
    "#         plt.imshow(frame_rotated,aspect=aspect)\n",
    "#     except:\n",
    "#         pass\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# #################### REMOVE PATCHES BELOW THRESHOLD ##############\n",
    "# ##################################################################\n",
    "\n",
    "# centres = []\n",
    "# ids = []\n",
    "# min_size = 0\n",
    "# for k in range(102):\n",
    "#     idx = np.unique(img_array[k])\n",
    "#     centres.append([])\n",
    "#     ids.append([])\n",
    "#     #print (k, idx.shape, idx)\n",
    "#     ctr=0\n",
    "#     for id_ in idx:\n",
    "#         idx2 = np.where(img_array[k]==id_)\n",
    "#         if idx2[0].shape[0]< min_size:\n",
    "#             img_array[k][idx2]=0\n",
    "#             continue\n",
    "#         ids[k].append(ctr)\n",
    "#         if idx2[0].shape[0]>1:\n",
    "#             centres[k].append(np.array([np.mean(idx2[0]), np.mean(idx2[1])]))\n",
    "#         else:\n",
    "#             centres[k].append(np.array([idx2[0], idx2[1]]))\n",
    "#         ctr+=1    \n",
    "            \n",
    "#         #print (centres[k])\n",
    "#     #print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LINK CENTRES ACROSS TIME\n",
    "# centres = np.array(centres)\n",
    "# print (centres.shape)\n",
    "# from scipy.spatial import distance\n",
    "\n",
    "# matches = []\n",
    "# for k in range(1,102,1):\n",
    "    \n",
    "#     # find min distances \n",
    "#     dist = distance.cdist(centres[k],centres[k-1]) \n",
    "#     print (k, dist.min(axis=1))\n",
    "#     match = dist.argmin(axis=1)\n",
    "#     print (\"k, \", k, \"  match: \",  match)\n",
    "#     matches.append(match)\n",
    "    \n",
    "# matches = np.array(matches)\n",
    "# print (matches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FIND CENTRES FOR ALL THE CONTOURS\n",
    "# #centres = []\n",
    "# #min_size = 100\n",
    "# imgs = img_array.copy()\n",
    "# fig=plt.figure(figsize=(20,20))\n",
    "# ctr_plot=0\n",
    "# for k in range(20,40,1):\n",
    "#     ax = plt.subplot(4,5,ctr_plot+1)\n",
    "#     #idx = np.unique(img_array[k])\n",
    "#     #print (k, idx.shape, idx)\n",
    "#     ctr=0\n",
    "#     for id_ in ids[k]:\n",
    "#         idx2 = np.where(img_array[k]==id_)\n",
    "#         #if idx2[0].shape[0]< min_size:\n",
    "#         #    continue\n",
    "#         print (\"frame: \", k, \" animal id: \", id_, \" ctr: \", ctr)\n",
    "#         print (\"ids \", ids[k])\n",
    "#         print (\"matches \", matches[k])\n",
    "#         print (\"   matches \", matches[k-1][ctr])\n",
    "#         #print (matches[k])\n",
    "#         imgs[k][idx2]=matches[k-1][ctr]\n",
    "#         ctr+=1\n",
    "        \n",
    "#     plt.ylabel(str(k))\n",
    "#     idx =np.where(imgs[k]<0)\n",
    "#     imgs[k][idx]=0\n",
    "    \n",
    "#     vmin = np.min(imgs[k]); vmax=np.max(imgs[k])\n",
    "#     img2 = surfaces[k]\n",
    "#     img2 = (img2-np.min(img2))/(np.max(img2)-np.min(img2))\n",
    "#     img2 = img2*(vmax-vmin)+vmin\n",
    "#     img_final = np.vstack((imgs[k],img2))\n",
    "#     img_final[img_final.shape[0]//2]=np.nan\n",
    "#     plt.imshow(img_final)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     ctr_plot+=1\n",
    "    \n",
    "# #plt.show()\n",
    "# #\"/home/cat/watershed.png\",dpi=1200)\n",
    "# fig.savefig(\"/home/cat/watershed.svg\", format='svg', dpi=300)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = 24\n",
    "# ax =plt.subplot(1,2,1)\n",
    "# plt.imshow(img_array[frame])\n",
    "# ax =plt.subplot(1,2,2)\n",
    "# plt.imshow(surfaces[frame])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
