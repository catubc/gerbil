{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "from tqdm import trange\n",
    "\n",
    "#import glob2\n",
    "\n",
    "from numba import jit\n",
    "import tables\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import h5py\n",
    "#import hdf5storage\n",
    "import csv\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"DLClight\"] = \"True\"\n",
    "import deeplabcut\n",
    "import tensorflow.contrib.slim as slim\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "vers = (tf.__version__).split(\".\")\n",
    "if int(vers[0]) == 1 and int(vers[1]) > 12:\n",
    "    TF = tf.compat.v1\n",
    "else:\n",
    "    TF = tf\n",
    "    \n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import resnet_v1\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "#from deeplabcut.pose_estimation_tensorflow.train import get_optimizer, LearningRate\n",
    "from deeplabcut.pose_estimation_tensorflow.train import  LearningRate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_optimizer(loss_op, cfg, train_resnet=False):\n",
    "    # train_resnet=True trains resnet!\n",
    "    learning_rate = TF.placeholder(tf.float32, shape=[])\n",
    "\n",
    "    if cfg.optimizer == \"sgd\":\n",
    "        optimizer = TF.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "    elif cfg.optimizer == \"adam\":\n",
    "        optimizer = TF.train.AdamOptimizer(learning_rate)\n",
    "    else:\n",
    "        raise ValueError('unknown optimizer {}'.format(cfg.optimizer))\n",
    "\n",
    "    #%%\n",
    "    all_variables_to_train = tf.trainable_variables()\n",
    "    if train_resnet:\n",
    "        variables_to_train = all_variables_to_train\n",
    "    else:\n",
    "        variables_to_train = list(filter(lambda k: 'mclassid' in k.name, all_variables_to_train))\n",
    "\n",
    "    train_op = slim.learning.create_train_op(loss_op, optimizer, variables_to_train=variables_to_train)\n",
    "\n",
    "    return learning_rate, train_op\n",
    "\n",
    "\n",
    "def get_train_config(cfg, shuffle=1):\n",
    "    from deeplabcut.utils import auxiliaryfunctions\n",
    "    from deeplabcut.pose_estimation_tensorflow.config import load_config\n",
    "    project_path = cfg['project_path']\n",
    "    iteration = cfg['iteration']\n",
    "    TrainingFraction = cfg['TrainingFraction'][iteration]\n",
    "    modelfolder = os.path.join(\n",
    "        project_path,\n",
    "        str(auxiliaryfunctions.GetModelFolder(TrainingFraction, shuffle, cfg)))\n",
    "\n",
    "    path_test_config = Path(modelfolder) / 'train' / 'pose_cfg.yaml'\n",
    "    print(path_test_config)\n",
    "    try:\n",
    "        dlc_cfg = load_config(str(path_test_config))\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\n",
    "            \"It seems the model for shuffle %s and trainFraction %s does not exist.\"\n",
    "            % (shuffle, TrainingFraction))\n",
    "    return dlc_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config...\n",
      "/media/cat/4TBSSD/DLC_full_directory/dlc-models/iteration-0/madeline_july2Jul2-trainset95shuffle1/train/pose_cfg.yaml\n",
      "(500, 34, 34)\n",
      "(500, 34, 34)\n",
      "(500, 34, 34)\n",
      "(500, 34, 34)\n",
      "x train:  (2000, 34, 34, 3) y train:  (2000, 1) x test:  (380, 34, 34, 3) y test:  (380, 1)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# ------------------- User inputs --------\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import resnet_v1\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "\n",
    "# define paths\n",
    "config_path = '/media/cat/4TBSSD/DLC_full_directory/config.yaml'\n",
    "videofile_path = '/media/cat/4TBSSD/DLC_full_directory/videos_to_label/2020-3-16_12_54_07_193951_compressed_label.mp4'\n",
    "shuffle = 1 #dlc experiment shuffle\n",
    "\n",
    "# ------------------- READ DLC info --------\n",
    "# read config\n",
    "print(\"Reading config...\")\n",
    "cfg = deeplabcut.auxiliaryfunctions.read_config(str(config_path))\n",
    "dlc_cfg = get_train_config(cfg,shuffle=shuffle)\n",
    "\n",
    "#\n",
    "\n",
    "#\n",
    "# train w imagenet: data/255\n",
    "BATCH_SIZE = 60\n",
    "num_classes = 10\n",
    "is_training=False\n",
    "\n",
    "#%%\n",
    "# Example with CIFAR10, replace with frames and labels\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# CIFAR DATA: x_train (50000, 32, 32, 3) \n",
    "#             y_train (50000, 1) \n",
    "#             x_test (10000, 32, 32, 3) \n",
    "#             y_test (10000, 1)\n",
    "\n",
    "def load_gerbil_training_data(animal_dir):\n",
    "    \n",
    "    from skimage.measure import block_reduce\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    for k in range(4):\n",
    "        data = np.load(animal_dir+\"id_\"+str(k)+'.npy')\n",
    "        \n",
    "        # scale data down:\n",
    "        #image = np.arange(3*3*4).reshape(3, 3, 4)\n",
    "        data_downsampled = []\n",
    "        for p in range(data.shape[0]):\n",
    "            temp = data[k]\n",
    "           # print (\"temp start: \", temp.shape)\n",
    "            temp = block_reduce(data[k], \n",
    "                                block_size=(6,6), \n",
    "                                func=np.mean)\n",
    "            #print (\"temp finish: \", temp.shape)\n",
    "            data_downsampled.append(temp)\n",
    "        data = np.array(data_downsampled)\n",
    "        \n",
    "        idx_rand = np.random.choice(np.arange(data.shape[0]), 500, replace=False)\n",
    "        #print (\"idx rand: \", idx_rand.shape)\n",
    "        \n",
    "        x_train.append(data[idx_rand])\n",
    "        print (data[idx_rand].shape)\n",
    "        y_train.append(np.zeros(idx_rand.shape[0])+k)\n",
    "\n",
    "        # make test set\n",
    "        idx_test = np.delete(np.arange(data.shape[0]), \n",
    "                             idx_rand)\n",
    "        #print (\"idx test: \", idx_test.shape)\n",
    "        temp = data[idx_test]\n",
    "        #print (temp.shape)\n",
    "        x_test.append(temp)\n",
    "        y_test.append(np.zeros(temp.shape[0])+k)\n",
    "\n",
    "        \n",
    "\n",
    "    x_train = np.vstack(x_train)\n",
    "    x_train = np.int32((x_train,x_train,x_train)).transpose(1,2,3,0)\n",
    "    #np.save('/home/cat/x_train.npy', x_train)\n",
    "    \n",
    "    y_train = np.hstack(y_train)[:,None]\n",
    "    \n",
    "    x_test = np.vstack(x_test)\n",
    "    x_test = np.int32((x_test,x_test,x_test)).transpose(1,2,3,0)\n",
    "    y_test = np.hstack(y_test)[:,None]\n",
    "        \n",
    "        \n",
    "    return x_train, y_train, x_test, y_test \n",
    "\n",
    "animal_dir ='/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/training_images/animals/'\n",
    "(x_train, y_train, x_test, y_test) = load_gerbil_training_data(animal_dir)\n",
    "\n",
    "\n",
    "print (\"x train: \", x_train.shape, \n",
    "       \"y train: \", y_train.shape, \n",
    "       \"x test: \", x_test.shape, \n",
    "       \"y test: \", y_test.shape)\n",
    "\n",
    "# for k in range(10):\n",
    "#     ax=plt.subplot(2,5,k+1)\n",
    "#     plt.imshow(x_train[k])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (2000, 34, 34, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train, x_test = np.array(x_train,np.float32), np.array(x_test, np.float32)\n",
    "y_train, y_test = np.array(y_train.flatten(), np.int64), np.array(y_test.flatten(), np.int64)\n",
    "\n",
    "nx_in, ny_in, nc_in = x_train.shape[1:]\n",
    "assert nc_in == 3\n",
    "\n",
    "print (\"X_train: \", x_train.shape)\n",
    "np.save('/home/cat/x_train.npy', x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_train[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:  <DatasetV1Adapter shapes: ((?, 34, 34, 3), (?,)), types: (tf.float32, tf.int32)> (?, 34, 34, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%% ------------- BEGIN GRAPH -------------\n",
    "TF.reset_default_graph()\n",
    "# tf.data API\n",
    "batch_size = tf.placeholder(tf.int64, shape=[])\n",
    "x, y = tf.placeholder(tf.float32, shape=[None, nx_in, ny_in, nc_in]), tf.placeholder(tf.int32, shape=[None,])\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size).repeat().shuffle(5000)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size).shuffle(5000)\n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                           train_dataset.output_shapes)\n",
    "image_batch, targets = iterator.get_next()\n",
    "\n",
    "\n",
    "print (\"train_dataset: \", train_dataset, image_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# init iterators\n",
    "train_init_op = iterator.make_initializer(train_dataset)\n",
    "test_init_op = iterator.make_initializer(test_dataset)\n",
    "\n",
    "# upsample cifar images which are 32 x 32\n",
    "if nx_in <= 200:\n",
    "    inputs = tf.image.resize_images(image_batch, [224, 224])\n",
    "print (inputs.shape)\n",
    "targets = tf.reshape(targets, [batch_size, ])\n",
    "\n",
    "# Make model\n",
    "net_funcs = {'resnet_50': resnet_v1.resnet_v1_50,\n",
    "             'resnet_101': resnet_v1.resnet_v1_101,\n",
    "             'resnet_152': resnet_v1.resnet_v1_152}\n",
    "\n",
    "net_fun = net_funcs[dlc_cfg.net_type]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the same way as dlc -- here note that they don't normalize\n",
    "mean = tf.constant(dlc_cfg.mean_pixel, dtype=tf.float32, shape=[1, 1, 1, 3],\n",
    "                   name='img_mean')\n",
    "im_centered = inputs - mean\n",
    "# add strides st we can load dlc weights\n",
    "if 'output_stride' not in dlc_cfg.keys():\n",
    "    dlc_cfg.output_stride = 16\n",
    "if 'deconvolutionstride' not in dlc_cfg.keys():\n",
    "    dlc_cfg.deconvolutionstride = 2\n",
    "    \n",
    "# \n",
    "with slim.arg_scope(resnet_v1.resnet_arg_scope()):\n",
    "    net, endpoints = net_fun(im_centered, num_classes=None,#num_classes,\n",
    "                             is_training=is_training,\n",
    "                             #global_pool=True,\n",
    "                             output_stride=dlc_cfg.output_stride)\n",
    "\n",
    "net = tf.squeeze(net, axis=[1, 2])\n",
    "logits = slim.fully_connected(net, num_outputs=num_classes,\n",
    "                              activation_fn=None,\n",
    "                              scope='mclassid')\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add extrainfo\n",
    "logits2 = tf.nn.softmax(logits)\n",
    "classes = tf.cast(tf.argmax(logits2, axis=1, ), tf.int32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(classes, targets), dtype=tf.float32))\n",
    "eval_dict = {'logits2': logits2,\n",
    "             'classes': classes,\n",
    "             'accuracy':accuracy}\n",
    "\n",
    "# restore variables for resnet\n",
    "variables_to_restore = slim.get_variables_to_restore(include=[\"resnet_v1\"])\n",
    "restorer = TF.train.Saver(variables_to_restore)\n",
    "saver = TF.train.Saver(\n",
    "        max_to_keep=5\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous dlc_cfg init weights:  C:\\ProgramData\\Anaconda3\\envs\\DLC-GPU2\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\n",
      "Restored variables from\n",
      "/home/cat/Downloads/resnet_v1_50.ckpt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% Init session\n",
    "#ess.close()\n",
    "config_TF = TF.ConfigProto()\n",
    "config_TF.gpu_options.allow_growth = True\n",
    "sess = TF.Session(config=config_TF)\n",
    "TF.summary.FileWriter('logs/', sess.graph)\n",
    "\n",
    "learning_rate, train_op = get_optimizer(loss, dlc_cfg)\n",
    "lr = tf.get_variable('learning_rate', initializer=0.01, trainable=False)\n",
    "#%%\n",
    "sess.run(TF.global_variables_initializer())\n",
    "sess.run(TF.local_variables_initializer())\n",
    "#sess.save()\n",
    "\n",
    "# Restore the resnet weights from dlc\n",
    "print (\"Previous dlc_cfg init weights: \", dlc_cfg.init_weights)\n",
    "dlc_cfg.init_weights = '/home/cat/Downloads/resnet_v1_50.ckpt'\n",
    "restorer.restore(sess, dlc_cfg.init_weights)\n",
    "print('Restored variables from\\n{}\\n'.format(dlc_cfg.init_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,) [0 0 0 ... 3 3 3]\n",
      "(2000, 34, 34, 3)\n",
      "Training...\n",
      "Epoch: 0 \t Iter: 0/33, Loss: 2.1462 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 1/33, Loss: 2.5226 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 2/33, Loss: 2.4110 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 3/33, Loss: 2.2843 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 4/33, Loss: 1.9533 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 5/33, Loss: 1.8757 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 6/33, Loss: 1.7340 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 7/33, Loss: 2.3452 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 8/33, Loss: 3.2127 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 9/33, Loss: 3.1833 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 10/33, Loss: 1.5377 Accuracy:1.0000\n",
      "Epoch: 0 \t Iter: 11/33, Loss: 3.0968 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 12/33, Loss: 2.1737 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 13/33, Loss: 2.9981 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 14/33, Loss: 2.0751 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 15/33, Loss: 1.3953 Accuracy:1.0000\n",
      "Epoch: 0 \t Iter: 16/33, Loss: 1.9549 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 17/33, Loss: 1.8852 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 18/33, Loss: 1.4384 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 19/33, Loss: 1.4083 Accuracy:1.0000\n",
      "Epoch: 0 \t Iter: 20/33, Loss: 2.7155 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 21/33, Loss: 2.6765 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 22/33, Loss: 1.5681 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 23/33, Loss: 1.5076 Accuracy:0.0000\n",
      "Epoch: 0 \t Iter: 24/33, Loss: 1.7335 Accuracy:0.6667\n",
      "Epoch: 0 \t Iter: 25/33, Loss: 1.2247 Accuracy:1.0000\n",
      "Epoch: 0 \t Iter: 26/33, Loss: 1.1931 Accuracy:1.0000\n",
      "Epoch: 0 \t Iter: 27/33, Loss: 1.1507 Accuracy:1.0000\n",
      "Epoch: 0 \t Iter: 28/33, Loss: 1.0998 Accuracy:1.0000\n",
      "Epoch: 0 \t Iter: 29/33, Loss: 1.2158 Accuracy:1.0000\n",
      "Epoch: 0 \t Iter: 30/33, Loss: 0.9944 Accuracy:1.0000\n",
      "Epoch: 0 \t Iter: 31/33, Loss: 1.3749 Accuracy:1.0000\n",
      "Epoch: 0 \t Iter: 32/33, Loss: 1.1111 Accuracy:1.0000\n",
      "Epoch: 0, Loss: 1.9151\n",
      "Epoch: 0, Test Loss: 0.9129 Test Accuracy 1.0000\n",
      "Epoch: 1 \t Iter: 0/33, Loss: 1.3748 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 1/33, Loss: 2.3392 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 2/33, Loss: 1.0160 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 3/33, Loss: 0.9807 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 4/33, Loss: 1.6595 Accuracy:0.6667\n",
      "Epoch: 1 \t Iter: 5/33, Loss: 2.2671 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 6/33, Loss: 0.8721 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 7/33, Loss: 2.2090 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 8/33, Loss: 2.1705 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 9/33, Loss: 2.1227 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 10/33, Loss: 1.3248 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 11/33, Loss: 2.0189 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 12/33, Loss: 0.7303 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 13/33, Loss: 1.5051 Accuracy:0.6667\n",
      "Epoch: 1 \t Iter: 14/33, Loss: 1.0979 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 15/33, Loss: 1.0833 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 16/33, Loss: 1.7940 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 17/33, Loss: 0.7002 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 18/33, Loss: 0.6864 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 19/33, Loss: 0.6766 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 20/33, Loss: 1.1866 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 21/33, Loss: 1.6331 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 22/33, Loss: 1.1509 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 23/33, Loss: 0.6654 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 24/33, Loss: 0.6569 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 25/33, Loss: 1.5345 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 26/33, Loss: 0.6291 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 27/33, Loss: 0.6107 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 28/33, Loss: 1.4619 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 29/33, Loss: 1.0516 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 30/33, Loss: 0.5525 Accuracy:1.0000\n",
      "Epoch: 1 \t Iter: 31/33, Loss: 1.3890 Accuracy:0.0000\n",
      "Epoch: 1 \t Iter: 32/33, Loss: 0.5160 Accuracy:1.0000\n",
      "Epoch: 1, Loss: 1.2626\n",
      "Epoch: 1, Test Loss: 0.5973 Test Accuracy 1.0000\n",
      "Epoch: 2 \t Iter: 0/33, Loss: 1.0108 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 1/33, Loss: 0.6375 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 2/33, Loss: 0.6345 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 3/33, Loss: 1.2873 Accuracy:0.0000\n",
      "Epoch: 2 \t Iter: 4/33, Loss: 1.2655 Accuracy:0.0000\n",
      "Epoch: 2 \t Iter: 5/33, Loss: 1.2366 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 6/33, Loss: 0.6027 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 7/33, Loss: 1.1718 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 8/33, Loss: 0.4285 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 9/33, Loss: 0.9698 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 10/33, Loss: 0.8310 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 11/33, Loss: 0.4140 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 12/33, Loss: 1.0436 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 13/33, Loss: 0.5497 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 14/33, Loss: 0.9299 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 15/33, Loss: 0.9161 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 16/33, Loss: 0.3921 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 17/33, Loss: 0.8762 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 18/33, Loss: 0.9582 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 19/33, Loss: 0.9454 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 20/33, Loss: 0.3774 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 21/33, Loss: 0.9110 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 22/33, Loss: 0.8901 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 23/33, Loss: 0.8649 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 24/33, Loss: 0.8004 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 25/33, Loss: 0.3630 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 26/33, Loss: 0.5242 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 27/33, Loss: 0.7693 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 28/33, Loss: 0.3532 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 29/33, Loss: 0.3476 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 30/33, Loss: 0.7609 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 31/33, Loss: 0.5134 Accuracy:1.0000\n",
      "Epoch: 2 \t Iter: 32/33, Loss: 0.3266 Accuracy:1.0000\n",
      "Epoch: 2, Loss: 0.7546\n",
      "Epoch: 2, Test Loss: 0.5398 Test Accuracy 1.0000\n",
      "Epoch: 3 \t Iter: 0/33, Loss: 0.4996 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 1/33, Loss: 0.4871 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 2/33, Loss: 0.3055 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 3/33, Loss: 0.7108 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 4/33, Loss: 0.7275 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 5/33, Loss: 0.4325 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 6/33, Loss: 0.6594 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 7/33, Loss: 0.6539 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 8/33, Loss: 0.2762 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 9/33, Loss: 0.2718 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 10/33, Loss: 0.6851 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 11/33, Loss: 0.3762 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 12/33, Loss: 0.2562 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 13/33, Loss: 0.3594 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 14/33, Loss: 0.3485 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 15/33, Loss: 0.3352 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 16/33, Loss: 0.2387 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 17/33, Loss: 0.6487 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 18/33, Loss: 0.6187 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 19/33, Loss: 0.2881 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 20/33, Loss: 0.2776 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 21/33, Loss: 0.6117 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 22/33, Loss: 0.2232 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 23/33, Loss: 0.2207 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 24/33, Loss: 0.2167 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 25/33, Loss: 0.2351 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 26/33, Loss: 0.2073 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 27/33, Loss: 0.2221 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 28/33, Loss: 0.6318 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 29/33, Loss: 0.2097 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 30/33, Loss: 0.2032 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 31/33, Loss: 0.5880 Accuracy:1.0000\n",
      "Epoch: 3 \t Iter: 32/33, Loss: 0.6202 Accuracy:1.0000\n",
      "Epoch: 3, Loss: 0.4135\n",
      "Epoch: 3, Test Loss: 0.5950 Test Accuracy 1.0000\n",
      "Epoch: 4 \t Iter: 0/33, Loss: 0.1865 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 1/33, Loss: 0.1816 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 2/33, Loss: 0.1823 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 3/33, Loss: 0.5980 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 4/33, Loss: 0.1771 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 5/33, Loss: 0.1683 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 6/33, Loss: 0.5807 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 7/33, Loss: 0.1692 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 8/33, Loss: 0.1607 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 9/33, Loss: 0.1579 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 10/33, Loss: 0.1544 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 11/33, Loss: 0.5606 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 12/33, Loss: 0.5657 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 13/33, Loss: 0.5594 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 14/33, Loss: 0.1423 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 15/33, Loss: 0.1580 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 16/33, Loss: 0.5335 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 17/33, Loss: 0.5229 Accuracy:1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \t Iter: 18/33, Loss: 0.5096 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 19/33, Loss: 0.1550 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 20/33, Loss: 0.4807 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 21/33, Loss: 0.1528 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 22/33, Loss: 0.1511 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 23/33, Loss: 0.1485 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 24/33, Loss: 0.4309 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 25/33, Loss: 0.4193 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 26/33, Loss: 0.1328 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 27/33, Loss: 0.5853 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 28/33, Loss: 0.3861 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 29/33, Loss: 0.5830 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 30/33, Loss: 0.1340 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 31/33, Loss: 0.1339 Accuracy:1.0000\n",
      "Epoch: 4 \t Iter: 32/33, Loss: 0.1355 Accuracy:1.0000\n",
      "Epoch: 4, Loss: 0.3121\n",
      "Epoch: 4, Test Loss: 0.5619 Test Accuracy 1.0000\n",
      "Epoch: 5 \t Iter: 0/33, Loss: 0.1345 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 1/33, Loss: 0.1328 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 2/33, Loss: 0.1304 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 3/33, Loss: 0.3388 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 4/33, Loss: 0.4116 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 5/33, Loss: 0.1234 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 6/33, Loss: 0.4054 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 7/33, Loss: 0.3256 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 8/33, Loss: 0.1327 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 9/33, Loss: 0.3189 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 10/33, Loss: 0.5201 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 11/33, Loss: 0.3111 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 12/33, Loss: 0.1322 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 13/33, Loss: 0.4990 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 14/33, Loss: 0.1134 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 15/33, Loss: 0.1127 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 16/33, Loss: 0.1114 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 17/33, Loss: 0.1097 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 18/33, Loss: 0.4586 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 19/33, Loss: 0.1327 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 20/33, Loss: 0.1044 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 21/33, Loss: 0.1324 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 22/33, Loss: 0.4262 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 23/33, Loss: 0.0999 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 24/33, Loss: 0.4079 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 25/33, Loss: 0.2987 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 26/33, Loss: 0.0962 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 27/33, Loss: 0.2990 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 28/33, Loss: 0.0939 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 29/33, Loss: 0.2960 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 30/33, Loss: 0.2931 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 31/33, Loss: 0.0906 Accuracy:1.0000\n",
      "Epoch: 5 \t Iter: 32/33, Loss: 0.1340 Accuracy:1.0000\n",
      "Epoch: 5, Loss: 0.2342\n",
      "Epoch: 5, Test Loss: 0.3128 Test Accuracy 1.0000\n",
      "Epoch: 6 \t Iter: 0/33, Loss: 0.0885 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 1/33, Loss: 0.0873 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 2/33, Loss: 0.0858 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 3/33, Loss: 0.1332 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 4/33, Loss: 0.0827 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 5/33, Loss: 0.3515 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 6/33, Loss: 0.2709 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 7/33, Loss: 0.1310 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 8/33, Loss: 0.3438 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 9/33, Loss: 0.2662 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 10/33, Loss: 0.3356 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 11/33, Loss: 0.0764 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 12/33, Loss: 0.2616 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 13/33, Loss: 0.0754 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 14/33, Loss: 0.2571 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 15/33, Loss: 0.0742 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 16/33, Loss: 0.1294 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 17/33, Loss: 0.3109 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 18/33, Loss: 0.2470 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 19/33, Loss: 0.1283 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 20/33, Loss: 0.0718 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 21/33, Loss: 0.0714 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 22/33, Loss: 0.2407 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 23/33, Loss: 0.1249 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 24/33, Loss: 0.2360 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 25/33, Loss: 0.2338 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 26/33, Loss: 0.1211 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 27/33, Loss: 0.2279 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 28/33, Loss: 0.0692 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 29/33, Loss: 0.2211 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 30/33, Loss: 0.2172 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 31/33, Loss: 0.2126 Accuracy:1.0000\n",
      "Epoch: 6 \t Iter: 32/33, Loss: 0.2345 Accuracy:1.0000\n",
      "Epoch: 6, Loss: 0.1824\n",
      "Epoch: 6, Test Loss: 0.2416 Test Accuracy 1.0000\n",
      "Epoch: 7 \t Iter: 0/33, Loss: 0.2034 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 1/33, Loss: 0.2958 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 2/33, Loss: 0.1953 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 3/33, Loss: 0.2928 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 4/33, Loss: 0.0700 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 5/33, Loss: 0.1857 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 6/33, Loss: 0.1124 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 7/33, Loss: 0.1119 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 8/33, Loss: 0.0705 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 9/33, Loss: 0.1097 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 10/33, Loss: 0.1081 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 11/33, Loss: 0.0703 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 12/33, Loss: 0.2426 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 13/33, Loss: 0.2769 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 14/33, Loss: 0.2384 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 15/33, Loss: 0.1010 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 16/33, Loss: 0.1686 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 17/33, Loss: 0.2613 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 18/33, Loss: 0.0700 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 19/33, Loss: 0.0975 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 20/33, Loss: 0.0698 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 21/33, Loss: 0.1666 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 22/33, Loss: 0.0692 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 23/33, Loss: 0.0687 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 24/33, Loss: 0.0935 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 25/33, Loss: 0.2381 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 26/33, Loss: 0.2351 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 27/33, Loss: 0.2306 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 28/33, Loss: 0.2250 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 29/33, Loss: 0.0915 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 30/33, Loss: 0.1678 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 31/33, Loss: 0.1681 Accuracy:1.0000\n",
      "Epoch: 7 \t Iter: 32/33, Loss: 0.0658 Accuracy:1.0000\n",
      "Epoch: 7, Loss: 0.1567\n",
      "Epoch: 7, Test Loss: 0.0656 Test Accuracy 1.0000\n",
      "Epoch: 8 \t Iter: 0/33, Loss: 0.1672 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 1/33, Loss: 0.0903 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 2/33, Loss: 0.0897 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 3/33, Loss: 0.1851 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 4/33, Loss: 0.0653 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 5/33, Loss: 0.1629 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 6/33, Loss: 0.1617 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 7/33, Loss: 0.0861 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 8/33, Loss: 0.1582 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 9/33, Loss: 0.0843 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 10/33, Loss: 0.1541 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 11/33, Loss: 0.1518 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 12/33, Loss: 0.0812 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 13/33, Loss: 0.0800 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 14/33, Loss: 0.1446 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 15/33, Loss: 0.1422 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 16/33, Loss: 0.1952 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 17/33, Loss: 0.1374 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 18/33, Loss: 0.0746 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 19/33, Loss: 0.1329 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 20/33, Loss: 0.0728 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 21/33, Loss: 0.1285 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 22/33, Loss: 0.0676 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 23/33, Loss: 0.0676 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 24/33, Loss: 0.1225 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 25/33, Loss: 0.0672 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 26/33, Loss: 0.1188 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 27/33, Loss: 0.0677 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 28/33, Loss: 0.1152 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 29/33, Loss: 0.1133 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 30/33, Loss: 0.1113 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 31/33, Loss: 0.0657 Accuracy:1.0000\n",
      "Epoch: 8 \t Iter: 32/33, Loss: 0.2131 Accuracy:1.0000\n",
      "Epoch: 8, Loss: 0.1175\n",
      "Epoch: 8, Test Loss: 0.2130 Test Accuracy 1.0000\n",
      "Epoch: 9 \t Iter: 0/33, Loss: 0.0651 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 1/33, Loss: 0.0651 Accuracy:1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \t Iter: 2/33, Loss: 0.2131 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 3/33, Loss: 0.0638 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 4/33, Loss: 0.0632 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 5/33, Loss: 0.1022 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 6/33, Loss: 0.0617 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 7/33, Loss: 0.0608 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 8/33, Loss: 0.2068 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 9/33, Loss: 0.1004 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 10/33, Loss: 0.0999 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 11/33, Loss: 0.0576 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 12/33, Loss: 0.0569 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 13/33, Loss: 0.0560 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 14/33, Loss: 0.0978 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 15/33, Loss: 0.0541 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 16/33, Loss: 0.0658 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 17/33, Loss: 0.1980 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 18/33, Loss: 0.0516 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 19/33, Loss: 0.0658 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 20/33, Loss: 0.1937 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 21/33, Loss: 0.1912 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 22/33, Loss: 0.1469 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 23/33, Loss: 0.1836 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 24/33, Loss: 0.0483 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 25/33, Loss: 0.0661 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 26/33, Loss: 0.0660 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 27/33, Loss: 0.0999 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 28/33, Loss: 0.1002 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 29/33, Loss: 0.0650 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 30/33, Loss: 0.0644 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 31/33, Loss: 0.0464 Accuracy:1.0000\n",
      "Epoch: 9 \t Iter: 32/33, Loss: 0.1396 Accuracy:1.0000\n",
      "Epoch: 9, Loss: 0.0975\n",
      "Epoch: 9, Test Loss: 0.0460 Test Accuracy 1.0000\n"
     ]
    }
   ],
   "source": [
    "# TRAIN NETWORK\n",
    "print (y_train.shape, y_train)\n",
    "print (x_train.shape)\n",
    "if True:\n",
    "    lr_gen = LearningRate(dlc_cfg)\n",
    "    #%%\n",
    "    EPOCHS = 10 # 10000\n",
    "    current_lr = 0.0001\n",
    "    n_batches = max(1, int(x_train.shape[0] / BATCH_SIZE))\n",
    "    #n_batches = 30\n",
    "    print('Training...')\n",
    "    for epoch in range(EPOCHS):\n",
    "        sess.run(train_init_op, feed_dict={x: x_train, \n",
    "                                           y: y_train, \n",
    "                                           batch_size: BATCH_SIZE,\n",
    "                                           learning_rate: current_lr})\n",
    "\n",
    "        tot_loss = 0\n",
    "        for iter in range(n_batches):\n",
    "            _, loss_value, accuracy_value = sess.run([train_op, loss, accuracy],\n",
    "                                                     feed_dict={learning_rate:current_lr})\n",
    "            print(\"Epoch: {} \\t Iter: {}/{}, Loss: {:.4f} Accuracy:{:.4f}\".format(epoch, iter, n_batches, loss_value, accuracy_value))\n",
    "            tot_loss += loss_value\n",
    "\n",
    "            if iter % 100 == 0 or (iter+1 == n_batches):\n",
    "                model_name = 'snapshots/mclass_epoch{}-iter{}-'.format(epoch,iter)\n",
    "                saver.save(sess, model_name, global_step=iter)\n",
    "                if iter +1  == EPOCHS:\n",
    "                    model_name = 'snapshots/mclass_epoch{}-iter{}-final-'.format(epoch,iter)\n",
    "                    saver.save(sess, model_name, global_step=0)\n",
    "\n",
    "        print(\"Epoch: {}, Loss: {:.4f}\".format(epoch, tot_loss / n_batches))\n",
    "        \n",
    "        # initialise iterator with test data\n",
    "        sess.run(test_init_op,\n",
    "                 feed_dict={x: x_test, \n",
    "                            y: y_test, \n",
    "                            batch_size: BATCH_SIZE, \n",
    "                            learning_rate:current_lr})\n",
    "        \n",
    "        print('Epoch: {}, '.format(epoch) + 'Test Loss: {:.4f} Test Accuracy {:.4f}'.format(*sess.run([loss,accuracy])))\n",
    "\n",
    "\n",
    "#sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'accuracy:0' refers to a Tensor which does not exist. The operation, 'accuracy', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6dc68a305257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#image_tensor = detection_graph.get_tensor_by_name(':0')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#scores = detection_graph.get_tensor_by_name('logits2:0')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3652\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[1;32m   3653\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3654\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3518\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   3519\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3520\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   3521\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3522\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'accuracy:0' refers to a Tensor which does not exist. The operation, 'accuracy', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "model_path = \"/home/cat/code/dlc_toolbox/snapshots/mclass_epoch1-iter32--32\"\n",
    "detection_graph = tf.Graph()\n",
    "with tf.Session(graph=detection_graph) as sess:\n",
    "    # Load the graph with the trained states\n",
    "    loader = tf.train.import_meta_graph(model_path+'.meta')\n",
    "    loader.restore(sess, model_path)\n",
    "    \n",
    "    current_graph = tf.compat.v1.get_default_graph()\n",
    "    #for k in current_graph.get_operations():\n",
    "    #    print(k)    \n",
    "\n",
    "    # Get the tensors by their variable name\n",
    "    #image_tensor = detection_graph.get_tensor_by_name(':0')\n",
    "    \n",
    "    boxes = detection_graph.get_tensor_by_name('accuracy:0')\n",
    "    #scores = detection_graph.get_tensor_by_name('logits2:0')\n",
    "    #...\n",
    "    # Make predictions\n",
    "    #_boxes, _scores = sess.run([boxes, scores], \n",
    "    #                           feed_dict={image_tensor: image_np_expanded})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  name: \"make_initializer_1\"\n",
      "op: \"MakeIterator\"\n",
      "input: \"ShuffleDataset_1\"\n",
      "input: \"IteratorV2\"\n",
      "device: \"/device:CPU:0\"\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@IteratorV2\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-cbabf7e9f839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sess.run(test_init_op,\n\u001b[0;32m----> 6\u001b[0;31m                  feed_dict={x: x_test, y: y_test, batch_size: BATCH_SIZE, learning_rate:current_lr})\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# feed_dict={x: x_test[:10]}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "model_path = \"model.ckpt\"\n",
    "detection_graph = tf.Graph()\n",
    "with tf.Session(graph=detection_graph) as sess:\n",
    "    # Load the graph with the trained states\n",
    "    loader = tf.train.import_meta_graph(model_path+'.meta')\n",
    "    loader.restore(sess, model_path)\n",
    "\n",
    "    # Get the tensors by their variable name\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    ...\n",
    "    # Make predictions\n",
    "    _boxes, _scores = sess.run([boxes, scores], feed_dict={image_tensor: image_np_expanded})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Session' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-393d8b2600a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m res = sess.predict(test_init_op,  \n\u001b[0m\u001b[1;32m      2\u001b[0m                feed_dict = feed_dict)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Session' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "res = sess.predict(test_init_op,  \n",
    "               feed_dict = feed_dict)\n",
    "\n",
    "\n",
    "\n",
    "print (out['classes'].shape, out['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name '/home/cat/code/dlc_toolbox/snapshots/mclass_epoch1-iter32--32.data-00000-of-00001' looks like an (invalid) Operation name, not a Tensor. Tensor names must be of the form \"<op_name>:<output_index>\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-aae1ddf1e4cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m##model = graph.get_tensor_by_name('resnet_model/final_dense:0')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#model.predict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'/home/cat/code/dlc_toolbox/snapshots/mclass_epoch1-iter32--32.data-00000-of-00001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#res = sess.run(model, {inputs:img})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3652\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[1;32m   3653\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3654\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3550\u001b[0m         err_msg += (\" Tensor names must be of the form \"\n\u001b[1;32m   3551\u001b[0m                     \"\\\"<op_name>:<output_index>\\\".\")\n\u001b[0;32m-> 3552\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3554\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The name '/home/cat/code/dlc_toolbox/snapshots/mclass_epoch1-iter32--32.data-00000-of-00001' looks like an (invalid) Operation name, not a Tensor. Tensor names must be of the form \"<op_name>:<output_index>\"."
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "#image_batch = x_test[:10]\n",
    "#inputs = tf.image.resize_images(image_batch, [224, 224])\n",
    "#print (inputs.shape)\n",
    "graph = tf.get_default_graph()\n",
    "    \n",
    "feed_dict={x: x_test[:10]}\n",
    "\n",
    "##model = graph.get_tensor_by_name('resnet_model/final_dense:0')\n",
    "#model.predict()\n",
    "model = graph.get_tensor_by_name('/home/cat/code/dlc_toolbox/snapshots/mclass_epoch1-iter32--32.data-00000-of-00001')\n",
    "\n",
    "#res = sess.run(model, {inputs:img})\n",
    "    \n",
    "#res = sess.predict(test_init_op,  \n",
    "#               feed_dict = feed_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess,[\"serve\"], graph_pb_path)\n",
    "    graph = tf.get_default_graph()\n",
    "    inputs = graph.get_tensor_by_name('input_tensor:0')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pose_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-07b82e6917ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpose_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pose\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreuse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pose_net' is not defined"
     ]
    }
   ],
   "source": [
    "# pn = pose_net(dlc_cfg)\n",
    "\n",
    "# net, end_points = pn.extract_features(inputs)\n",
    "# scope = \"pose\"\n",
    "# reuse = None\n",
    "# heads = {}\n",
    "\n",
    "# with tf.variable_scope(scope, reuse=reuse):\n",
    "#     heads[\"part_pred\"] = prediction_layer(\n",
    "#         dlc_cfg, net, \"part_pred\", nj\n",
    "#     )\n",
    "#     heads[\"locref\"] = prediction_layer(\n",
    "#         dlc_cfg, net, \"locref_pred\", nj * 2\n",
    "#     )\n",
    "\n",
    "#     heads[\"pairwise_pred\"] = prediction_layer(\n",
    "#         dlc_cfg, net, \"pairwise_pred\", nl * 2\n",
    "#     )\n",
    "# pred = heads['part_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtest:  (380, 34, 34, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'heads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-46717a0bec56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"xtest: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'part_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'heads' is not defined"
     ]
    }
   ],
   "source": [
    "print (\"xtest: \", x_test.shape)\n",
    "pred = heads['part_pred']\n",
    "\n",
    "feed_dict = {inputs: x_test[0]}\n",
    "res = sess.run([pred], feed_dict=feed_dict)\n",
    "\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# feed to the network\n",
    "feed_dict = {inputs: ff[None, :, :, :]}\n",
    "[pred_s] = sess.run([pred], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3) (10000,) 60 0.0001\n",
      "[3 8 8 ... 5 1 7]\n"
     ]
    }
   ],
   "source": [
    "print (x_test.shape,\n",
    "      y_test.shape,\n",
    "      BATCH_SIZE,\n",
    "      current_lr)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
