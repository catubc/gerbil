{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "#import cv2\n",
    "from tqdm import trange\n",
    "\n",
    "#import glob2\n",
    "\n",
    "#from numba import jit\n",
    "#import tables\n",
    "#from scipy.io import loadmat\n",
    "#import scipy\n",
    "#import h5py\n",
    "#import hdf5storage\n",
    "#import csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " frog   cat  bird  bird\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# initialize a multi-layer CNN\n",
    "net = Net()\n",
    "\n",
    "# check if torch device available;\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "\n",
    "# move CNN to CUDA\n",
    "net.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.216\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[1,  4000] loss: 1.221\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[1,  6000] loss: 1.203\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[1,  8000] loss: 1.236\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[1, 10000] loss: 1.231\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[1, 12000] loss: 1.230\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[2,  2000] loss: 1.214\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[2,  4000] loss: 1.232\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[2,  6000] loss: 1.229\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[2,  8000] loss: 1.241\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[2, 10000] loss: 1.204\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "[2, 12000] loss: 1.223\n",
      "inputs:  torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# TRAIN NETWORK ON TRAINING DATA; \n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        #inputs, labels = data\n",
    "\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            print (\"inputs: \", inputs.shape, labels.shape)\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/cat/cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat   car plane truck\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = dataiter.next()\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "\n",
    "net.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat   dog   car horse\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 54 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        #images, labels = data\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-f08ad528fc69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#images, labels = data[0].to(device), data[1].to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-e398721d8f84>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        #images, labels = data\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = data[0].to(device), data[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default functions\n",
    "        \n",
    "def load_csv(fname):\n",
    "    with open(fname, newline='') as csvfile:\n",
    "        data = list(csv.reader(csvfile))\n",
    "\n",
    "    labels = data[1]\n",
    "    #print (\"data labels: \", labels)\n",
    "    #print (\"column vals: \", data[2])\n",
    "\n",
    "    # load values\n",
    "    data_array = np.array(data[3:])\n",
    "    #print (\"# of datapoints (x,y,likelihood): \", data_array.shape)\n",
    "\n",
    "    # \n",
    "    #labels = ['fnose','f_leye','f_reye','f_lear','f_rear','f_',\n",
    "    #         'male_nose','male_left_ear','male_right_ear','male_base_of_tail',\n",
    "    #          'pup_shaved_nose','pup_shaved_left_ear','pup_shaved_right_ear','pup_shaved_base_of_tail',\n",
    "    #          'pup_noshave_nose','pup_noshave_left_ear','pup_noshave_right_ear','pup_noshave_base_of_tail'             \n",
    "    #         ]\n",
    "    \n",
    "    labels = labels[1:]\n",
    "    \n",
    "    traces = []\n",
    "    traces_nan = []\n",
    "    # zero out low quality DLC values\n",
    "    for idx in range(1,len(labels)-1,3):\n",
    "        #print (\"idx: \", idx)\n",
    "        #print (data_array[1:,idx:idx+3])\n",
    "        #print (data_array[1:,idx:idx+3].shape)\n",
    "\n",
    "        temp = data_array[1:,idx:idx+3]\n",
    "        idx1 = np.where(temp=='')[0]\n",
    "        temp[idx1]=0\n",
    "        temp = temp.astype(np.float)# np.array(temp)\n",
    "        #print (idx, \"TEMP: \", temp.shape)\n",
    "        #temp.replace(\"''\",'0')\n",
    "        \n",
    "\n",
    "        # replace low likelihoods with median\n",
    "        likelihoods = temp[:,2]\n",
    "        idx2 = np.where(likelihoods<0.8)[0]\n",
    "        temp[idx2,0]=np.median(temp[:,0])\n",
    "        temp[idx2,1]=np.median(temp[:,1])\n",
    "        traces.append(temp.copy())\n",
    "        \n",
    "        temp[idx2,0]=np.nan\n",
    "        temp[idx2,1]=np.nan\n",
    "        traces_nan.append(temp.copy())\n",
    "\n",
    "    return traces, labels, traces_nan\n",
    "\n",
    "# function that does search forward steps: \n",
    "def search_forward(data_assembled_fixed,\n",
    "                  traces_inf,\n",
    "                  threshold_p,\n",
    "                  dist_threshold,\n",
    "                  data_assembled_all_features,\n",
    "                  selected_feature,\n",
    "                  comments=False):\n",
    "\n",
    "    # count # of merges\n",
    "    n_merges = 0\n",
    "    \n",
    "    # load traces\n",
    "    tracex = data_assembled_fixed[:,0]\n",
    "    tracey = data_assembled_fixed[:,1]\n",
    "\n",
    "    # find assembled locations with high prob. \n",
    "    probs = data_assembled_fixed[:,2]\n",
    "    idx = np.where(probs>threshold_p)[0]\n",
    "    \n",
    "    # if no values over threshold skip chunk;\n",
    "    if idx.shape[0]==0:\n",
    "        return data_assembled_fixed, data_assembled_all_features\n",
    "    \n",
    "    \n",
    "    if comments:\n",
    "        print (\"data assembled fixed: \", data_assembled_fixed.shape)\n",
    "        print (\"traces inf: \", traces_inf.shape)\n",
    "        print (\"probs: \", probs[:10])\n",
    "        print (\"IDX: \", idx.shape)\n",
    "\n",
    "    # find ends of continous labeled segments\n",
    "    # old method\n",
    "    #diffs = idx[1:]-idx[:-1]\n",
    "    #seg_ends = np.where(diffs>1)[0]\n",
    "    seg_ends=[]\n",
    "    for k in range(idx.shape[0]-1):\n",
    "        if (idx[k+1]-idx[k])>1:\n",
    "            seg_ends.append(k)\n",
    "    # append the last value if it's not at the end of the data\n",
    "    if idx.shape[0]<data_assembled_fixed.shape[0]:\n",
    "        if idx.shape[0]>0:\n",
    "            seg_ends.append(idx.shape[0]-1)\n",
    "    #print (\"idx shape:\" , idx.shape[0], \" tracex: \", tracesx.shape[0])\n",
    "    #print (\"Actual last idx values: \", idx[-1])\n",
    "\n",
    "    seg_ends = np.array(seg_ends)\n",
    "    #print (seg_ends.shape, idx[-1].shape, idx[-1])\n",
    "    # add last segment also\n",
    "    #if idx[-1]!=(tracex.shape[0]-1):\n",
    "    #    seg_ends.append()\n",
    "#     if idx.shape[0]>0:\n",
    "#         seg_ends=np.concatenate((seg_ends, [idx[-1]]),axis=0)\n",
    "    \n",
    "    if comments:\n",
    "        #print (\"diffs[ends]: \", diffs[seg_ends])\n",
    "        if seg_ends.shape[0]>0:\n",
    "            print (seg_ends)\n",
    "            print (\"seg ends: \", idx[seg_ends])\n",
    "\n",
    "    # propagate forward\n",
    "    # loop over all ends of continous segments and search forward for min distances\n",
    "    for l in range(seg_ends.shape[0]):\n",
    "        idx_start = idx[seg_ends[l]]\n",
    "\n",
    "        # initalized with the first starting location;\n",
    "        loc0 = np.array([tracex[idx_start], tracey[idx_start]])\n",
    "\n",
    "        # search forward\n",
    "        idx_next = idx_start+1\n",
    "        if idx_next>=1000:\n",
    "            continue\n",
    "        while True:\n",
    "            if comments:\n",
    "                print (\"idx_current: \", idx_next-1 , \"/\", seg_ends.shape[0],\n",
    "                       \"loc0: \", loc0, \" prob: \", probs[idx_next-1])\n",
    "                print (\"idx_next: \", idx_next , \n",
    "                       \"loc0: \", np.array([tracex[idx_next], tracey[idx_next]]), \" prob: \", probs[idx_next])\n",
    "\n",
    "            # if there is no inference, delete data\n",
    "            if len(traces_inf[idx_next])==0:\n",
    "                break\n",
    "                \n",
    "            loc_candidates = np.vstack(traces_inf[idx_next]).T\n",
    "            if comments:\n",
    "                print (\"loc_candidates: \", loc_candidates)\n",
    "  \n",
    "            # compute distance between previous assembled (true) location and canadidate\n",
    "            dist = (loc_candidates.T - loc0)**2\n",
    "            dist = np.sum(dist, axis=1)\n",
    "            dist = np.sqrt(dist)\n",
    "\n",
    "            # minimum distance is less than threshold, add to assembled animal data;\n",
    "            min_dist = np.min(dist)\n",
    "            arg_min = np.argmin(dist)\n",
    "            if comments:\n",
    "                print (\"Dist: \", min_dist, \" argmin: \", arg_min, \" values; \", loc_candidates.T[arg_min])\n",
    "\n",
    "            if min_dist < dist_threshold:\n",
    "                \n",
    "                # first check if the value has alerady been assigned to an assembled animal;\n",
    "                if comments:\n",
    "                    print (\" CROSS VALUE SEARCH *****************************************************\")\n",
    "                    print (data_assembled_all_features.shape)\n",
    "                    print (\"data assembled all features; \", data_assembled_all_features[:,idx_next,0])\n",
    "                    print (\"best inference candidate: \", loc_candidates[0][arg_min])\n",
    "                    print (np.min(np.abs(data_assembled_all_features[:,idx_next, 0]-loc_candidates[0][arg_min])))\n",
    "\n",
    "                # Chekc if x values are identical between a previously assembled feature and the best inference match\n",
    "                # if so, check if the probability of the assembled feature is above thrshold (ie. >0 as it's already been set to 0)\n",
    "                # and skip it; \n",
    "                # otherwise, do not inherit the label and exit the segment\n",
    "                if np.min(np.abs(data_assembled_all_features[:,idx_next,0]-loc_candidates[0][arg_min]))<1E-5:\n",
    "                    if np.min(np.abs(data_assembled_all_features[:,idx_next,1]-loc_candidates[1][arg_min]))<1E-5:\n",
    "                        argmin_temp = np.argmin(np.abs(data_assembled_all_features[:,idx_next,0]-\n",
    "                                                    loc_candidates[0][arg_min]))\n",
    "                        if data_assembled_all_features[argmin_temp,idx_next,2]>0.0:\n",
    "                            if comments:\n",
    "                                print (\"Infered value belongs to already assbmeld feature\", argmin_temp,\n",
    "                                      \"  with prob: \", data_assembled_all_features[argmin_temp,idx_next,2])\n",
    "                                print (\"data_assembled_all_features[idx_next]: \", data_assembled_all_features.shape)\n",
    "                                print (np.argmin(np.abs(data_assembled_all_features[:,0]-loc_candidates[0][arg_min])))\n",
    "\n",
    "                            break\n",
    "\n",
    "                if comments:\n",
    "                    print (\"replace assembled val at time step: \", idx_next, \" at loc: \", loc0 )\n",
    "                    \n",
    "                loc0 = np.array([loc_candidates[0][arg_min],\n",
    "                                loc_candidates[1][arg_min]])\n",
    "                if comments:\n",
    "\n",
    "                    print (\"      with new location from inference\", loc0)\n",
    "\n",
    "                    print ('data_assembled_fixed[feature][pre]: ', \n",
    "                           data_assembled_fixed[idx_next])\n",
    "\n",
    "                \n",
    "                # fix the data in progress\n",
    "                data_assembled_fixed[idx_next]=np.array([loc0[0],  # set x\n",
    "                                                         loc0[1],  # set y\n",
    "                                                         1.0])     # set probability\n",
    "                # fix master list as well\n",
    "                data_assembled_all_features[selected_feature,idx_next]=np.array([loc0[0],  # set x\n",
    "                                                         loc0[1],  # set y\n",
    "                                                         1.0])     # set probability\n",
    "                \n",
    "                # metadata printing\n",
    "                if comments:\n",
    "                    print ('data_assembled_fixed[feature][post]: ', \n",
    "                       data_assembled_fixed[idx_next])\n",
    "\n",
    "                    print ('')\n",
    "                    \n",
    "                    \n",
    "                idx_next+=1\n",
    "                n_merges+=1\n",
    "                # exit if at end of data\n",
    "                if idx_next>=1000:\n",
    "                    break\n",
    "\n",
    "                # exit if reached a chunk that is labled above accepted probability:\n",
    "                if data_assembled_fixed[idx_next][2]>threshold_p:\n",
    "                    if comments:\n",
    "                        print (\"***** Point has prob > threshold (moving to next discontious segment) *****\")\n",
    "                        print (\"\")\n",
    "                        print (\"\")\n",
    "                        print (\"\")\n",
    "                    break\n",
    "\n",
    "\n",
    "            else: #move to the next continous segment if distance to nearest time point is too far\n",
    "                if comments:\n",
    "                    print (\"***** JUMPING OT NEXT SEG *****\")\n",
    "                    print (\"\")\n",
    "                    print (\"\")\n",
    "                    print (\"\")\n",
    "                break\n",
    "\n",
    "            #return\n",
    "                \n",
    "    print ('********** # OF MERGES: ', n_merges)\n",
    "\n",
    "    # return fixed data\n",
    "    return data_assembled_fixed, data_assembled_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_01_54_23_358257_compressed/2020-3-16_01_54_23_358257_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_02_54_39_170978_compressed/2020-3-16_02_54_39_170978_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_03_57_56_902379_compressed/2020-3-16_03_57_56_902379_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_03 54 54 231226_compressed/2020-3-16_03 54 54 231226_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_04_55_09_841582_compressed/2020-3-16_04_55_09_841582_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_04_58_11_998956_compressed/2020-3-16_04_58_11_998956_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_05 55 25 305681_compressed/2020-3-16_05 55 25 305681_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_05 58 27 193818_compressed/2020-3-16_05 58 27 193818_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_06 55 40 714236_compressed/2020-3-16_06 55 40 714236_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_06 58 43 678014_compressed/2020-3-16_06 58 43 678014_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_07_55_55_775234_compressed/2020-3-16_07_55_55_775234_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_07_59_00_362242_compressed/2020-3-16_07_59_00_362242_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_08_56_11_096689_compressed/2020-3-16_08_56_11_096689_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_08_59_17_534732_compressed/2020-3-16_08_59_17_534732_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_09_59_34_731308_compressed/2020-3-16_09_59_34_731308_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_09 56 26 362091_compressed/2020-3-16_09 56 26 362091_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_10_59_50_448686_compressed/2020-3-16_10_59_50_448686_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_10 56 41 406701_compressed/2020-3-16_10 56 41 406701_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_11_56_56_704655_compressed/2020-3-16_11_56_56_704655_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_12 57 12 418305_compressed/2020-3-16_12 57 12 418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_02 57 41 995158_compressed/2020-3-16_02 57 41 995158_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle',\n",
    "'/mnt/adfe6e7b-b77b-4731-bc9e-e639667faba4/madeline/march_2/march_16/2020-3-16_01_57_27_327194_compressed/2020-3-16_01_57_27_327194_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/pickle/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing : /media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/pickle/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89989/89989 [00:11<00:00, 7773.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89989, 14)\n",
      " traces_inferences [n_frames, #_non_unique_featres]:  (89989, 14)\n"
     ]
    }
   ],
   "source": [
    "# LOAD INFERENCE DATA from full_pickle files and convert to  .npy file\n",
    "end = None\n",
    "#end = 1000\n",
    "for full_pickle in fnames:\n",
    "    print (\"processing :\", full_pickle)\n",
    "    # convert full pickel file to simpler data structure\n",
    "    fname_out = full_pickle[:-7]+\"_traces_inferences.npy\"\n",
    "    if os.path.exists(fname_out)==False:\n",
    "        from deeplabcut.pose_estimation_tensorflow.lib.inferenceutils import (\n",
    "                convertdetectiondict2listoflist)\n",
    "        import pickle, re\n",
    "        # load pickle and \n",
    "        with open(full_pickle, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "        header = data.pop(\"metadata\")\n",
    "        all_jointnames = header[\"all_joints_names\"]\n",
    "\n",
    "        #if displayedbodyparts == \"all\":\n",
    "        if True:\n",
    "            numjoints = len(all_jointnames)\n",
    "            bpts = range(numjoints)\n",
    "\n",
    "        frame_names = list(data)\n",
    "        frames = [int(re.findall(r\"\\d+\", name)[0]) for name in frame_names]\n",
    "\n",
    "        # Convert inference locations to an easier array to parse\n",
    "\n",
    "        traces_inferences = []\n",
    "        ctr=0\n",
    "        start = 0\n",
    "        if end is None:\n",
    "            end = len(frame_names)\n",
    "\n",
    "        for n in trange(start, end, 1):\n",
    "            #ind = n\n",
    "            #print (n, frame_names[n])\n",
    "            #print (data)\n",
    "            # load inference locations\n",
    "            traces_inferences.append([])\n",
    "            dets = convertdetectiondict2listoflist(data[frame_names[n]], bpts)\n",
    "            for i, det in enumerate(dets):\n",
    "                traces_inferences[ctr].append([])\n",
    "                for x, y, p, _ in det:\n",
    "                    traces_inferences[ctr][i].append([x,y])\n",
    "\n",
    "            ctr+=1\n",
    "        traces_inferences = np.array(traces_inferences)\n",
    "        print (traces_inferences.shape)\n",
    "\n",
    "        np.save(fname_out, traces_inferences)\n",
    "\n",
    "    else:\n",
    "        traces_inferences = np.load(fname_out, allow_pickle=True)\n",
    "    print (\" traces_inferences [n_frames, #_non_unique_featres]: \", traces_inferences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " traces_inferences [n_frames, #_non_unique_featres]:  (89988, 14)\n"
     ]
    }
   ],
   "source": [
    "fname_out = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npy'\n",
    "traces_inferences = np.load(fname_out, allow_pickle=True)\n",
    "print (\" traces_inferences [n_frames, #_non_unique_featres]: \", traces_inferences.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# #########################################################\n",
    "# ############## CONNECTED COMPONENTS SOLUTION ############\n",
    "# #########################################################\n",
    "# #########################################################\n",
    "\n",
    "#for fname in fnames:\n",
    "def connected_components_function(fname_in,\n",
    "                                 ctr_comments,\n",
    "                                 network_history,\n",
    "                                 min_network,\n",
    "                                 n_networks,\n",
    "                                 start,\n",
    "                                 end):\n",
    "    fname_in = fname_in[:-7]+\"_traces_inferences.npy\"\n",
    "    traces_inferences = np.load(fname_in, allow_pickle=True)\n",
    "    print (\" traces_inferences [n_frames, #_non_unique_featres]: \", traces_inferences.shape)\n",
    "    print (fname_in)\n",
    "\n",
    "    fname_out = fname_in[:-4]+'.npz'\n",
    "\n",
    "    #[start:end,feature]\n",
    "    labels = []\n",
    "#     kmeans_start = 0\n",
    "#     kmeans_end = traces_inferences.shape[0]\n",
    "\n",
    "\n",
    "    # ##########################################################\n",
    "    # ################### PARAMETER LISTS ######################\n",
    "    # ##########################################################\n",
    "    #min_network = 5  # min length of segs to connect\n",
    "    #n_networks = 4 # essentially Number of animals that are matched to a graph\n",
    "    #network_history = 30\n",
    "\n",
    "    max_dist_between_features = 125 # connected componennts max distances allowed between sequential features\n",
    "    min_dist_chunks = 200 # min distance between matching history\n",
    "    \n",
    "    # THIS IS TRICKY: if block labeled, tough to jump \n",
    "    max_network_jump = 400 # maximum amount an animal id (centre) can move in a single frame \n",
    "    \n",
    "    \n",
    "    max_dist_merge_networks_cc = 75 # post-cc step to fix oversplits; searches cnetres of two networks\n",
    "                                     # with non-overlapping features and merges them\n",
    "\n",
    "    # otehr params\n",
    "    min_n_matches_history_override = 4 # this parameter indicates if x feature-wise\n",
    "                                       # very close matches in previous history\n",
    "                                       # will override the centres-based history tracker\n",
    "\n",
    "    # ##########################################################\n",
    "    # ################## FRAME LOOP START#######################\n",
    "    # ##########################################################\n",
    "    comments = False\n",
    "\n",
    "    labels_array = []\n",
    "    features_array = []\n",
    "    ctr=0\n",
    "    historical_centres = np.zeros((network_history,n_networks,2))\n",
    "    # loop over frames\n",
    "    #ctr_comments =[]\n",
    "    for k in range(start, end):\n",
    "\n",
    "        if ctr in ctr_comments:\n",
    "            comments=True\n",
    "        else:\n",
    "            comments=False\n",
    "\n",
    "        if True:\n",
    "            if k%1000==0:\n",
    "                print (\"FRAME: \", k)\n",
    "\n",
    "        # make label array\n",
    "        labels_array.append([])\n",
    "        features_array.append([])\n",
    "\n",
    "        # LOAD DATA FROM INFERENCE STEP\n",
    "        flat_list = []\n",
    "        list_idx = []\n",
    "        for n, sublist in enumerate(traces_inferences[k]):\n",
    "            list_idx.extend(np.zeros(len(sublist),'int32')+n)\n",
    "            for item in sublist:\n",
    "                flat_list.append(item)\n",
    "\n",
    "        #print (flat_list)\n",
    "        locs = np.vstack(flat_list).copy()\n",
    "        list_idx = np.array(list_idx)\n",
    "\n",
    "\n",
    "        # ####################################################################################\n",
    "        # ####################################################################################\n",
    "        # ########################### CONNECTED COMPONENTS ###################################\n",
    "        # ####################################################################################\n",
    "        # ####################################################################################\n",
    "        # loop over features and build graphs:\n",
    "        # find nearest next feature to the selected feature and connect them:\n",
    "        cc = []\n",
    "        cc2 = np.zeros((list_idx.shape[0],list_idx.shape[0]),'int32')\n",
    "        # loop over each group of features in the dataset \n",
    "        for feature in range(np.unique(list_idx).shape[0]-1):\n",
    "            idx = np.where(list_idx==feature)[0]\n",
    "            locs_feat_current = locs[idx]\n",
    "\n",
    "            # grab all features in the next step of hierarchy and mathc to previous hierarchy features;\n",
    "            for qq in range(feature+1,feature+2):\n",
    "                idx_next = np.where(list_idx==qq)[0]\n",
    "                locs_next = locs[idx_next]\n",
    "\n",
    "                if locs_next.shape[0]==0:\n",
    "                    continue\n",
    "\n",
    "                # Compute shortest distance between the current features and the next step features\n",
    "                dists = []\n",
    "                argmins = []\n",
    "                for p in range(locs_feat_current.shape[0]):\n",
    "                    loc_ = locs_feat_current[p]\n",
    "\n",
    "                    vect = locs_next-loc_\n",
    "                    min_dist = np.min(scipy.spatial.distance.cdist(vect*0, vect))\n",
    "                    argmin = np.argmin(scipy.spatial.distance.cdist(vect*0, vect))\n",
    "                    dists.append(min_dist)\n",
    "                    argmins.append(argmin)\n",
    "\n",
    "                # ranked by distance\n",
    "                dists = np.array(dists)\n",
    "                argmins = np.array(argmins)\n",
    "                idx_sort = np.argsort(dists)\n",
    "\n",
    "                for p in range(idx_sort.shape[0]):\n",
    "                    # load sorted data\n",
    "                    min_dist = dists[idx_sort[p]]\n",
    "                    argmin = argmins[idx_sort[p]]\n",
    "\n",
    "                    if min_dist<max_dist_between_features:\n",
    "                        # check to ensure the same type of feature doesn't already exist in the dataset:\n",
    "                        # actually need to check if any of the other parts are connected, not just the previous most recent part?! \n",
    "                        # idx here is all the locations of current hierarchy features\n",
    "                        if np.any(cc2[idx,idx_next[argmin]]):\n",
    "                            if comments: \n",
    "                                print(\"feature already connected to other parts; skipping\")\n",
    "                            continue\n",
    "                        #cc.append([idx[p], idx_next[argmin]])\n",
    "                        cc2[idx[idx_sort[p]], idx_next[argmin]]=1\n",
    "\n",
    "\n",
    "        graph=np.array(cc2)\n",
    "        graph = csr_matrix(graph)\n",
    "\n",
    "\n",
    "        n_components, labels_all = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
    "        #print (n_components)\n",
    "\n",
    "        # find all unique network ids; labels_unique[0] - ids;  labels_unique[1] is counts\n",
    "        labels_unique = np.unique(labels_all, return_counts=True)\n",
    "\n",
    "        # keep only networks over min_network size;\n",
    "        idx_nets = np.where(labels_unique[1]>=min_network)[0]\n",
    "        labels_kept = labels_unique[0][idx_nets]\n",
    "\n",
    "        # order the networks by size and keep only to n_networks\n",
    "        idx_ordered = np.argsort(labels_unique[1][idx_nets])[::-1]\n",
    "        labels_kept = labels_kept[idx_ordered][:n_networks]\n",
    "        if comments:\n",
    "            print (\"idx_networks kept:\", idx_nets)\n",
    "            print (\"labels kept: \", labels_kept)\n",
    "            print (\" size of networks kept: \", labels_unique[1][idx_nets][idx_ordered][:n_networks])\n",
    "\n",
    "            for p in np.unique(labels_kept):\n",
    "                idx = np.where(labels_all==p)[0]\n",
    "                locs_network = locs[idx]\n",
    "                print (\"network :\", p, locs_network)\n",
    "                print ('size of network ', locs_network.shape)\n",
    "                print (\" feature types; \", list_idx[idx])\n",
    "            print (\"\")\n",
    "\n",
    "        # final cc check for oversplit clusters:\n",
    "        # note: This should be done in the CC matrix step, but can't seem to get it to work in full\n",
    "        labels_kept_temp = labels_kept.copy()\n",
    "        for p in np.unique(labels_kept):\n",
    "            idx1 = np.where(labels_all==p)[0]\n",
    "            features1 = list_idx[idx1]\n",
    "            locs_network1 = locs[idx1]\n",
    "\n",
    "            if idx1.shape[0]==0:\n",
    "                continue\n",
    "\n",
    "            for pp in np.unique(labels_kept):\n",
    "                if pp==p:\n",
    "                    continue\n",
    "                idx2 = np.where(labels_all==pp)[0]\n",
    "                if idx2.shape[0]==0:\n",
    "                    continue\n",
    "\n",
    "                features2 = list_idx[idx2]\n",
    "                locs_network2 = locs[idx2]\n",
    "\n",
    "                # check if nonoveralpping features\n",
    "                if np.any(np.isin(features1,features2))==False:\n",
    "\n",
    "                    # chekc if very close in distance\n",
    "    #                 vect = labels_array[ctr-1][z]-locs_feature\n",
    "    #                 min_dist = np.min(scipy.spatial.distance.cdist(vect*0, vect))\n",
    "                    dists = scipy.spatial.distance.cdist(locs_network1, locs_network2)\n",
    "                    if comments:\n",
    "                        print (\"dists between nonvoeralpping networks: \", dists)\n",
    "\n",
    "                    # merge bits\n",
    "                    if np.min(dists)<max_dist_merge_networks_cc:\n",
    "\n",
    "                        # change labels_all and labels_kept\n",
    "                        labels_all[idx2] = p\n",
    "                        idx_del = np.where(labels_kept_temp==pp)[0]\n",
    "                        labels_kept_temp = np.delete(labels_kept_temp, idx_del)\n",
    "\n",
    "                        if comments:\n",
    "                            print (\"merged networks: \", p, \" and \", pp, \" at idx: \", idx_del)\n",
    "\n",
    "\n",
    "        labels_kept = labels_kept_temp\n",
    "        #print (\"LABELS post cc: \", labels)\n",
    "\n",
    "        # ####################################################################################\n",
    "        # ####################################################################################\n",
    "        # ########################### FRAME LOOP ANALYSIS ####################################\n",
    "        # ####################################################################################\n",
    "        # ####################################################################################\n",
    "        # save previous centres to match them and overwrite below\n",
    "        # loop over all network components\n",
    "        if ctr>0:\n",
    "            # make large list to hold ftuure labels\n",
    "    #        features_list = [\n",
    "            for p in range(n_networks):\n",
    "                labels_array[ctr].append([])\n",
    "                features_array[ctr].append([])\n",
    "\n",
    "            # keep track of the matches with previous chunks\n",
    "            previous_centres = historical_centres.copy() #[0,p]=np.mean(locs_network,0))\n",
    "\n",
    "            if comments:\n",
    "                print (\"previous centres: \", previous_centres.shape)\n",
    "            #break\n",
    "\n",
    "            idx_matches = []\n",
    "            idx_matches_p = []\n",
    "\n",
    "\n",
    "            # ####################################################################################\n",
    "            # ########################### COMPUTE DISTANCES TO PREVIOUS FRAME ####################\n",
    "            # ####################################################################################\n",
    "\n",
    "            # search for current network chunk for nearest previous chunk\n",
    "            # count the number of matches between current network centre and history:\n",
    "            n_matches_history = np.zeros((labels_kept.shape[0], previous_centres.shape[1]),'int32')\n",
    "            total_dist = np.zeros((labels_kept.shape[0],previous_centres.shape[1]),'float32') \n",
    "\n",
    "            # new method checks averages\n",
    "            # and also whether min_network closest matches to the previous immediate vals;\n",
    "            # If option 2 is very close it overrides all other matches. \n",
    "            for ctr_p, p in enumerate(np.unique(labels_kept)):\n",
    "                idx = np.where(labels_all==p)[0]\n",
    "                locs_network = locs[idx]\n",
    "\n",
    "                # compute cntre:\n",
    "                centre_network = np.median(locs_network,0)\n",
    "                if comments:\n",
    "                    print (\"centre network\", p, centre_network)\n",
    "                    print (\" doing feature-wise heuristic search at prev step: \")\n",
    "                    #print (\"      Previous time step data\", labels_array[ctr-1])\n",
    "                    #print (\"      current network: \", locs_network)\n",
    "                # also quick check if the previous steps had values very close to current \n",
    "                # loop over current network values and find shortest 5 distances:\n",
    "                min_dist_count = np.zeros(n_networks, 'int32')\n",
    "                for zz in range(locs_network.shape[0]):\n",
    "                    locs_feature = locs_network[zz]\n",
    "                    if comments:\n",
    "                        print (\"search for close feature to \", locs_feature)\n",
    "                        #if comments:\n",
    "\n",
    "                    #min_dist_count = 0\n",
    "                    for z in range(len(labels_array[ctr-1])):\n",
    "                        temp_temp = labels_array[ctr-1][z]\n",
    "                        if len(labels_array[ctr-1][z])==0:\n",
    "                            continue\n",
    "                        vect = labels_array[ctr-1][z]-locs_feature\n",
    "                        min_dist = np.min(scipy.spatial.distance.cdist(vect*0, vect))\n",
    "                        #print (\"min dist: \", min_dist)\n",
    "                        if min_dist < min_n_matches_history_override:\n",
    "                            min_dist_count[z]+=1\n",
    "\n",
    "                # if sufficient matches no need to compute and check centres\n",
    "                max_nearest = np.max(min_dist_count)\n",
    "                if max_nearest > 5:\n",
    "                    argmax_overwrite = np.argmax(min_dist_count)\n",
    "                    #n_matches_history[:,argmax_overwrite]-=100  # ensure the previous neetwork can only be matched to the current one\n",
    "                                                      # by starting/biasing the match count for the rest of the matches;\n",
    "                                                      # can also do this other ways\n",
    "                    n_matches_history[ctr_p,argmax_overwrite]+=1E5\n",
    "                    total_dist[ctr_p,argmax_overwrite]=0 #previous_c\n",
    "\n",
    "                    if comments:\n",
    "                        print (\"nearly similar network at previous time step; \")\n",
    "                        print (\" Min dist array: \", min_dist_count)\n",
    "                        print (\"         matching to prev network using argmax: \", argmax_overwrite)\n",
    "                        print (\"         current locs \", locs_network)\n",
    "                        print (\"         previous matched network: \", labels_array[ctr-1][argmax_overwrite])\n",
    "\n",
    "                else:\n",
    "                    # loop over each previous network\n",
    "                    for z in range(previous_centres.shape[1]):\n",
    "\n",
    "                        # loop over each previous history point: find how many historical matches it has\n",
    "                        for h in range(previous_centres[:,z].shape[0]):\n",
    "\n",
    "                            # May wish to implement an L1 not L2 distance \n",
    "                            # OR an individual feature distance rather than mean\n",
    "                            # OR find median xy point and use that as centre;\n",
    "                            #if True:\n",
    "                            vect = previous_centres[h,z]-centre_network\n",
    "                            min_dist = np.min(np.linalg.norm(vect))\n",
    "                            #print (\"VECT: \", vect, \" Min dist: \", min_dist)\n",
    "                            #min_dist = np.min(scipy.spatial.distance.cdist(vect*0, vect))\n",
    "                            if min_dist<min_dist_chunks:\n",
    "                                n_matches_history[ctr_p][z]+=1\n",
    "                                total_dist[ctr_p][z]+=min_dist #previous_centres[:,z].shape[0]-h)/previous_centres[:,z].shape[0])\n",
    "                                #total_dist[z]+=min_dist*((previous_centres[:,z].shape[0]-h)/previous_centres[:,z].shape[0])\n",
    "\n",
    "                                if comments:\n",
    "                                    print (z,h,\"adding dist: \", min_dist)\n",
    "\n",
    "            # check best matches from history\n",
    "            for ctr_p, p in enumerate(np.unique(labels_kept)):\n",
    "                idx = np.where(labels_all==p)[0]\n",
    "                locs_network = locs[idx]\n",
    "\n",
    "                if comments:\n",
    "                    print (\"\")\n",
    "                    print (\"animal:\", ctr_p, \"n_mathces_history:\", n_matches_history[ctr_p])\n",
    "                    print (\"locs: \", locs_network)\n",
    "\n",
    "                # Loop to ensure no better match found for a previous animal ID        \n",
    "                while True:\n",
    "                    argmax = np.argmax(n_matches_history[ctr_p])\n",
    "                    if comments:\n",
    "                        print (\"curretn best match for current locs network: \", locs_network)\n",
    "                        print (\"   is prev network: \", labels_array[ctr-1][argmax])\n",
    "\n",
    "                    if n_matches_history[ctr_p,argmax]==0:\n",
    "                        break\n",
    "\n",
    "                    # ensure no boetter match was found for the current val\n",
    "                    n_matches_all_column = n_matches_history[:,argmax]\n",
    "                    if np.max(n_matches_all_column)>n_matches_history[ctr_p,argmax]:\n",
    "\n",
    "                        argmax_col = np.argmax(n_matches_all_column)\n",
    "\n",
    "                        # check also distances for better fit:\n",
    "                        current_dist = total_dist[ctr_p][argmax]/n_matches_history[ctr_p][argmax]\n",
    "                        alternative_match_dist = total_dist[argmax_col][argmax]/n_matches_history[argmax_col][argmax]\n",
    "\n",
    "                        if comments:\n",
    "                            print (\" current dist: \", current_dist)\n",
    "                            print (\" alternative dist: \", alternative_match_dist)\n",
    "                        \n",
    "                        #if False:\n",
    "                        if alternative_match_dist< current_dist:\n",
    "\n",
    "                            n_matches_history[ctr_p, argmax]=0\n",
    "                            if comments: \n",
    "                                print (\" FOUND BETTER MACH WITH ANOTHER ANIMAL, setting argmax to zoer\")\n",
    "                        else:\n",
    "                            break\n",
    "                        #else:\n",
    "                        #    break\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "\n",
    "                # check case when more than 1 animal within merging distance and pick closest\n",
    "                max_count = n_matches_history[ctr_p][argmax]\n",
    "                if comments:\n",
    "                    print (\" argmax in match history: \", argmax)\n",
    "                    print ('               max count: ', max_count)\n",
    "\n",
    "                # check if more than one match for new network\n",
    "                # may wish to take all matches > 15 or max\n",
    "\n",
    "                idx11 = np.where(n_matches_history[ctr_p]==max_count)[0]\n",
    "                if (idx11.shape[0]>1) and max_count>0:\n",
    "\n",
    "                    # find what the averate distance between each matched history and the new frame are and \n",
    "                    # take the shortest average distance\n",
    "                    # check all the matches that had same amount as idx11\n",
    "                    match_means = total_dist[ctr_p][idx11]/n_matches_history[ctr_p][idx11]\n",
    "                    argmin_match = np.argmin(match_means)\n",
    "                    argmax = idx11[argmin_match]\n",
    "                    min_dist_found = match_means[argmin_match]\n",
    "\n",
    "                    if comments:\n",
    "                        print (\"DUPLICATE MATCHES: so looking at distances: \", total_dist[ctr_p][idx11])\n",
    "                        print (\"Original min distance found: \", min_dist_found)\n",
    "                        print (\"Average distancesL\", match_means, \" of argmin: \", argmin_match)\n",
    "                        print (\"total dists: \", total_dist[ctr_p])\n",
    "\n",
    "                    # check if matched network doesn't actually have even closer match:\n",
    "                    # so search in the column of the original best match to see if it has a better match\n",
    "                    idx13 = np.where(n_matches_history[:,argmax]==max_count)[0]\n",
    "                    match_means_network_match = total_dist[:,argmax][idx13]/n_matches_history[:,argmax][idx13]\n",
    "                    argmin_match_near = np.argmin(match_means_network_match)\n",
    "                    if match_means_network_match[argmin_match_near]<min_dist_found:\n",
    "\n",
    "                        # set the distance for the previous best match to very large value\n",
    "                        total_dist[ctr_p][argmax] = 1E10\n",
    "\n",
    "                        # recompute the argmax    \n",
    "                        match_means = total_dist[ctr_p][idx11]/n_matches_history[ctr_p][idx11]\n",
    "                        argmin_match = np.argmin(match_means)\n",
    "                        argmax = idx11[argmin_match]\n",
    "                        min_dist_found = match_means[argmin_match]\n",
    "\n",
    "                        if comments:\n",
    "                            print (\"BETTER MATCH WAS FOUND\", argmin_match)\n",
    "                            print (\"new min distance found: \", min_dist_found)\n",
    "\n",
    "\n",
    "                        #else:\n",
    "                        #    break\n",
    "                    else:\n",
    "                        if comments:\n",
    "                            print (\"NO BETTER MATCH FOUND\")\n",
    "\n",
    "                # check also to see if networked matched on centre-based distance doesn't actually ahve a better match via\n",
    "                #   feature-based matching with another dataset;\n",
    "                n_matches_all_column = n_matches_history[:,argmax]\n",
    "                if np.max(n_matches_all_column)>n_matches_history[ctr_p,argmax]:\n",
    "                    if comments:\n",
    "                        print (\"  Matches in columN: \", n_matches_all_column)\n",
    "                        print (\"     ARE GREATER THAN BEST Centre based match: \", n_matches_history)\n",
    "                        print (\"  ***************************************\")\n",
    "\n",
    "                # ############################################################ \n",
    "                # ######################## SAVE MATCH DATA ################### \n",
    "                # ############################################################ \n",
    "                if n_matches_history[ctr_p][argmax]>0:\n",
    "                    # replace locations of previous match \n",
    "                    idx_matches.append(argmax)\n",
    "                    idx_matches_p.append(p)\n",
    "                    if comments:\n",
    "                        print (\"Matched to previous centre: \", argmax)\n",
    "                        print (\"final argmax: \", argmax)\n",
    "                        print (\"locs current network:\", locs_network)\n",
    "                        print (\"to be inserted near previous network: \", labels_array[ctr-1][argmax])\n",
    "\n",
    "                # add it as a new tracklet\n",
    "                else:\n",
    "                    idx_matches.append(None)\n",
    "                    idx_matches_p.append(p)\n",
    "\n",
    "                # zero out the better match in this column\n",
    "                total_dist[:,argmax]=1E10\n",
    "                n_matches_history[:,argmax] = 0\n",
    "\n",
    "            # ############################################################\n",
    "            # ############################################################\n",
    "            # ############### INSERT THE MATCHED DATA ####################\n",
    "            # ############################################################\n",
    "            # ############################################################\n",
    "            if comments:\n",
    "                print(\"\")\n",
    "                print(\"FINAL NETWORK INSERTION STEP\")\n",
    "\n",
    "            # loop over the matched ids\n",
    "            for p in range(len(idx_matches)):\n",
    "                idx = np.where(labels_all==idx_matches_p[p])[0]\n",
    "                locs_network = locs[idx]\n",
    "                feature_types = list_idx[idx]\n",
    "                if comments:\n",
    "                    print (\"idx_matches[p]:\", idx_matches[p])\n",
    "\n",
    "                if idx_matches[p] is not None:\n",
    "\n",
    "                    # do a final check to make sure neighbouring timestep networks aren't super-far apart\n",
    "                    centre_prev_network = np.median(labels_array[ctr-1][idx_matches[p]],0)\n",
    "                    centre_current_network = np.median(locs_network,0)\n",
    "                    vect = centre_prev_network-centre_current_network\n",
    "                    dist_centre = np.linalg.norm(vect)\n",
    "                    if comments:\n",
    "                        print (\"   FINAL CHECK DISTANCE BETWEEN PREVIOUS AND CURRENT CENTRE\",\n",
    "                              \"  vect\" , vect,\n",
    "                              \"  dist: \", dist_centre)\n",
    "                    if dist_centre>=max_network_jump:\n",
    "                        if comments:\n",
    "                            print (\" SKIPPED NETWORK DUE TO LARGE JUMP!\")\n",
    "                    else:\n",
    "                        labels_array[ctr][idx_matches[p]]=locs_network\n",
    "                        features_array[ctr][idx_matches[p]]=feature_types\n",
    "\n",
    "                        if comments:\n",
    "                            print (\"\")\n",
    "                            print (\"inserted: \", locs_network)\n",
    "                            print (\" at location: \", idx_matches[p])\n",
    "                            print (\"ctr-1 values at this location: \",idx_matches[p],\n",
    "                                   \" has values: \",\n",
    "                                   labels_array[ctr-1][idx_matches[p]])\n",
    "                else:\n",
    "                    if comments:\n",
    "                        print (\"network doesn't have match: \", locs_network)\n",
    "\n",
    "            # ############################################################\n",
    "            # ############################################################\n",
    "            # ############### REVIEW UNMATCHED DATA ####################\n",
    "            # ############################################################\n",
    "            # ############################################################           \n",
    "            ctr_inner=0\n",
    "            for p in range(len(idx_matches)):\n",
    "                if idx_matches[p] is None:\n",
    "                    idx = np.where(labels_all==idx_matches_p[p])[0]\n",
    "                    feature_types = list_idx[idx]\n",
    "                    locs_network = locs[idx]\n",
    "                    if comments:\n",
    "                        print (\"Inserting missed network to end:\", locs_network)\n",
    "                    # search for an empty list to populate\n",
    "                    while True:\n",
    "                        # find the first empty location to insert data\n",
    "                        if len(labels_array[ctr][ctr_inner])==0:\n",
    "\n",
    "                            # do a final check to make sure neighbouring timestep networks aren't super-far apart\n",
    "                            if len(labels_array[ctr-1][ctr_inner])==0:\n",
    "                                centre_prev_network=np.array((1E10,1E10))\n",
    "                            else:\n",
    "                                centre_prev_network = np.median(labels_array[ctr-1][ctr_inner],0)\n",
    "                            \n",
    "                            vect = centre_prev_network-centre_current_network\n",
    "                            dist_centre = np.linalg.norm(vect)\n",
    "                            if comments:\n",
    "                                print (\"   FINAL CHECK DISTANCE BETWEEN PREVIOUS AND CURRENT CENTRE\",\n",
    "                                      \"  vect\" , vect,\n",
    "                                      \"  dist: \", dist_centre)\n",
    "                            if dist_centre>=max_network_jump:\n",
    "                                if comments:\n",
    "                                    print (\" SKIPPED NETWORK DUE TO LARGE JUMP!\")\n",
    "\n",
    "                                # exit and skip this segment altogether\n",
    "                                break\n",
    "\n",
    "                            else:\n",
    "                                labels_array[ctr][ctr_inner]=locs_network\n",
    "                                features_array[ctr][ctr_inner]=feature_types\n",
    "                                ctr_inner+=1\n",
    "                                break\n",
    "                        ctr_inner+=1\n",
    "\n",
    "            # add centres to \n",
    "\n",
    "            historical_centres[1:]=historical_centres[:-1] #[0,p]=np.mean(locs_network,0))\n",
    "            for pp in range(len(labels_array[ctr])):\n",
    "                if len(labels_array[ctr][pp])==0:\n",
    "                    continue\n",
    "                locs_new = labels_array[ctr][pp]\n",
    "                centres_new = np.median(locs_new,0)\n",
    "                if comments:\n",
    "                    print (\"centres new\", pp, centres_new)\n",
    "                #historical_centres[0,pp]=centres_new\n",
    "                historical_centres[0,pp]=centres_new\n",
    "\n",
    "\n",
    "            if comments:\n",
    "                print (k, \" FINAL labels array: \", labels_array[ctr])\n",
    "\n",
    "        # for first time point\n",
    "        else:\n",
    "            for k in range(n_networks):\n",
    "                labels_array[ctr].append([])\n",
    "                features_array[ctr].append([])\n",
    "\n",
    "            for n, p in enumerate(np.unique(labels_kept)):\n",
    "                idx = np.where(labels_all==p)[0]\n",
    "                locs_network = locs[idx]\n",
    "                feature_types = list_idx[idx]\n",
    "\n",
    "                #print (\"locs network\", locs_network)\n",
    "                labels_array[ctr][n]=locs_network\n",
    "                features_array[ctr][n]=feature_types\n",
    "\n",
    "                # fill the entire history with starting locations:\n",
    "                historical_centres[:,n]=np.median(locs_network,0)\n",
    "\n",
    "            if comments:\n",
    "                print (\"FIRST saved labels array: \", labels_array)\n",
    "    #             break\n",
    "    #         break\n",
    "    #     break\n",
    "\n",
    "        ctr+=1   \n",
    "        #print (\"\")\n",
    "        #print (\"\")\n",
    "\n",
    "    # convert the output to a rectangular matrix with correct locations for data;\n",
    "    final_features = np.zeros((n_networks*14, len(labels_array),2), 'float32')\n",
    "    print (\"Final eatures; \", final_features.shape)\n",
    "    for k in range(len(labels_array)):\n",
    "        if k%1000==0:\n",
    "            print (k)\n",
    "        for p in range(len(labels_array[k])):\n",
    "            #for l in range(len(labels_array[k][p])):\n",
    "                #print (data[k][p][l])\n",
    "            label_locs = features_array[k][p]\n",
    "            if len(label_locs)>0:\n",
    "                #print (k, p, label_locs)\n",
    "                final_features[label_locs+p*14,k]=labels_array[k][p]\n",
    "\n",
    "    tracesx = final_features[:,:,0]\n",
    "    tracesy = final_features[:,:,1]\n",
    "    probs = np.ones(tracesy.shape, 'float32')\n",
    "    print (\"SAVING:to file: \", fname_out)\n",
    "    np.savez(fname_out,\n",
    "            tracesx=tracesx,\n",
    "            tracesy=tracesy,\n",
    "            probs =probs\n",
    "            )    \n",
    "    \n",
    "    \n",
    "\n",
    "# if True:\n",
    "#     import parmap\n",
    "#     parmap.map(connected_components_function, fnames,\n",
    "#               pm_processes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make inference traces arrays from Anqi's data\n",
    "# fname = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/markers/markers'\n",
    "\n",
    "# inferences = []\n",
    "# for k in range(14):\n",
    "#     fname_temp = fname + str(k)+'.npy'\n",
    "#     temp = np.load(fname_temp)\n",
    "#     inferences.append(temp)\n",
    "# inferences=np.array(inferences).transpose(1,0,2,3)\n",
    "# print (inferences.shape)\n",
    "\n",
    "# np.save('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/markers/markers_inferences_traces.npy', inferences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " traces_inferences [n_frames, #_non_unique_featres]:  (89989, 14)\n",
      "/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/pickle/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature already connected to other parts; skipping\n",
      "feature already connected to other parts; skipping\n",
      "feature already connected to other parts; skipping\n",
      "feature already connected to other parts; skipping\n",
      "feature already connected to other parts; skipping\n",
      "idx_networks kept: [0 3 5 6 7]\n",
      "labels kept:  [0 6 7 5 3]\n",
      " size of networks kept:  [14  9  8  6  5]\n",
      "network : 0 [[916.445 171.816]\n",
      " [893.195 191.795]\n",
      " [921.79  197.864]\n",
      " [882.773 212.324]\n",
      " [916.359 226.673]\n",
      " [892.261 235.695]\n",
      " [898.336 252.904]\n",
      " [908.085 267.85 ]\n",
      " [915.882 275.59 ]\n",
      " [940.492 258.934]\n",
      " [899.791 316.819]\n",
      " [898.357 339.274]\n",
      " [901.095 374.061]\n",
      " [895.038 406.445]]\n",
      "size of network  (14, 2)\n",
      " feature types;  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "network : 3 [[315.129 659.45 ]\n",
      " [281.59  656.947]\n",
      " [307.943 683.363]\n",
      " [330.708 640.724]\n",
      " [338.91  684.12 ]]\n",
      "size of network  (5, 2)\n",
      " feature types;  [0 1 2 3 4]\n",
      "network : 5 [[259.373 671.072]\n",
      " [286.112 712.103]\n",
      " [262.355 697.932]\n",
      " [239.844 701.309]\n",
      " [215.439 692.973]\n",
      " [204.366 690.878]]\n",
      "size of network  (6, 2)\n",
      " feature types;  [3 4 5 6 7 8]\n",
      "network : 6 [[955.318 204.609]\n",
      " [948.862 180.251]\n",
      " [939.619 171.596]\n",
      " [923.655 148.957]\n",
      " [915.489 139.621]\n",
      " [890.242 139.164]\n",
      " [870.413 132.954]\n",
      " [851.296 133.666]\n",
      " [829.366 140.207]]\n",
      "size of network  (9, 2)\n",
      " feature types;  [ 5  6  7  8  9 10 11 12 13]\n",
      "network : 7 [[291.637 636.959]\n",
      " [261.224 627.476]\n",
      " [251.682 603.415]\n",
      " [249.533 575.942]\n",
      " [236.183 549.916]\n",
      " [220.612 530.508]\n",
      " [215.511 506.3  ]\n",
      " [219.76  485.587]]\n",
      "size of network  (8, 2)\n",
      " feature types;  [ 6  7  8  9 10 11 12 13]\n",
      "\n",
      "dists between nonvoeralpping networks:  [[785.31668198 794.51192369 792.45774992 794.29654143 794.13746848\n",
      "  775.53367726 765.20478218 750.94864441 730.78928921]\n",
      " [811.49188796 820.05548495 817.65992811 818.71930741 818.20176758\n",
      "  799.09729833 788.21392361 773.55538354 753.0463291 ]\n",
      " [805.17065467 814.79988286 812.96988337 815.28586384 815.33275703\n",
      "  797.00983495 786.9705002  772.91608498 752.92787521]\n",
      " [761.79652488 770.81109972 768.67007637 770.33819008 770.11235191\n",
      "  751.42579857 741.02082287 726.71843317 706.52464094]\n",
      " [780.95430185 791.15448015 789.64052154 792.67026663 793.04634432\n",
      "  775.20578956 765.68883926 752.02328362 732.38544463]]\n",
      "dists between nonvoeralpping networks:  [[ 32.52259438  62.67444217  84.64893995 106.19049524 135.01913965\n",
      "  159.8733957  182.69829891 198.3017623 ]\n",
      " [ 22.37101591  35.82336943  61.32017195  87.11751416 116.26448559\n",
      "  140.37498782 164.50213631 182.17353952]\n",
      " [ 49.18553499  72.84244456  97.75982214 122.27427915 151.51765379\n",
      "  176.04361558 199.73727893 216.54465513]\n",
      " [ 39.25198423  70.7356753   87.39033217 103.85609346 131.07657491\n",
      "  155.78413229 177.03152427 190.72741668]\n",
      " [ 66.77496874  96.14394069 118.83610987 140.32365379 169.00754464\n",
      "  193.8841493  216.44229162 231.54281373]]\n",
      "merged networks:  3  and  7  at idx:  [2]\n",
      "previous centres:  (5, 5, 2)\n",
      "centre network 0 [900.443 255.919]\n",
      " doing feature-wise heuristic search at prev step: \n",
      "search for close feature to  [916.445 171.816]\n",
      "search for close feature to  [893.195 191.795]\n",
      "search for close feature to  [921.79  197.864]\n",
      "search for close feature to  [882.773 212.324]\n",
      "search for close feature to  [916.359 226.673]\n",
      "search for close feature to  [892.261 235.695]\n",
      "search for close feature to  [898.336 252.904]\n",
      "search for close feature to  [908.085 267.85 ]\n",
      "search for close feature to  [915.882 275.59 ]\n",
      "search for close feature to  [940.492 258.934]\n",
      "search for close feature to  [899.791 316.819]\n",
      "search for close feature to  [898.357 339.274]\n",
      "search for close feature to  [901.095 374.061]\n",
      "search for close feature to  [895.038 406.445]\n",
      "0 0 adding dist:  102.80306663227516\n",
      "0 1 adding dist:  116.14984750743328\n",
      "0 2 adding dist:  86.28322069209057\n",
      "0 3 adding dist:  90.57027614510181\n",
      "0 4 adding dist:  116.24265924349804\n",
      "1 0 adding dist:  103.79171408282069\n",
      "1 1 adding dist:  41.64940129221548\n",
      "1 2 adding dist:  14.995148448748372\n",
      "1 3 adding dist:  30.933764724003456\n",
      "1 4 adding dist:  16.120911466167147\n",
      "centre network 3 [261.224 627.476]\n",
      " doing feature-wise heuristic search at prev step: \n",
      "search for close feature to  [315.129 659.45 ]\n",
      "search for close feature to  [281.59  656.947]\n",
      "search for close feature to  [307.943 683.363]\n",
      "search for close feature to  [330.708 640.724]\n",
      "search for close feature to  [338.91 684.12]\n",
      "search for close feature to  [291.637 636.959]\n",
      "search for close feature to  [261.224 627.476]\n",
      "search for close feature to  [251.682 603.415]\n",
      "search for close feature to  [249.533 575.942]\n",
      "search for close feature to  [236.183 549.916]\n",
      "search for close feature to  [220.612 530.508]\n",
      "search for close feature to  [215.511 506.3  ]\n",
      "search for close feature to  [219.76  485.587]\n",
      "nearly similar network at previous time step; \n",
      " Min dist array:  [0 0 0 9 0]\n",
      "         matching to prev network using argmax:  3\n",
      "         current locs  [[315.129 659.45 ]\n",
      " [281.59  656.947]\n",
      " [307.943 683.363]\n",
      " [330.708 640.724]\n",
      " [338.91  684.12 ]\n",
      " [291.637 636.959]\n",
      " [261.224 627.476]\n",
      " [251.682 603.415]\n",
      " [249.533 575.942]\n",
      " [236.183 549.916]\n",
      " [220.612 530.508]\n",
      " [215.511 506.3  ]\n",
      " [219.76  485.587]]\n",
      "         previous matched network:  [[373.689 629.571]\n",
      " [353.155 635.379]\n",
      " [364.026 668.226]\n",
      " [330.981 640.841]\n",
      " [346.573 675.661]\n",
      " [291.635 636.894]\n",
      " [261.137 628.506]\n",
      " [251.916 603.616]\n",
      " [249.649 576.237]\n",
      " [236.105 550.065]\n",
      " [220.433 530.699]\n",
      " [215.547 506.389]\n",
      " [219.722 485.465]]\n",
      "centre network 5 [249.6085 695.4525]\n",
      " doing feature-wise heuristic search at prev step: \n",
      "search for close feature to  [259.373 671.072]\n",
      "search for close feature to  [286.112 712.103]\n",
      "search for close feature to  [262.355 697.932]\n",
      "search for close feature to  [239.844 701.309]\n",
      "search for close feature to  [215.439 692.973]\n",
      "search for close feature to  [204.366 690.878]\n",
      "nearly similar network at previous time step; \n",
      " Min dist array:  [0 0 6 0 0]\n",
      "         matching to prev network using argmax:  2\n",
      "         current locs  [[259.373 671.072]\n",
      " [286.112 712.103]\n",
      " [262.355 697.932]\n",
      " [239.844 701.309]\n",
      " [215.439 692.973]\n",
      " [204.366 690.878]]\n",
      "         previous matched network:  [[258.893 671.42 ]\n",
      " [286.959 711.728]\n",
      " [262.01  697.989]\n",
      " [240.922 701.13 ]\n",
      " [218.373 693.757]\n",
      " [204.472 690.434]]\n",
      "centre network 6 [915.489 140.207]\n",
      " doing feature-wise heuristic search at prev step: \n",
      "search for close feature to  [955.318 204.609]\n",
      "search for close feature to  [948.862 180.251]\n",
      "search for close feature to  [939.619 171.596]\n",
      "search for close feature to  [923.655 148.957]\n",
      "search for close feature to  [915.489 139.621]\n",
      "search for close feature to  [890.242 139.164]\n",
      "search for close feature to  [870.413 132.954]\n",
      "search for close feature to  [851.296 133.666]\n",
      "search for close feature to  [829.366 140.207]\n",
      "0 0 adding dist:  17.65191040652541\n",
      "0 1 adding dist:  1.3262066204027023\n",
      "0 2 adding dist:  30.628530114910838\n",
      "0 3 adding dist:  38.07152254638628\n",
      "0 4 adding dist:  1.3384767461558653\n",
      "1 1 adding dist:  76.19669714626747\n",
      "1 2 adding dist:  128.7089455360427\n",
      "1 3 adding dist:  143.38715625885047\n",
      "1 4 adding dist:  104.44282265670535\n",
      "\n",
      "animal: 0 n_mathces_history: [5 5 0 0 0]\n",
      "locs:  [[916.445 171.816]\n",
      " [893.195 191.795]\n",
      " [921.79  197.864]\n",
      " [882.773 212.324]\n",
      " [916.359 226.673]\n",
      " [892.261 235.695]\n",
      " [898.336 252.904]\n",
      " [908.085 267.85 ]\n",
      " [915.882 275.59 ]\n",
      " [940.492 258.934]\n",
      " [899.791 316.819]\n",
      " [898.357 339.274]\n",
      " [901.095 374.061]\n",
      " [895.038 406.445]]\n",
      "curretn best match for current locs network:  [[916.445 171.816]\n",
      " [893.195 191.795]\n",
      " [921.79  197.864]\n",
      " [882.773 212.324]\n",
      " [916.359 226.673]\n",
      " [892.261 235.695]\n",
      " [898.336 252.904]\n",
      " [908.085 267.85 ]\n",
      " [915.882 275.59 ]\n",
      " [940.492 258.934]\n",
      " [899.791 316.819]\n",
      " [898.357 339.274]\n",
      " [901.095 374.061]\n",
      " [895.038 406.445]]\n",
      "   is prev network:  [[971.183 218.733]\n",
      " [931.359 219.42 ]\n",
      " [955.746 210.68 ]\n",
      " [950.703 187.459]\n",
      " [939.61  171.601]\n",
      " [923.768 155.797]\n",
      " [916.036 147.89 ]\n",
      " [892.199 140.561]\n",
      " [876.049 132.594]\n",
      " [853.571 133.808]\n",
      " [834.682 139.976]]\n",
      " argmax in match history:  0\n",
      "               max count:  5\n",
      "DUPLICATE MATCHES: so looking at distances:  [512.0491  207.49094]\n",
      "Original min distance found:  41.49818725585938\n",
      "Average distancesL [102.40981445  41.49818726]  of argmin:  1\n",
      "total dists:  [512.0491  207.49094   0.        0.        0.     ]\n",
      "NO BETTER MATCH FOUND\n",
      "Matched to previous centre:  1\n",
      "final argmax:  1\n",
      "locs current network: [[916.445 171.816]\n",
      " [893.195 191.795]\n",
      " [921.79  197.864]\n",
      " [882.773 212.324]\n",
      " [916.359 226.673]\n",
      " [892.261 235.695]\n",
      " [898.336 252.904]\n",
      " [908.085 267.85 ]\n",
      " [915.882 275.59 ]\n",
      " [940.492 258.934]\n",
      " [899.791 316.819]\n",
      " [898.357 339.274]\n",
      " [901.095 374.061]\n",
      " [895.038 406.445]]\n",
      "to be inserted near previous network:  [[907.862 309.231]\n",
      " [898.582 339.498]\n",
      " [902.981 379.92 ]\n",
      " [899.098 410.416]]\n",
      "\n",
      "animal: 1 n_mathces_history: [     0      0      0 100000      0]\n",
      "locs:  [[315.129 659.45 ]\n",
      " [281.59  656.947]\n",
      " [307.943 683.363]\n",
      " [330.708 640.724]\n",
      " [338.91  684.12 ]\n",
      " [291.637 636.959]\n",
      " [261.224 627.476]\n",
      " [251.682 603.415]\n",
      " [249.533 575.942]\n",
      " [236.183 549.916]\n",
      " [220.612 530.508]\n",
      " [215.511 506.3  ]\n",
      " [219.76  485.587]]\n",
      "curretn best match for current locs network:  [[315.129 659.45 ]\n",
      " [281.59  656.947]\n",
      " [307.943 683.363]\n",
      " [330.708 640.724]\n",
      " [338.91  684.12 ]\n",
      " [291.637 636.959]\n",
      " [261.224 627.476]\n",
      " [251.682 603.415]\n",
      " [249.533 575.942]\n",
      " [236.183 549.916]\n",
      " [220.612 530.508]\n",
      " [215.511 506.3  ]\n",
      " [219.76  485.587]]\n",
      "   is prev network:  [[373.689 629.571]\n",
      " [353.155 635.379]\n",
      " [364.026 668.226]\n",
      " [330.981 640.841]\n",
      " [346.573 675.661]\n",
      " [291.635 636.894]\n",
      " [261.137 628.506]\n",
      " [251.916 603.616]\n",
      " [249.649 576.237]\n",
      " [236.105 550.065]\n",
      " [220.433 530.699]\n",
      " [215.547 506.389]\n",
      " [219.722 485.465]]\n",
      " argmax in match history:  3\n",
      "               max count:  100000\n",
      "Matched to previous centre:  3\n",
      "final argmax:  3\n",
      "locs current network: [[315.129 659.45 ]\n",
      " [281.59  656.947]\n",
      " [307.943 683.363]\n",
      " [330.708 640.724]\n",
      " [338.91  684.12 ]\n",
      " [291.637 636.959]\n",
      " [261.224 627.476]\n",
      " [251.682 603.415]\n",
      " [249.533 575.942]\n",
      " [236.183 549.916]\n",
      " [220.612 530.508]\n",
      " [215.511 506.3  ]\n",
      " [219.76  485.587]]\n",
      "to be inserted near previous network:  [[373.689 629.571]\n",
      " [353.155 635.379]\n",
      " [364.026 668.226]\n",
      " [330.981 640.841]\n",
      " [346.573 675.661]\n",
      " [291.635 636.894]\n",
      " [261.137 628.506]\n",
      " [251.916 603.616]\n",
      " [249.649 576.237]\n",
      " [236.105 550.065]\n",
      " [220.433 530.699]\n",
      " [215.547 506.389]\n",
      " [219.722 485.465]]\n",
      "\n",
      "animal: 2 n_mathces_history: [     0      0 100000      0      0]\n",
      "locs:  [[259.373 671.072]\n",
      " [286.112 712.103]\n",
      " [262.355 697.932]\n",
      " [239.844 701.309]\n",
      " [215.439 692.973]\n",
      " [204.366 690.878]]\n",
      "curretn best match for current locs network:  [[259.373 671.072]\n",
      " [286.112 712.103]\n",
      " [262.355 697.932]\n",
      " [239.844 701.309]\n",
      " [215.439 692.973]\n",
      " [204.366 690.878]]\n",
      "   is prev network:  [[258.893 671.42 ]\n",
      " [286.959 711.728]\n",
      " [262.01  697.989]\n",
      " [240.922 701.13 ]\n",
      " [218.373 693.757]\n",
      " [204.472 690.434]]\n",
      " argmax in match history:  2\n",
      "               max count:  100000\n",
      "Matched to previous centre:  2\n",
      "final argmax:  2\n",
      "locs current network: [[259.373 671.072]\n",
      " [286.112 712.103]\n",
      " [262.355 697.932]\n",
      " [239.844 701.309]\n",
      " [215.439 692.973]\n",
      " [204.366 690.878]]\n",
      "to be inserted near previous network:  [[258.893 671.42 ]\n",
      " [286.959 711.728]\n",
      " [262.01  697.989]\n",
      " [240.922 701.13 ]\n",
      " [218.373 693.757]\n",
      " [204.472 690.434]]\n",
      "\n",
      "animal: 3 n_mathces_history: [5 0 0 0 0]\n",
      "locs:  [[955.318 204.609]\n",
      " [948.862 180.251]\n",
      " [939.619 171.596]\n",
      " [923.655 148.957]\n",
      " [915.489 139.621]\n",
      " [890.242 139.164]\n",
      " [870.413 132.954]\n",
      " [851.296 133.666]\n",
      " [829.366 140.207]]\n",
      "curretn best match for current locs network:  [[955.318 204.609]\n",
      " [948.862 180.251]\n",
      " [939.619 171.596]\n",
      " [923.655 148.957]\n",
      " [915.489 139.621]\n",
      " [890.242 139.164]\n",
      " [870.413 132.954]\n",
      " [851.296 133.666]\n",
      " [829.366 140.207]]\n",
      "   is prev network:  [[971.183 218.733]\n",
      " [931.359 219.42 ]\n",
      " [955.746 210.68 ]\n",
      " [950.703 187.459]\n",
      " [939.61  171.601]\n",
      " [923.768 155.797]\n",
      " [916.036 147.89 ]\n",
      " [892.199 140.561]\n",
      " [876.049 132.594]\n",
      " [853.571 133.808]\n",
      " [834.682 139.976]]\n",
      " argmax in match history:  0\n",
      "               max count:  5\n",
      "Matched to previous centre:  0\n",
      "final argmax:  0\n",
      "locs current network: [[955.318 204.609]\n",
      " [948.862 180.251]\n",
      " [939.619 171.596]\n",
      " [923.655 148.957]\n",
      " [915.489 139.621]\n",
      " [890.242 139.164]\n",
      " [870.413 132.954]\n",
      " [851.296 133.666]\n",
      " [829.366 140.207]]\n",
      "to be inserted near previous network:  [[971.183 218.733]\n",
      " [931.359 219.42 ]\n",
      " [955.746 210.68 ]\n",
      " [950.703 187.459]\n",
      " [939.61  171.601]\n",
      " [923.768 155.797]\n",
      " [916.036 147.89 ]\n",
      " [892.199 140.561]\n",
      " [876.049 132.594]\n",
      " [853.571 133.808]\n",
      " [834.682 139.976]]\n",
      "\n",
      "FINAL NETWORK INSERTION STEP\n",
      "idx_matches[p]: 1\n",
      "   FINAL CHECK DISTANCE BETWEEN PREVIOUS AND CURRENT CENTRE   vect [  0.5965 103.79  ]   dist:  103.79171408282069\n",
      "\n",
      "inserted:  [[916.445 171.816]\n",
      " [893.195 191.795]\n",
      " [921.79  197.864]\n",
      " [882.773 212.324]\n",
      " [916.359 226.673]\n",
      " [892.261 235.695]\n",
      " [898.336 252.904]\n",
      " [908.085 267.85 ]\n",
      " [915.882 275.59 ]\n",
      " [940.492 258.934]\n",
      " [899.791 316.819]\n",
      " [898.357 339.274]\n",
      " [901.095 374.061]\n",
      " [895.038 406.445]]\n",
      " at location:  1\n",
      "ctr-1 values at this location:  1  has values:  [[907.862 309.231]\n",
      " [898.582 339.498]\n",
      " [902.981 379.92 ]\n",
      " [899.098 410.416]]\n",
      "idx_matches[p]: 3\n",
      "   FINAL CHECK DISTANCE BETWEEN PREVIOUS AND CURRENT CENTRE   vect [-0.087  1.03 ]   dist:  1.033667741588148\n",
      "\n",
      "inserted:  [[315.129 659.45 ]\n",
      " [281.59  656.947]\n",
      " [307.943 683.363]\n",
      " [330.708 640.724]\n",
      " [338.91  684.12 ]\n",
      " [291.637 636.959]\n",
      " [261.224 627.476]\n",
      " [251.682 603.415]\n",
      " [249.533 575.942]\n",
      " [236.183 549.916]\n",
      " [220.612 530.508]\n",
      " [215.511 506.3  ]\n",
      " [219.76  485.587]]\n",
      " at location:  3\n",
      "ctr-1 values at this location:  3  has values:  [[373.689 629.571]\n",
      " [353.155 635.379]\n",
      " [364.026 668.226]\n",
      " [330.981 640.841]\n",
      " [346.573 675.661]\n",
      " [291.635 636.894]\n",
      " [261.137 628.506]\n",
      " [251.916 603.616]\n",
      " [249.649 576.237]\n",
      " [236.105 550.065]\n",
      " [220.433 530.699]\n",
      " [215.547 506.389]\n",
      " [219.722 485.465]]\n",
      "idx_matches[p]: 2\n",
      "   FINAL CHECK DISTANCE BETWEEN PREVIOUS AND CURRENT CENTRE   vect [0.299  0.4205]   dist:  0.515966326420667\n",
      "\n",
      "inserted:  [[259.373 671.072]\n",
      " [286.112 712.103]\n",
      " [262.355 697.932]\n",
      " [239.844 701.309]\n",
      " [215.439 692.973]\n",
      " [204.366 690.878]]\n",
      " at location:  2\n",
      "ctr-1 values at this location:  2  has values:  [[258.893 671.42 ]\n",
      " [286.959 711.728]\n",
      " [262.01  697.989]\n",
      " [240.922 701.13 ]\n",
      " [218.373 693.757]\n",
      " [204.472 690.434]]\n",
      "idx_matches[p]: 0\n",
      "   FINAL CHECK DISTANCE BETWEEN PREVIOUS AND CURRENT CENTRE   vect [ 8.279 15.59 ]   dist:  17.65191040652541\n",
      "\n",
      "inserted:  [[955.318 204.609]\n",
      " [948.862 180.251]\n",
      " [939.619 171.596]\n",
      " [923.655 148.957]\n",
      " [915.489 139.621]\n",
      " [890.242 139.164]\n",
      " [870.413 132.954]\n",
      " [851.296 133.666]\n",
      " [829.366 140.207]]\n",
      " at location:  0\n",
      "ctr-1 values at this location:  0  has values:  [[971.183 218.733]\n",
      " [931.359 219.42 ]\n",
      " [955.746 210.68 ]\n",
      " [950.703 187.459]\n",
      " [939.61  171.601]\n",
      " [923.768 155.797]\n",
      " [916.036 147.89 ]\n",
      " [892.199 140.561]\n",
      " [876.049 132.594]\n",
      " [853.571 133.808]\n",
      " [834.682 139.976]]\n",
      "centres new 0 [915.489 140.207]\n",
      "centres new 1 [900.443 255.919]\n",
      "centres new 2 [249.6085 695.4525]\n",
      "centres new 3 [261.224 627.476]\n",
      "42426  FINAL labels array:  [array([[955.318, 204.609],\n",
      "       [948.862, 180.251],\n",
      "       [939.619, 171.596],\n",
      "       [923.655, 148.957],\n",
      "       [915.489, 139.621],\n",
      "       [890.242, 139.164],\n",
      "       [870.413, 132.954],\n",
      "       [851.296, 133.666],\n",
      "       [829.366, 140.207]]), array([[916.445, 171.816],\n",
      "       [893.195, 191.795],\n",
      "       [921.79 , 197.864],\n",
      "       [882.773, 212.324],\n",
      "       [916.359, 226.673],\n",
      "       [892.261, 235.695],\n",
      "       [898.336, 252.904],\n",
      "       [908.085, 267.85 ],\n",
      "       [915.882, 275.59 ],\n",
      "       [940.492, 258.934],\n",
      "       [899.791, 316.819],\n",
      "       [898.357, 339.274],\n",
      "       [901.095, 374.061],\n",
      "       [895.038, 406.445]]), array([[259.373, 671.072],\n",
      "       [286.112, 712.103],\n",
      "       [262.355, 697.932],\n",
      "       [239.844, 701.309],\n",
      "       [215.439, 692.973],\n",
      "       [204.366, 690.878]]), array([[315.129, 659.45 ],\n",
      "       [281.59 , 656.947],\n",
      "       [307.943, 683.363],\n",
      "       [330.708, 640.724],\n",
      "       [338.91 , 684.12 ],\n",
      "       [291.637, 636.959],\n",
      "       [261.224, 627.476],\n",
      "       [251.682, 603.415],\n",
      "       [249.533, 575.942],\n",
      "       [236.183, 549.916],\n",
      "       [220.612, 530.508],\n",
      "       [215.511, 506.3  ],\n",
      "       [219.76 , 485.587]]), []]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eatures;  (70, 2000, 2)\n",
      "0\n",
      "1000\n",
      "SAVING:to file:  /media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/pickle/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npz\n"
     ]
    }
   ],
   "source": [
    "fname = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle'\n",
    "fname = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/pickle/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full.pickle'\n",
    "# fname_in = fname_in[:-7]+\"_traces_inferences.npy\"\n",
    "\n",
    "ctr_comments = [1376]\n",
    "network_history = 5\n",
    "min_network= 4\n",
    "n_networks = 5\n",
    "start = 41050\n",
    "end = start+2000\n",
    "connected_components_function(fname,\n",
    "                             ctr_comments,\n",
    "                             network_history,\n",
    "                             min_network,\n",
    "                             n_networks,\n",
    "                              start,\n",
    "                              end\n",
    "                             )\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " traces_inferences [n_frames, #_non_unique_featres]:  (1000, 14)\n",
      "/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_1000frames_traces_inferences.npy\n",
      "FRAME:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/cat/.conda/envs/DLC-GPU/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eatures;  (56, 1000, 2)\n",
      "0\n",
      "SAVING:to file:  /media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_1000frames_traces_inferences.npz\n"
     ]
    }
   ],
   "source": [
    "# PARALLEL VERSION OF CC\n",
    "fnames = ['/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_1000frames.pickle']\n",
    "\n",
    "if True:\n",
    "    import parmap\n",
    "    parmap.map(connected_components_function, fnames,\n",
    "              pm_processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n",
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# ################################################################################\n",
    "# ################# VISUALIZE SCATTER FOR ALL ANIMALS ############################\n",
    "# ################################################################################\n",
    "# ################################################################################\n",
    "\n",
    "# data = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_1000frames_traces_inferences.npz')\n",
    "# tracesx = data['tracesx'].T\n",
    "# tracesy = data['tracesy'].T\n",
    "\n",
    "\n",
    "# clrs = ['red','blue','cyan','green']\n",
    "# # print (clrs)\n",
    "# fig =plt.figure()\n",
    "# ax1 = plt.subplot(1,1,1)\n",
    "# #ax2 = plt.subplot(2,1,2)\n",
    "# #for k in range(labels_array.shape[0]):\n",
    "#     #for p in range(len(labels_array[k])):\n",
    "    \n",
    "# for p in range(4):\n",
    "#     tempx = np.nanmean(tracesx[:,p*14:(p+1)*14],1)\n",
    "#     tempy = np.nanmean(tracesy[:,p*14:(p+1)*14],1)\n",
    "#     print (tempx.shape)\n",
    "#     ax1.scatter(np.arange(1000), tempx,c=clrs[p])\n",
    "#     #ax2.scatter(k, tempy,c=clrs[p])\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128, 160, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "fname_predictions = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/predictions_10k_new.npy'\n",
    "predictions = np.load(fname_predictions)\n",
    "print (predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Anqi's sigmoid transformation\n",
    "id_=0\n",
    "ax=plt.subplot(1,2,1)\n",
    "pred_s = predictions[id_].sum(2)\n",
    "plt.imshow(pred_s)\n",
    "\n",
    "ax=plt.subplot(1,2,2)\n",
    "pred_s = predictions[id_]\n",
    "\n",
    "pred_s = 1 / (np.exp(-pred_s) + 1)  # confidence map\n",
    "plt.imshow(pred_s.sum(2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 697.459  667.697  668.008  629.044  620.625  642.748  619.947  611.675\n",
      "  604.278  594.503  583.035  563.966  545.126  519.195  500.33   482.725\n",
      "  490.637  453.657  460.835  453.433  436.101  419.403  396.119  385.04\n",
      "  374.515  362.907  347.24   341.515  379.356  354.778  358.04   325.546\n",
      "  331.706  322.015  293.597  261.084  259.557    0.       0.       0.\n",
      "    0.       0.       0.       0.       0.    1139.772 1171.796 1156.13\n",
      " 1156.046 1132.095 1100.112    0.       0.       0.       0.       0.   ]\n",
      "Labels array:  (2000, 56, 2)\n",
      "0\n",
      "[   0.       0.       0.       0.       0.    1051.982 1059.949 1059.797\n",
      " 1068.089    0.       0.       0.       0.       0.   ]\n",
      "14\n",
      "[1082.96  1094.105 1110.125 1114.969 1139.039 1124.774 1140.771 1156.171\n",
      " 1171.758 1178.419 1184.883 1187.268 1179.993    0.   ]\n",
      "28\n",
      "[388.092 361.935 368.646 337.413 343.797 331.186 307.585 275.821 258.116\n",
      " 260.839 256.733 237.137 226.782 226.47 ]\n",
      "42\n",
      "[1188.534 1204.38  1170.43  1209.056 1165.694 1185.789 1179.572 1178.926\n",
      " 1173.484 1171.292 1162.397 1163.303 1158.209 1139.843]\n",
      "0\n",
      "[   0.       0.       0.       0.       0.    1052.012 1059.759 1059.934\n",
      " 1068.082    0.       0.       0.       0.       0.   ]\n",
      "14\n",
      "[1189.19  1204.696 1173.2   1180.03  1139.874 1124.514 1140.946 1157.566\n",
      " 1173.409 1179.245 1185.44  1187.913    0.       0.   ]\n",
      "28\n",
      "[388.268 361.94  368.592 337.212 344.019 331.127 307.408 275.65  258.096\n",
      " 260.726 256.746 237.079 226.814 226.2  ]\n",
      "42\n",
      "[   0.       0.       0.    1211.19  1166.717 1186.978 1172.588 1179.211\n",
      " 1179.64  1174.959 1172.019 1172.356 1163.911 1140.542]\n",
      "0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "14\n",
      "[1204.265 1220.296 1183.338 1225.185 1173.671 1202.865 1195.321 1186.302\n",
      " 1187.141 1179.591 1170.917 1164.601 1157.387 1134.786]\n",
      "28\n",
      "[388.406 361.385 368.84  337.137 344.414 330.998 307.037 274.921 258.063\n",
      "   0.    257.201 237.286 226.156 225.499]\n",
      "42\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0\n",
      "[   0.       0.       0.       0.       0.    1052.038 1052.027 1060.434\n",
      " 1068.064    0.       0.       0.       0.       0.   ]\n",
      "14\n",
      "[1204.2   1212.04  1186.069 1227.721 1181.692 1202.593 1195.515 1185.012\n",
      " 1172.184 1151.622 1147.501 1146.824 1141.175 1123.812]\n",
      "28\n",
      "[388.076 361.35  368.758 336.886 344.15  331.069 306.975 274.883 258.021\n",
      "   0.    257.203 237.296 226.2   225.664]\n",
      "42\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0\n",
      "[   0.       0.       0.       0.       0.    1059.955 1060.187 1060.417\n",
      " 1068.06     0.       0.       0.       0.       0.   ]\n",
      "14\n",
      "[1092.098 1103.464 1115.862 1115.318    0.       0.       0.       0.\n",
      "    0.       0.       0.       0.       0.       0.   ]\n",
      "28\n",
      "[388.507 361.76  368.689 337.086 344.075 331.125 307.364 275.188 258.172\n",
      " 260.857 250.374 236.953 226.425 225.836]\n",
      "42\n",
      "[1205.545 1212.543 1192.346 1227.942 1182.889 1204.045 1189.483 1173.891\n",
      " 1163.69  1141.907 1131.418 1130.536 1129.428 1118.068]\n",
      "0\n",
      "[   0.       0.       0.       0.       0.    1051.979 1060.16  1060.144\n",
      " 1068.039    0.       0.       0.       0.       0.   ]\n",
      "14\n",
      "[1218.287 1228.167 1197.71  1236.43  1194.503 1205.271 1189.748 1172.407\n",
      " 1157.105 1139.2   1126.507 1121.784 1122.385 1118.215]\n",
      "28\n",
      "[388.037 361.701 368.912 336.787 344.151 331.048 307.465 275.386 258.16\n",
      " 260.884 256.774 237.177 227.134 226.763]\n",
      "42\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0\n",
      "[   0.       0.       0.       0.       0.    1051.998 1059.741 1060.121\n",
      " 1068.047    0.       0.       0.       0.       0.   ]\n",
      "14\n",
      "[1219.796 1228.237 1202.905 1237.53  1195.789 1210.959 1195.821 1173.058\n",
      " 1156.617 1141.152 1123.501 1114.798 1110.527 1104.878]\n",
      "28\n",
      "[388.103 361.618 369.125 336.682 344.186 331.196 307.554 275.535 258.59\n",
      " 260.883 256.791 237.227 226.973 226.436]\n",
      "42\n",
      "[1115.907 1116.154 1115.791 1124.117 1132.05  1131.889 1148.047    0.\n",
      "    0.       0.       0.       0.       0.       0.   ]\n",
      "0\n",
      "[   0.       0.       0.       0.       0.    1060.131 1051.985 1060.103\n",
      " 1067.981    0.       0.       0.       0.       0.   ]\n",
      "14\n",
      "[1219.65  1228.146 1201.727 1236.371 1191.483 1206.824 1189.793 1173.261\n",
      " 1163.502 1143.568 1126.803 1115.903 1115.288 1108.49 ]\n",
      "28\n",
      "[388.567 361.743 369.159 337.653 344.865 331.243 307.534 275.074 258.195\n",
      " 260.942 256.55  236.916 226.361 225.91 ]\n",
      "42\n",
      "[   0.       0.       0.       0.       0.    1132.193 1140.654 1147.862\n",
      " 1163.968    0.       0.       0.       0.       0.   ]\n",
      "0\n",
      "[   0.       0.       0.       0.       0.    1060.184 1052.11  1060.227\n",
      " 1068.019    0.       0.       0.       0.       0.   ]\n",
      "14\n",
      "[1236.85  1236.712 1212.22  1226.995 1188.256 1195.124 1172.863 1170.08\n",
      " 1163.286 1144.345 1131.469 1122.357 1115.948 1116.896]\n",
      "28\n",
      "[388.585 361.717 369.556 338.071 345.935 331.35  307.907 275.061 258.157\n",
      " 260.927 256.948 237.011 226.306 225.935]\n",
      "42\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0\n",
      "[   0.       0.       0.       0.       0.    1059.977 1060.107 1060.642\n",
      " 1068.08     0.       0.       0.       0.       0.   ]\n",
      "14\n",
      "[1253.18  1244.636 1220.692 1233.656 1201.823 1211.385 1180.68  1163.503\n",
      " 1153.185 1140.69  1126.355 1115.76  1115.51  1109.507]\n",
      "28\n",
      "[388.228 361.662 369.693 336.996 344.866 331.372 308.636 276.322 258.698\n",
      " 261.36  256.385 236.816 226.226 226.337]\n",
      "42\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "################################################################################\n",
    "######################### VISUALIZE 2D LOCATIONS ###############################\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "\n",
    "\n",
    "data = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npz')\n",
    "tracesx = data['tracesx'].T\n",
    "tracesy = data['tracesy'].T\n",
    "\n",
    "print (tracesx[0])\n",
    "labels_array = np.array((tracesx, tracesy))\n",
    "labels_array = labels_array.transpose(1,2,0)\n",
    "print (\"Labels array: \", labels_array.shape)\n",
    "\n",
    "\n",
    "frame_id = 1372\n",
    "#print (labels_array[200])\n",
    "clrs_new = ['blue','red','cyan','green','yellow','pink','magenta','white','lightgreen','lightblue']\n",
    "\n",
    "original_vid.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "#scale_percent = 400 # percent of original size\n",
    "width = 320*4\n",
    "height = 256*4\n",
    "dim = (width, height)\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.tight_layout(pad=1.08, h_pad=None, w_pad=None, rect=None)\n",
    "for t in range(10):\n",
    "    ax=plt.subplot(2,5,t+1)\n",
    "    #ax=plt.subplot(1,2,t+1)\n",
    "    \n",
    "    ret, frame = original_vid.read()\n",
    "    \n",
    "    # resize image\n",
    "    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA) \n",
    "\n",
    "\n",
    "    plt.imshow(resized,alpha=.7)\n",
    "\n",
    "    for a in range(0,56,14):\n",
    "        print (a)\n",
    "        tempx = labels_array[frame_id+t, a:a + 14][:,0]\n",
    "        tempy = labels_array[frame_id+t, a:a+14][:,1]\n",
    "        \n",
    "        print (tempx)\n",
    "        plt.scatter(\n",
    "            tempx, \n",
    "            tempy, \n",
    "            c=clrs_new[a//14],alpha=.8)\n",
    "    \n",
    "    plt.title(str(t+frame_id)+\" \" +str(round((t+frame_id)/25.,1)),fontsize=8)\n",
    "#     plt.ylim(1024,0)\n",
    "#     plt.xlim(0,1280)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730 0\n",
      "[0. 0.]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-72f3da58bd4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             plt.scatter(np.array(labels_array[frame_id][k])[:,0], \n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     c=clrs_new[k])\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "frame_id = 583\n",
    "#print (labels_array[200])\n",
    "#clrs_new = ['blue','red','cyan','green','yellow','pink','magenta','white','lightgreen','lightblue']\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "frame_ids = [730]\n",
    "for frame_id in frame_ids:\n",
    "    for k in range(len(labels_array[frame_id])):\n",
    "        print (frame_id, k)\n",
    "        print (labels_array[frame_id][k])\n",
    "        if len(labels_array[frame_id][k])>0:\n",
    "            plt.scatter(np.array(labels_array[frame_id][k])[:,0], \n",
    "                    np.array(labels_array[frame_id][k])[:,1],\n",
    "                    c=clrs_new[k])\n",
    "        #print (np.array(labels_array[frame_id+t][k]).shape)\n",
    "        if np.array(labels_array[frame_id][k]).shape[0]>0:\n",
    "            plt.scatter(np.array(labels_array[frame_id][k])[:,0].mean(0),\n",
    "              np.array(labels_array[frame_id][k])[:,1].mean(0),\n",
    "              s=100, c=clrs_new[k])\n",
    "\n",
    "frame_ids = [731]\n",
    "for frame_id in frame_ids:\n",
    "    for k in range(len(labels_array[frame_id])):\n",
    "\n",
    "        if np.array(labels_array[frame_id][k]).shape[0]>0:\n",
    "            plt.scatter(np.array(labels_array[frame_id][k])[:,0].mean(0),\n",
    "              np.array(labels_array[frame_id][k])[:,1].mean(0),\n",
    "              s=100, c=clrs_new[k])\n",
    "\n",
    "\n",
    "    \n",
    "#plt.title(str(t+frame_id))\n",
    "plt.ylim(1024,0)\n",
    "plt.xlim(0,1280)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89988, 14)\n"
     ]
    }
   ],
   "source": [
    "traces_inferences = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npy',allow_pickle=True)\n",
    "\n",
    "print (traces_inferences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:21<00:00, 95.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# select start and ends:\n",
    "\n",
    "# Add fixed labels to video:\n",
    "reassembled = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npz')\n",
    "reassembled = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/pickle/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npz')\n",
    "tracesx_re = reassembled['tracesx'].T\n",
    "tracesy_re = reassembled['tracesy'].T\n",
    "print (tracesx_re.shape)\n",
    "\n",
    "# OPTIONAL MAKE VIDEO TO REVIEW ASSEMBLED VS. INFERENCE LABELS (PRE-FIX)\n",
    "# colors have weird inversion; red is blue and cyan is yellow\n",
    "#colors_4 = ['blue','red','cyan','green','pink','orange']\n",
    "\n",
    "#          pup1     pup2    female  male\n",
    "colors_4= ['orange','green', 'blue', 'red', 'cyan']\n",
    "\n",
    "video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/2020-3-16_12_57_12_418305_compressed.avi'\n",
    "original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "# video sizes\n",
    "size_vid = np.array([1280,1024])\n",
    "scale = 1\n",
    "dot_size = 8//scale\n",
    "\n",
    "#out_dir = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/2020-3-9_08_18_49_128168/'\n",
    "fname_out = video_name[:-4]+\"_corrected.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc('M','P','E','G')\n",
    "video_out = cv2.VideoWriter(fname_out,fourcc, 25, (size_vid[0]//scale,size_vid[1]//scale), True)\n",
    "\n",
    "#dot_size = 10//scale\n",
    "# setup cutoff \n",
    "pcutoff = 0.01\n",
    "\n",
    "# go through first videos\n",
    "from tqdm import trange\n",
    "\n",
    "original_vid.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "for n in trange(0,end-start, 1):\n",
    "    ret, frame = original_vid.read()\n",
    "    #print (n, frame.shape)\n",
    "    cv2.putText(frame, str(n), (50, 100), font, 5, (255, 255, 0), 5)\n",
    "    frame = frame[::scale, ::scale]\n",
    "    \n",
    "    #cv2.putText(frame,   text,location,  font,font size, font color,    font weight, line)\n",
    "    #cv2.putText(img, text, pos, font_face, scale, color, 1, cv2.LINE_AA)\n",
    "    \n",
    "#     for k in range(traces_inferences.shape[1]):\n",
    "#         for p in range(len(traces_inferences[n,k])):\n",
    "#             y = int(traces_inferences[n][k][p][0])//scale + 2\n",
    "#             x = int(traces_inferences[n][k][p][1])//scale + 2\n",
    "         \n",
    "#             frame[x-dot_size:x+dot_size,y-dot_size:y+dot_size]= (np.float32(\n",
    "#                 matplotlib.colors.to_rgb('white'))*255.).astype('uint8')\n",
    "    \n",
    "    \n",
    "    for k in range(14*n_networks):\n",
    "        y = tracesx_re[n,k]\n",
    "        x = tracesy_re[n,k]\n",
    "        \n",
    "        if np.isnan(x) or np.isnan(y):\n",
    "            continue\n",
    "        else:\n",
    "            x=int(x)//scale\n",
    "            y=int(y)//scale\n",
    "            \n",
    "            frame[x-dot_size:x+dot_size,y-dot_size:y+dot_size]= (np.float32(\n",
    "                matplotlib.colors.to_rgb(colors_4[k//14]))*255.).astype('uint8')\n",
    "            #print (colors_4[k])\n",
    "            #frame[y-dot_size:y+dot_size,x-dot_size:x+dot_size]= (np.float32(\n",
    "            #    matplotlib.colors.to_rgb(colors_4[z//14]))*255.).astype('uint8')\n",
    "                \n",
    "    #print (\"\")\n",
    "    video_out.write(frame)\n",
    "\n",
    "    #print (\"\")\n",
    "\n",
    "video_out.release()\n",
    "original_vid.release()\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 337)\n",
      "(56, 1000)\n"
     ]
    }
   ],
   "source": [
    "data1 = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/markers/markers_traces_inferences.npz')\n",
    "tracesx = data1['tracesx']\n",
    "print (tracesx.shape)\n",
    "\n",
    "data2 = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_1000frames_traces_inferences.npz')\n",
    "tracesx = data2['tracesx']\n",
    "print (tracesx.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128, 160, 10)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(fname_predictions[:-4]+\"_watershed.npy\")\n",
    "fname_predictions = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/predictions.npy'\n",
    "predictions = np.load(fname_predictions)[:,:,:,:10]\n",
    "print (predictions.shape)\n",
    "\n",
    "ids = [2, 50, 81, 111]\n",
    "fig=plt.figure(figsize=(40,40))\n",
    "for ctr,id_ in enumerate(ids):\n",
    "    ax=plt.subplot(1,4,ctr+1)\n",
    "    plt.imshow(predictions[id_].sum(2))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(str(id_),fontsize=5)\n",
    "plt.savefig('/home/cat/watershed.png',dpi=600)    \n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
