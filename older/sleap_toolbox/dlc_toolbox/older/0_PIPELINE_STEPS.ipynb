{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE FOR PROCESSING DATA POST SLEAP TRACKING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' After training sleap networks, run sleap-track on a list of .avi files:\\n    \\n    python sleap_os_multifile.py \\n    \\n    (file is on workstation)\\n        \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################\n",
    "############ RUN SLEAP ON AVI FILES ###############\n",
    "###################################################\n",
    "''' After training sleap networks, run sleap-track on a list of .avi files:\n",
    "    \n",
    "    python sleap_os_multifile.py \n",
    "    \n",
    "    - .py file is on workstation\n",
    "    - NNs have to be hardlinked\n",
    "        \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Run sleap-analysis on .slp file which saves a .csv file;\\n    Note, 1hr vids require between 80-100GB of ram each, \\n    \\n    python slp_to_h5_to_csv.py\\n    \\n    (file is on workstation)\\n    \\n    - TODO: simplify this step\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################\n",
    "######## CONVERT .SLP FILES TO CSV ################\n",
    "###################################################\n",
    "'''  Run sleap-analysis on .slp file which saves a .csv file;\n",
    "    Note, 1hr vids require between 80-100GB of ram each, \n",
    "    \n",
    "    python slp_to_h5_to_csv.py\n",
    "    \n",
    "    (file is on workstation)\n",
    "    \n",
    "    - TODO: simplify this step\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Notebook: 8_CSV_to_CSUA_and_chain_generation\\n\\n    Makes required input image folders for training CNNs\\n    \\n    Makes 2 other files:\\n    - traces_inferences.npy : [n_frames, n_animals x n_features, 3] \\n      this file contains all the feature locations (the 3rd dimnesion is x,y,likelihood_\\n      \\n    - chain_ids.npy :         [n_frames, n_animals] \\n      this file contains the track id for each group of features as outputed by sleap\\n\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "###### CONVERT CSV TO .NPY TRACKS AND CHAINS #####\n",
    "##################################################\n",
    "''' Notebook: 8_CSV_to_CSUA_and_chain_generation\n",
    "\n",
    "    Makes required input image folders for training CNNs. \n",
    "    \n",
    "    Input: ...\n",
    "\n",
    "    Output: \n",
    "    - a directory for each track in the sleap output; \n",
    "      there is a flag to toggle saving the .png files also (required for making training data later)\n",
    "    \n",
    "    - traces_inferences.npy : [n_frames, n_animals x n_features, 3] \n",
    "      this file contains all the feature locations (the 3rd dimnesion is x,y,likelihood_\n",
    "      \n",
    "    - chain_ids.npy :         [n_frames, n_animals] \n",
    "      this file contains the track id for each group of features as outputed by sleap\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Manually curate training datasets for the CNN trainins step\\n\\n    - review/verify the output directory from above;\\n    - move .npz files that correspond to single animal tracks to each animal directory\\n    - stack all images into a single .npy file for each animal\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "###### MANUALLY CURATE TRAINING SET FOR CNN ######\n",
    "##################################################\n",
    "''' Manually curate training datasets for the CNN trainins step\n",
    "\n",
    "    - review/verify the output directory from above;\n",
    "    - move .npz files that correspond to single animal tracks to each animal directory\n",
    "    - stack all images into a single .npy file for each animal\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "########### TRAIN THE CNN ON THE DATA ############\n",
    "##################################################\n",
    "''' Notebook: 9_train_CNN.\n",
    "\n",
    "    Input: location of single animal .npy files from above.\n",
    "    \n",
    "    Output: \n",
    "    - model.pt (saved CNN model)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "####### CLASSIFY ALL TRACKS IN A RECORDING #######\n",
    "##################################################\n",
    "''' Notebook: 9_classify_tracks.\n",
    "\n",
    "    Input: trained model (model.pt from above)\n",
    "    \n",
    "    Output:  [TO VERIFY THIS]\n",
    "    - predictions.npz\n",
    "    - classification_output.npz\n",
    "    \n",
    "    TODO: save full confidence array, not just the highest probability;\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "######### COMBINE CNN AND SLEAP RESULTS ##########\n",
    "##################################################\n",
    "''' Notebook: 10_combineCNN_Sleap_hungarian\n",
    "\n",
    "    This notebook uses a hungarian / greedy type of algorithm to assign the\n",
    "    CNN output to unique animal id tracks.\n",
    "    - it takes into consideration both the instantaneous CNN prediction and the average\n",
    "      ID of the track\n",
    "\n",
    "    Input: \n",
    "    - classification_output.npz\n",
    "    - chain_ids.npy\n",
    "    - traces_inferences.npy\n",
    "    \n",
    "    Output:  \n",
    "    - locs_array : [n_animals, n_frames, 2]\n",
    "      this is the unique ID corrected location of each animal (collapsed from n_features -> centre of mass)\n",
    "      \n",
    "    - locs_array_clean : [n_animals, n_frames, 2]\n",
    "      same as above but with some additional postprocessing including interpolating over missing data etc.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "###### TRAIN JAABA BEHAVIOR CLASSIFIERS ##########\n",
    "##################################################\n",
    "''' Notebook: 10_combineCNN_Sleap_hungarian\n",
    "\n",
    "    Input: \n",
    "    - classification_output.npz\n",
    "    - chain_ids.npy\n",
    "    - traces_inferences.npy\n",
    "    \n",
    "    Output:  \n",
    "    - locs_array : [n_animals, n_frames, 2]\n",
    "      this is the unique ID corrected location of each animal (collapsed from n_features -> centre of mass)\n",
    "      \n",
    "    - locs_array_clean : [n_animals, n_frames, 2]\n",
    "      same as above but with some additional postprocessing including interpolating over missing data etc.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 89987, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load('/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_16/2020_3_15_11_53_51_617746_compressed/locs_array.npy')\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
