{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "from tqdm import trange\n",
    "\n",
    "#import glob2\n",
    "\n",
    "from numba import jit\n",
    "import tables\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import h5py\n",
    "#import hdf5storage\n",
    "import csv\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "import umap\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scatter plots of pixel colors:\n",
    "\n",
    "#          pup1     pup2    female  male\n",
    "#clrs= ['red','blue','cyan','green', 'orange']\n",
    "\n",
    "def load_data(frames_idx,\n",
    "             features):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    default_mean_nan = 0\n",
    "    for k in range(n_networks):\n",
    "        x.append([])\n",
    "        y.append([])\n",
    "        for p in features:\n",
    "            \n",
    "            # impute x\n",
    "            temp = tracesx[k*14+p,frames_idx]\n",
    "            idx = np.where(temp!=0)[0]\n",
    "            mean = np.nanmean(temp[idx])\n",
    "            if np.isnan(mean):\n",
    "                mean = 0\n",
    "                \n",
    "            idx1 = np.where(temp==0.)[0]\n",
    "            temp[idx1]=mean\n",
    "            idx2 = np.where(np.isnan(temp))[0]\n",
    "            temp[idx2]=mean            \n",
    "            x[k].append(temp)\n",
    "            \n",
    "            # impute y\n",
    "            temp = tracesy[k*14+p,frames_idx]\n",
    "            idx = np.where(temp!=0)[0]\n",
    "            mean = np.nanmean(temp[idx])\n",
    "            if np.isnan(mean):\n",
    "                mean = 0\n",
    "            idx1 = np.where(temp==0.)[0]\n",
    "            temp[idx1]=mean\n",
    "            idx2 = np.where(np.isnan(temp))[0]\n",
    "            temp[idx2]=mean\n",
    "            y[k].append(temp)\n",
    "\n",
    "    x = np.array(x)  \n",
    "    y = np.array(y)\n",
    "    print (\"x,y:\", x.shape, y.shape)\n",
    "\n",
    "    idx = np.where(np.isnan(x))[0]\n",
    "    print (\"  NANS at assembly time: \", idx)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def load_frames_mean_dff(x, y, \n",
    "                clrs,\n",
    "                frames_idx,\n",
    "                        video_name):\n",
    "    \n",
    "    # DOT SIZE\n",
    "    dot_size = 8\n",
    "    \n",
    "    # GRAB FRAM PIXEL INTENSITY\n",
    "    \n",
    "    original_vid = cv2.VideoCapture(video_name)\n",
    "    \n",
    "    start_frame = frames_idx[0]\n",
    "    original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    \n",
    "    # get mean\n",
    "    frames = []\n",
    "    for n in trange(0, 100, 1):\n",
    "        ret, frame = original_vid.read()\n",
    "        frames.append(frame)\n",
    "    frames = np.array(frames)\n",
    "    frame_mean = frames.mean(0)   \n",
    "\n",
    "    vid = np.zeros((x.shape[0],x.shape[1],x.shape[2],3),'int32')\n",
    "    for n in trange(0, frames_idx.shape[0], 1):\n",
    "        ret, frame = original_vid.read()\n",
    "\n",
    "        frame = frame/frame_mean\n",
    "        \n",
    "        for k in range(n_networks):\n",
    "            for p in range(x.shape[1]):\n",
    "                #print (\"y[k,p,n]: \", y[k,p,n])\n",
    "                tempx = int(y[k,p,n])\n",
    "                tempy = int(x[k,p,n])\n",
    "                #print (tempx,tempy)\n",
    "                vid[k,p,n]=frame[tempx, tempy]\n",
    "                \n",
    "    print (\"Final vid: \", vid.shape)\n",
    "    \n",
    "    idx = np.where(np.isnan(vid))\n",
    "    print (\"VIDEO NANs: \", idx)\n",
    "\n",
    "    # label final frame for visualization below:\n",
    "    mark_frame = x.shape[2]//2\n",
    "    original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame+mark_frame)\n",
    "    ret, frame = original_vid.read()\n",
    "    for a in range(x.shape[0]):\n",
    "        xx = np.int32(y[a,:,mark_frame])\n",
    "        yy = np.int32(x[a,:,mark_frame])\n",
    " \n",
    "        for p in range(xx.shape[0]):\n",
    "            if xx[p]>0:\n",
    "                frame[xx[p]-dot_size:xx[p]+dot_size,yy[p]-dot_size:yy[p]+dot_size]= (np.float32(\n",
    "                    matplotlib.colors.to_rgb(clrs[a]))*255.).astype('uint8')\n",
    "    \n",
    "    original_vid.release()\n",
    "\n",
    "    # return whole video + example frame\n",
    "    return vid, frame\n",
    "\n",
    "def load_frames_adaptive_threshold(x, y, \n",
    "                clrs,\n",
    "                frames_idx,\n",
    "               video_name):\n",
    "    \n",
    "    # DOT SIZE\n",
    "    dot_size = 8\n",
    "    jitter=3\n",
    "    \n",
    "    # GRAB FRAM PIXEL INTENSITY\n",
    "    #video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "    original_vid = cv2.VideoCapture(video_name)\n",
    "    \n",
    "    start_frame = frames_idx[0]\n",
    "    original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    vid = np.zeros((x.shape[0],x.shape[1],x.shape[2],3),'int32')\n",
    "    for n in trange(0, frames_idx.shape[0], 1):\n",
    "        ret, frame = original_vid.read()\n",
    "\n",
    "        #frame=np.array(frame.mean(2),'uint8')\n",
    "        frame=frame[:,:,0]\n",
    "        \n",
    "        frame = cv2.medianBlur(frame,5)\n",
    "        frame = cv2.adaptiveThreshold(frame,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "                    cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "        frame = cv2.medianBlur(frame,15)\n",
    "\n",
    "        \n",
    "        for k in range(n_networks):\n",
    "            for p in range(x.shape[1]):\n",
    "                #print (\"y[k,p,n]: \", y[k,p,n])\n",
    "                tempx = int(y[k,p,n])\n",
    "                tempy = int(x[k,p,n])\n",
    "                \n",
    "                #vid[k,p,n]=frame[tempx, tempy]\n",
    "                 #print (tempx,tempy)\n",
    "                tempe = frame[tempx-jitter:tempx+jitter, \n",
    "                                             tempy-jitter:tempy+jitter]\n",
    "                #print (tempe.shape)\n",
    "                tempe_mean = tempe.mean()\n",
    "                #print (tempe)\n",
    "                if tempe.shape[0]>0:\n",
    "                    #print (tempe, np.nanmean(tempe))\n",
    "                    vid[k,p,n]=np.nanmean(tempe)\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "    print (\"Final vid: \", vid.shape)\n",
    "    \n",
    "    idx = np.where(np.isnan(vid))\n",
    "    print (\"VIDEO NANs: \", idx)\n",
    "\n",
    "    # label final frame for visualization below:\n",
    "    mark_frame = x.shape[2]//2\n",
    "    original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame+mark_frame)\n",
    "    ret, frame = original_vid.read()\n",
    "    for a in range(x.shape[0]):\n",
    "        xx = np.int32(y[a,:,mark_frame])\n",
    "        yy = np.int32(x[a,:,mark_frame])\n",
    " \n",
    "        for p in range(xx.shape[0]):\n",
    "            if xx[p]>0:\n",
    "                frame[xx[p]-dot_size:xx[p]+dot_size,yy[p]-dot_size:yy[p]+dot_size]= (np.float32(\n",
    "                    matplotlib.colors.to_rgb(clrs[a]))*255.).astype('uint8')\n",
    "    \n",
    "    original_vid.release()\n",
    "\n",
    "    # return whole video + example frame\n",
    "#     print(\"VID DONE: \", vid.shape)\n",
    "#     vid = np.array((vid,vid,vid))\n",
    "#     print (vid.shape)\n",
    "#     vid = vid.transpose(1,2,3,0)\n",
    "\n",
    "    return vid, frame\n",
    "\n",
    "\n",
    "def load_frames(x, y, \n",
    "                clrs,\n",
    "                frames_idx,\n",
    "               video_name):\n",
    "    \n",
    "    # DOT SIZE\n",
    "    dot_size = 8\n",
    "    jitter=2\n",
    "    \n",
    "    # GRAB FRAM PIXEL INTENSITY\n",
    "    #video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "    original_vid = cv2.VideoCapture(video_name)\n",
    "    \n",
    "    start_frame = frames_idx[0]\n",
    "    original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    vid = np.zeros((x.shape[0],x.shape[1],x.shape[2],3),'int32')\n",
    "    for n in trange(0, frames_idx.shape[0], 1):\n",
    "        ret, frame = original_vid.read()\n",
    "\n",
    "        for k in range(n_networks):\n",
    "            for p in range(x.shape[1]):\n",
    "                #print (\"y[k,p,n]: \", y[k,p,n])\n",
    "                tempx = int(y[k,p,n])\n",
    "                tempy = int(x[k,p,n])\n",
    "                #print (tempx,tempy)\n",
    "                #vid[k,p,n]=frame[tempx, tempy]\n",
    "                \n",
    "                #print (tempx,tempy)\n",
    "                tempe = frame[tempx-jitter:tempx+jitter, \n",
    "                                             tempy-jitter:tempy+jitter]\n",
    "                #print (tempe.shape)\n",
    "                tempe_mean = tempe.mean()\n",
    "                #print (tempe)\n",
    "                if tempe.shape[0]>0:\n",
    "                    #print (tempe, np.nanmean(tempe))\n",
    "                    vid[k,p,n]=np.nanmean(np.nanmean(tempe,0), 0)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "    print (\"Final vid: \", vid.shape)\n",
    "    \n",
    "    idx = np.where(np.isnan(vid))\n",
    "    print (\"VIDEO NANs: \", idx)\n",
    "\n",
    "    # label final frame for visualization below:\n",
    "    mark_frame = x.shape[2]//2\n",
    "    original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame+mark_frame)\n",
    "    ret, frame = original_vid.read()\n",
    "    for a in range(x.shape[0]):\n",
    "        xx = np.int32(y[a,:,mark_frame])\n",
    "        yy = np.int32(x[a,:,mark_frame])\n",
    " \n",
    "        for p in range(xx.shape[0]):\n",
    "            if xx[p]>0:\n",
    "                frame[xx[p]-dot_size:xx[p]+dot_size,yy[p]-dot_size:yy[p]+dot_size]= (np.float32(\n",
    "                    matplotlib.colors.to_rgb(clrs[a]))*255.).astype('uint8')\n",
    "    \n",
    "    original_vid.release()\n",
    "\n",
    "    # return whole video + example frame\n",
    "    return vid, frame\n",
    "\n",
    "\n",
    "def load_frames_sobel(x, y, \n",
    "                            clrs,\n",
    "                            frames_idx,\n",
    "                     video_name):\n",
    "    \n",
    "    # DOT SIZE\n",
    "    dot_size = 8\n",
    "    \n",
    "    # GRAB FRAM PIXEL INTENSITY\n",
    "    #video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "    original_vid = cv2.VideoCapture(video_name)\n",
    "    \n",
    "    start_frame = frames_idx[0]\n",
    "    original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    jitter=2\n",
    "    vid = np.zeros((x.shape[0],x.shape[1],x.shape[2]),'float32')\n",
    "    for n in trange(0, frames_idx.shape[0], 1):\n",
    "        ret, frame = original_vid.read()\n",
    "        \n",
    "        #\n",
    "        #image = frame.mean(2)\n",
    "        image = frame[:,:,2]\n",
    "        \n",
    "        edge_sobel = filters.sobel(image)\n",
    "        for k in range(n_networks):\n",
    "            for p in range(x.shape[1]):\n",
    "                #print (\"y[k,p,n]: \", y[k,p,n])\n",
    "                tempx = int(y[k,p,n])\n",
    "                tempy = int(x[k,p,n])\n",
    "                #print (tempx,tempy)\n",
    "                tempe = edge_sobel[tempx-jitter:tempx+jitter, \n",
    "                                             tempy-jitter:tempy+jitter]\n",
    "                #print (tempe)\n",
    "                if tempe.shape[0]>0:\n",
    "                    #print (tempe, np.nanmean(tempe))\n",
    "                    vid[k,p,n]=np.nanmean(tempe)\n",
    "                \n",
    "    print (\"Final vid: \", vid.shape)\n",
    "    \n",
    "    idx = np.where(np.isnan(vid))\n",
    "    print (\"VIDEO NANs: \", idx)\n",
    "\n",
    "    # label final frame for visualization below:\n",
    "    mark_frame = x.shape[2]//2\n",
    "    original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame+mark_frame)\n",
    "    ret, frame = original_vid.read()\n",
    "    for a in range(x.shape[0]):\n",
    "        xx = np.int32(y[a,:,mark_frame])\n",
    "        yy = np.int32(x[a,:,mark_frame])\n",
    " \n",
    "        for p in range(xx.shape[0]):\n",
    "            if xx[p]>0:\n",
    "                frame[xx[p]-dot_size:xx[p]+dot_size,yy[p]-dot_size:yy[p]+dot_size]= (np.float32(\n",
    "                    matplotlib.colors.to_rgb(clrs[a]))*255.).astype('uint8')\n",
    "    \n",
    "    original_vid.release()\n",
    "\n",
    "    # return whole video + example frame\n",
    "    vid = np.array((vid,vid,vid)).transpose(1,2,3,0)\n",
    "\n",
    "    return vid, frame\n",
    "\n",
    "\n",
    "\n",
    "def make_pca_data(vid):\n",
    "\n",
    "    vid_imputed = vid.copy()\n",
    "    n_networks = vid_imputed.shape[0]\n",
    "    print (\"# animals \", n_networks)\n",
    "    \n",
    "    # IMPUTE MISSNIG DATA BY REPLACING WITH MEAN\n",
    "    # loop over animal ids\n",
    "    for id_ in range(n_networks):\n",
    "        # loop over RGB camera colors\n",
    "        for k in range(3):\n",
    "            # loop over features\n",
    "            for p in range(vid_imputed.shape[1]):\n",
    "                temp1 = vid_imputed[id_,p,:,k]\n",
    "                \n",
    "                #print (temp1)\n",
    "               \n",
    "                idx2 = np.where(temp1==0.)[0]\n",
    "                #print (id_, k, p, \"Idx2: \", idx2)\n",
    "\n",
    "                mean = np.nanmean(temp1)\n",
    "\n",
    "                idx1 = np.where(np.isnan(temp1)==True)[0]\n",
    "                temp1[idx1] = mean\n",
    "\n",
    "                idx = np.where(temp1==0)[0]\n",
    "                vid_imputed[id_,p,idx,k] = mean\n",
    "\n",
    "    print (\"vid iputed: \", vid_imputed.shape)\n",
    "    \n",
    "    vid_pca = vid_imputed.transpose(2,0,1,3)\n",
    "    #print (vid_pca.shape)\n",
    "\n",
    "    vid_pca2 = []\n",
    "    for k in range(n_networks):\n",
    "        temp = vid_pca[:,k].reshape(vid_imputed.shape[2],-1)\n",
    "        #print (temp.shape)\n",
    "        vid_pca2.append(temp)\n",
    "\n",
    "    vid_pca = np.vstack(vid_pca2)\n",
    "    print (\"vid_pca: \", vid_pca.shape)\n",
    "\n",
    "    return vid_pca\n",
    "\n",
    "def make_pca_object(vid_pca):\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(vid_pca)\n",
    "    \n",
    "    return pca\n",
    "\n",
    "def run_pca(pca, vid_pca,\n",
    "            vid, \n",
    "            title, \n",
    "            clrs):\n",
    "\n",
    "    print (\"vid: \", vid.shape)\n",
    "    pca_2d = pca.transform(vid_pca)\n",
    "\n",
    "    # plot results\n",
    "\n",
    "    for k in range(0,vid_pca.shape[0],vid.shape[2]):\n",
    "        plt.scatter(pca_2d[k:k+vid.shape[2],0],\n",
    "                   pca_2d[k:k+vid.shape[2],1],\n",
    "                   c=clrs[k//vid.shape[2]])\n",
    "\n",
    "def run_umap(umap_obj, \n",
    "             vid_pca,\n",
    "             vid,\n",
    "             title,\n",
    "             clrs):\n",
    "    \n",
    "    #from sklearn.datasets import fetch_openml\n",
    "    #import matplotlib.pyplot as plt\n",
    "    #import seaborn as sns\n",
    "\n",
    "    #sns.set(context=\"paper\", style=\"white\")\n",
    "\n",
    "    #mnist = fetch_openml(\"mnist_784\", version=1)\n",
    "    #print (mnist.data.shape)\n",
    "    \n",
    "    embedding = reducer.transform(vid_pca)\n",
    "\n",
    "    print (\"Embeding: \", embedding.shape)\n",
    "    #fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    #color = mnist.target.astype(int)\n",
    "\n",
    "    for k in range(0,embedding.shape[0],vid.shape[2]):\n",
    "        plt.scatter(embedding[k:k+vid.shape[2],0],\n",
    "                   embedding[k:k+vid.shape[2],1],\n",
    "                   c=clrs[k//vid.shape[2]],\n",
    "                   alpha=.5)\n",
    "\n",
    "        \n",
    "def remove_outliers(vid):\n",
    "    print (\"VID: \", vid.shape)\n",
    "    for a in range(vid.shape[0]):\n",
    "        for f in range(vid.shape[1]):\n",
    "            for c in range(vid.shape[3]):\n",
    "                tempx = vid[a,f,:,c]\n",
    "                \n",
    "                idx = np.where(np.isnan(tempx))[0]\n",
    "                mean = np.nanmean(tempx)\n",
    "                tempx[idx]=mean\n",
    "                std = np.std(tempx)*1.1\n",
    "                idx = np.where(np.logical_or(\n",
    "                                    tempx>mean+std,\n",
    "                                    tempx<mean-std))[0]\n",
    "                tempx[idx]=mean\n",
    "                \n",
    "                vid[a,f,:,c]=tempx\n",
    "    \n",
    "    return vid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import umap\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# #import matplotlib.pyplot as plt\n",
    "# #import seaborn as sns\n",
    "\n",
    "# #sns.set(context=\"paper\", style=\"white\")\n",
    "\n",
    "# mnist = fetch_openml(\"mnist_784\", version=1)\n",
    "# print (mnist.data.shape)\n",
    "# reducer = umap.UMAP(random_state=42)\n",
    "# embedding = reducer.fit_transform(mnist.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 2000)\n",
      "n animals:  5\n"
     ]
    }
   ],
   "source": [
    "# LOAD RAW PCA DATA\n",
    "if False:\n",
    "    data = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npz')\n",
    "    vid_start = 0\n",
    "    locs = [[0, 215], [2180,2468], [4400, 4500],\n",
    "           [5376,5583]]\n",
    "\n",
    "    video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "\n",
    "else:\n",
    "    video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/2020-3-16_12_57_12_418305_compressed_corrected_nolabels.mp4'\n",
    "    vid_start = 41050\n",
    "    data = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/pickle/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npz')\n",
    "    locs = [ \n",
    "    [230,500],\n",
    "        [600,750],\n",
    "        [800,1200],\n",
    "        [1400,1800]\n",
    "        \n",
    "        \n",
    "    ]\n",
    "    \n",
    "# assign data\n",
    "tracesx = data['tracesx']\n",
    "tracesy = data['tracesy']\n",
    "print (tracesx.shape)\n",
    "n_networks = tracesx.shape[0]//14\n",
    "print (\"n animals: \", n_networks)\n",
    "\n",
    "\n",
    "# DEFINE CORRECT ASSEMBLED PERIODS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reject_outliers(data, m = 2.):\n",
    "#     d = np.abs(data - np.median(data))\n",
    "#     mdev = np.median(d)\n",
    "#     s = d/mdev if mdev else 0.\n",
    "#     return data[s<m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-194-41dc8496e074>:20: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(temp[idx])\n",
      "<ipython-input-194-41dc8496e074>:33: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(temp[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x,y: (5, 10, 270) (5, 10, 270)\n",
      "  NANS at assembly time:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/270 [00:00<?, ?it/s]<ipython-input-194-41dc8496e074>:153: RuntimeWarning: Mean of empty slice.\n",
      "  tempe_mean = tempe.mean()\n",
      "/home/cat/.local/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 270/270 [00:09<00:00, 29.35it/s]\n",
      "<ipython-input-194-41dc8496e074>:20: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(temp[idx])\n",
      "<ipython-input-194-41dc8496e074>:33: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(temp[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final vid:  (5, 10, 270, 3)\n",
      "VIDEO NANs:  (array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))\n",
      "VID:  (5, 10, 270, 3)\n",
      "# animals  5\n",
      "vid iputed:  (5, 10, 270, 3)\n",
      "vid_pca:  (1350, 30)\n",
      "vid:  (5, 10, 270, 3)\n",
      "x,y: (5, 10, 150) (5, 10, 150)\n",
      "  NANS at assembly time:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]<ipython-input-194-41dc8496e074>:153: RuntimeWarning: Mean of empty slice.\n",
      "  tempe_mean = tempe.mean()\n",
      "/home/cat/.local/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 150/150 [00:05<00:00, 28.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final vid:  (5, 10, 150, 3)\n",
      "VIDEO NANs:  (array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))\n",
      "VID:  (5, 10, 150, 3)\n",
      "# animals  5\n",
      "vid iputed:  (5, 10, 150, 3)\n",
      "vid_pca:  (750, 30)\n",
      "vid:  (5, 10, 150, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-194-41dc8496e074>:20: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(temp[idx])\n",
      "<ipython-input-194-41dc8496e074>:33: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(temp[idx])\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]<ipython-input-194-41dc8496e074>:153: RuntimeWarning: Mean of empty slice.\n",
      "  tempe_mean = tempe.mean()\n",
      "/home/cat/.local/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x,y: (5, 10, 400) (5, 10, 400)\n",
      "  NANS at assembly time:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:13<00:00, 29.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final vid:  (5, 10, 400, 3)\n",
      "VIDEO NANs:  (array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))\n",
      "VID:  (5, 10, 400, 3)\n",
      "# animals  5\n",
      "vid iputed:  (5, 10, 400, 3)\n",
      "vid_pca:  (2000, 30)\n",
      "vid:  (5, 10, 400, 3)\n",
      "x,y: (5, 10, 400) (5, 10, 400)\n",
      "  NANS at assembly time:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-194-41dc8496e074>:20: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(temp[idx])\n",
      "<ipython-input-194-41dc8496e074>:33: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(temp[idx])\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]<ipython-input-194-41dc8496e074>:153: RuntimeWarning: Mean of empty slice.\n",
      "  tempe_mean = tempe.mean()\n",
      "/home/cat/.local/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 400/400 [00:13<00:00, 29.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final vid:  (5, 10, 400, 3)\n",
      "VIDEO NANs:  (array([], dtype=int64), array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))\n",
      "VID:  (5, 10, 400, 3)\n",
      "# animals  5\n",
      "vid iputed:  (5, 10, 400, 3)\n",
      "vid_pca:  (2000, 30)\n",
      "vid:  (5, 10, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "################################################################\n",
    "################ PCA ON SINGLE PIXELS ##########################\n",
    "################################################################\n",
    "################################################################\n",
    "\n",
    "clrs= ['cyan','green', 'red', 'blue', 'pink']\n",
    "locations = np.arange(4)\n",
    "\n",
    "#features = np.arange(5,9,1)\n",
    "features = np.arange(0,10,1)\n",
    "\n",
    "fig = plt.figure()\n",
    "pca_data = []\n",
    "for ctr, location in enumerate(locations):\n",
    "    ax=plt.subplot(2,2,ctr+1)\n",
    "    # select x,y from specific chunk of data \n",
    "    frames_idx = np.arange(locs[location][0],locs[location][1],1)\n",
    "    \n",
    "    x,y = load_data(frames_idx,\n",
    "                   features)\n",
    "    \n",
    "    # grab frames from video\n",
    "    #vid, frame = load_frames_mean_dff(x, y, \n",
    "    vid, frame = load_frames_adaptive_threshold(x, y, \n",
    "                             clrs, \n",
    "                             frames_idx,\n",
    "                                     video_name)\n",
    "\n",
    "    # remove outliars\n",
    "    vid = remove_outliers(vid)\n",
    "\n",
    "    # make High Dimensional data;\n",
    "    vid_pca = make_pca_data(vid)\n",
    "    pca_data.append(vid_pca)\n",
    "    # run through fit step\n",
    "    \n",
    "    title = str(locs[location])\n",
    "    plt.title(\"frames: \"+title)\n",
    "    if True:\n",
    "        #if False:\n",
    "        if location == 0:\n",
    "            pca = make_pca_object(vid_pca)\n",
    "        run_pca(pca, \n",
    "                vid_pca, \n",
    "                vid,\n",
    "                title,\n",
    "                clrs)\n",
    "        #plt.xlim(-300,400)\n",
    "        #plt.ylim(-200,400)\n",
    "        #plt.xlim(-60,60)\n",
    "        #plt.ylim(-30,30)\n",
    "    else:\n",
    "        #if False:\n",
    "        if location ==0:\n",
    "            reducer = umap.UMAP(random_state=42)\n",
    "            umap_obj = reducer.fit(vid_pca)\n",
    "\n",
    "    \n",
    "        umap_data = run_umap(umap_obj,\n",
    "                             vid_pca,\n",
    "                             vid,\n",
    "                             title,\n",
    "                             clrs)\n",
    "        plt.xlim(-10,20)\n",
    "        plt.ylim(-10,20)\n",
    "    # also show last frame of stack\n",
    "    #fig=plt.figure()\n",
    "    #plt.imshow(frame)\n",
    "\n",
    "plt.suptitle(\"PCA distributions for 4 (non-id swapping) video segments for \"+str(features.shape[0])+ \" features\"+\n",
    "             \"\\n Features = pixel intensity at inferred location\", fontsize=20)\n",
    "#plt.suptitle(\"UMAP distributions for 4 (non-id swapping) video segments for \"+str(features.shape[0])+ \" features\"+\n",
    "#             \"\\n Features = pixel intensity at inferred location\", fontsize=20)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14, 207, 3)\n"
     ]
    }
   ],
   "source": [
    "print (vid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x,y: (5, 14, 270) (5, 14, 270)\n",
      "  NANS at assembly time:  []\n",
      "VID:  (5, 14, 215, 3)\n",
      "VID:  (5, 14, 215, 3)\n",
      "# animals  5\n",
      "vid iputed:  (5, 14, 215, 3)\n",
      "vid_pca:  (1075, 42)\n",
      "vid:  (5, 14, 215, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-c8941c2541b9>:20: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(temp[idx])\n",
      "<ipython-input-62-c8941c2541b9>:33: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(temp[idx])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-bc401e637020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mctr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# select x,y from specific chunk of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mframes_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     x,y = load_data(frames_idx,\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "################################################################\n",
    "################ PCA ON PATCHES + EDGES ########################\n",
    "################################################################\n",
    "################################################################\n",
    "\n",
    "clrs= ['cyan','green', 'red', 'blue', 'pink']\n",
    "locations = np.arange(4)\n",
    "#locations = [0]\n",
    "features = np.arange(5,6,1)\n",
    "features = np.arange(0,14,1)\n",
    "\n",
    "fig = plt.figure()\n",
    "pca_data = []\n",
    "for ctr, location in enumerate(locations):\n",
    "    ax=plt.subplot(2,2,ctr+1)\n",
    "    # select x,y from specific chunk of data \n",
    "    frames_idx = np.arange(locs[location][0],locs[location][1],1)\n",
    "    \n",
    "    x,y = load_data(frames_idx,\n",
    "                   features)\n",
    "    \n",
    "    # grab frames from video\n",
    "    fname_out = '/home/cat/'+str(ctr)+\"_sobel.npy\"\n",
    "    if os.path.exists(fname_out)==False:\n",
    "        vid, frame = load_frames_sobel(x, y, \n",
    "                             clrs, \n",
    "                             frames_idx)\n",
    "        np.save(fname_out, vid)\n",
    "    else:\n",
    "        vid = np.load(fname_out)\n",
    "    print (\"VID: \", vid.shape)\n",
    "    \n",
    "    ## remove outliars\n",
    "    vid = remove_outliers(vid)\n",
    "\n",
    "    # make High Dimensional data;\n",
    "    vid_pca = make_pca_data(vid)\n",
    "    pca_data.append(vid_pca)\n",
    "    # run through fit step\n",
    "    \n",
    "    title = str(locs[location])\n",
    "    plt.title(\"frames: \"+title)\n",
    "    if True:\n",
    "        #if False:\n",
    "        if location == 0:\n",
    "            pca = make_pca_object(vid_pca)\n",
    "        run_pca(pca, \n",
    "                vid_pca, \n",
    "                vid,\n",
    "                title,\n",
    "                clrs)\n",
    "        #plt.xlim(-100,100)\n",
    "        #plt.ylim(-100,100)\n",
    "        #plt.xlim(-60,60)\n",
    "        #plt.ylim(-30,30)\n",
    "    else:\n",
    "        #if False:\n",
    "        if location ==0:\n",
    "            reducer = umap.UMAP(random_state=42)\n",
    "            umap_obj = reducer.fit(vid_pca)\n",
    "\n",
    "    \n",
    "        umap_data = run_umap(umap_obj,\n",
    "                             vid_pca,\n",
    "                             vid,\n",
    "                             title,\n",
    "                             clrs)\n",
    "        plt.xlim(-10,20)\n",
    "        plt.ylim(-10,20)\n",
    "    # also show last frame of stack\n",
    "    #fig=plt.figure()\n",
    "    #plt.imshow(frame)\n",
    "\n",
    "plt.suptitle(\"PCA distributions for 4 (non-id swapping) video segments for \"+str(features.shape[0])+ \" features\"+\n",
    "             \"\\n Features = pixel intensity at inferred location\", fontsize=20)\n",
    "#plt.suptitle(\"UMAP distributions for 4 (non-id swapping) video segments for \"+str(features.shape[0])+ \" features\"+\n",
    "#             \"\\n Features = pixel intensity at inferred location\", fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4050, 42)\n"
     ]
    }
   ],
   "source": [
    "pca_data = np.vstack(pca_data)\n",
    "print (pca_data.shape)\n",
    "\n",
    "pca = make_pca_object(pca_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/anaconda3/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    }
   ],
   "source": [
    "reducer = umap.UMAP(random_state=42)\n",
    "umap_obj = reducer.fit(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# animals  5\n",
      "vid iputed:  (5, 10, 215, 3)\n",
      "vid_pca:  (1075, 30)\n",
      "vid:  (5, 10, 215, 3)\n"
     ]
    }
   ],
   "source": [
    "# make vid_pca data\n",
    "vid_pca = make_pca_data(vid)\n",
    "\n",
    "# make pca object\n",
    "#pca = make_pca_object(vid_pca)\n",
    "\n",
    "# \n",
    "clrs= ['cyan','green', 'red', 'blue', 'cyan']\n",
    "\n",
    "title = str(locs[location])\n",
    "run_pca(pca, \n",
    "        vid_pca, \n",
    "        vid,\n",
    "        title,\n",
    "        clrs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "from skimage.data import camera\n",
    "from skimage.util import compare_images\n",
    "\n",
    "#\n",
    "video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "start_frame = 0\n",
    "original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "vid = np.zeros((x.shape[0],x.shape[1],x.shape[2],3),'int32')\n",
    "#for n in trange(0, frames_idx.shape[0], 1):\n",
    "ret, image = original_vid.read()\n",
    "\n",
    "ax=plt.subplot(2,2,1)\n",
    "plt.imshow(image)\n",
    "\n",
    "ax=plt.subplot(2,2,2)\n",
    "image = np.mean(image,2)\n",
    "edge_roberts = filters.roberts(image)\n",
    "plt.imshow(edge_roberts)\n",
    "\n",
    "ax=plt.subplot(2,2,3)\n",
    "edge_sobel = filters.sobel(image)\n",
    "\n",
    "plt.imshow(edge_sobel)\n",
    "plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1024, 1280, 3)\n",
      "frame mean:  (1024, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "    \n",
    "video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "#video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/2020-3-16_12_57_12_418305_compressed_corrected.mp4'\n",
    "\n",
    "original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "start_frame = 0\n",
    "original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "vid = np.zeros((x.shape[0],x.shape[1],x.shape[2],3),'int32')\n",
    "#for n in trange(0, frames_idx.shape[0], 1):\n",
    "frames = []\n",
    "frames_blured= []\n",
    "frame_idx = np.random.randint(0,25000,100)\n",
    "#for n in trange(0, 100, 1):\n",
    "for n in tqdm(frame_idx):\n",
    "    original_vid.set(cv2.CAP_PROP_POS_FRAMES, n)\n",
    "\n",
    "    ret, frame = original_vid.read()\n",
    "    frames.append(frame)\n",
    "    \n",
    "    img = frame[:,:,0]\n",
    "    #temp = gaussian_filter(temp, sigma=5)\n",
    "    \n",
    "    frames_blured.append(temp)\n",
    "    \n",
    "# mean subtracted\n",
    "ax=plt.subplot(2,2,1)\n",
    "frames = np.array(frames)\n",
    "print (frames.shape)\n",
    "frame_means = frames.mean(0)  \n",
    "print (\"frame mean: \", frame_mean.shape)\n",
    "\n",
    "plt.imshow(frame[:,:,0]-frame_mean[:,:,0])\n",
    "plt.title(\"Mean subtracted\")\n",
    "\n",
    "ax=plt.subplot(2,2,2)\n",
    "img = frame[:,:,0]\n",
    "img = cv2.medianBlur(img,11)\n",
    "\n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "plt.imshow(th2)\n",
    "ax=plt.subplot(2,2,3)\n",
    "img = frame[:,:,0]\n",
    "img = cv2.medianBlur(img,15)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "plt.imshow(th3)\n",
    "\n",
    "# \n",
    "ax=plt.subplot(2,2,4)\n",
    "edge_sobel = filters.sobel(frame[:,:,0])\n",
    "\n",
    "plt.imshow(edge_sobel)\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14, 215, 3)\n"
     ]
    }
   ],
   "source": [
    "temp = np.array((vid,vid,vid)).transpose(1,2,3,0)\n",
    "print (temp.shape)\n",
    "np.save('/home/cat/vid_sobel.npy',temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "\n",
    "skimage.filters()\n",
    "\n",
    "image = data.page()\n",
    "\n",
    "global_thresh = threshold_otsu(image)\n",
    "binary_global = image > global_thresh\n",
    "\n",
    "block_size = 25\n",
    "binary_adaptive = threshold_local(image, block_size, offset=10)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(7, 8))\n",
    "ax0, ax1, ax2 = axes\n",
    "plt.gray()\n",
    "\n",
    "ax0.imshow(image)\n",
    "ax0.set_title('Image')\n",
    "\n",
    "ax1.imshow(binary_global)\n",
    "ax1.set_title('Global thresholding')\n",
    "\n",
    "ax2.imshow(binary_adaptive)\n",
    "ax2.set_title('Adaptive thresholding')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1280, 3)\n",
      "<class 'numpy.uint8'>\n",
      "(1024, 1280)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#img = cv2.imread('dave.jpg',0)\n",
    "#img = image\n",
    "\n",
    "original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "start_frame = 0\n",
    "original_vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "ret, img = original_vid.read()\n",
    "print (img.shape)\n",
    "print (type(img[0,0,0]))\n",
    "img=np.array(img.mean(2),'uint8')\n",
    "print (img.shape)\n",
    "\n",
    "ret,th1 = cv2.threshold(img,147,255,cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "#th2 = cv2.medianBlur(th2,15)\n",
    "\n",
    "\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "#th3 = cv2.medianBlur(th3,15)\n",
    "\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
