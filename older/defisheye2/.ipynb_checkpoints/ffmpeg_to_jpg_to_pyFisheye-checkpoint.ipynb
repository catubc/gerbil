{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pyFishEye import fisheye\n",
    "from defish import defish\n",
    "from movie import video_to_frames, make_dirs\n",
    "\n",
    "import parmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "####### MAKE SUPPORT FILES #######\n",
    "##################################\n",
    "video_name = '/media/cat/1TB/dan/movies/2020_08_01_11_27_15_857870_compressed.mp4'\n",
    "\n",
    "dir_frames, dir_fixed_frames = make_dirs(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "##### EXTRACT JPGs FROM MOVIE ######\n",
    "####################################\n",
    "video_to_frames(video_name, dir_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [08:22,  4.79s/it]                        \n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "######## CORRECT FISHEYE ########\n",
    "#################################\n",
    "\n",
    "f = fisheye()\n",
    "main_dir = '/home/cat/code/fisheye/'\n",
    "\n",
    "f.LoadCorrectionMap('corr_cohort2.npy')\n",
    "\n",
    "img_names = glob.glob(dir_frames+\"/*.jpg\")\n",
    "imgs_split = np.array_split(img_names,100)\n",
    "    \n",
    "#\n",
    "if True:\n",
    "        parmap.map(defish, \n",
    "                   imgs_split, \n",
    "                   f.map_x, \n",
    "                   f.map_y,\n",
    "                   dir_fixed_frames,\n",
    "                   pm_processes=4,\n",
    "                   pm_pbar=True)\n",
    "else:\n",
    "    for imgs_s in imgs_split:\n",
    "        defish(imgs_s, \n",
    "               f.map_x, \n",
    "               f.map_y,\n",
    "               dir_fixed_frames)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################\n",
    "###### FFMPEG TO MAKE MOVIES #######\n",
    "####################################\n",
    "fname_out = out_dir+os.path.split(video_name.replace('.mp4','_corrected.mp4'))[1]\n",
    "\n",
    "os.system(\"ffmpeg -f image2 -i \" + dir_fixed_frames+\"/%5d.jpg -vcodec libx264 -b 2000k \" + fname_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1584/28801 [00:30<08:47, 51.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9e68dd9870c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_fixed_frames\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "####### RECONSTRUCT DEFISHED MOVIE ######\n",
    "#########################################\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "size = (1280,1024)\n",
    "\n",
    "out_dir = '/media/cat/1TB/dan/movies/'\n",
    "out = cv2.VideoWriter(out_dir+os.path.split(video_name.replace('.mp4','_corrected.mp4'))[1],\n",
    "                      cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                      15, \n",
    "                      size)\n",
    "\n",
    "# \n",
    "img_array = []\n",
    "fnames = np.sort(glob.glob(dir_fixed_frames+'/*.jpg'))\n",
    "for filename in tqdm(fnames):\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    out.write(img)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True (51, 1, 2)\n",
      "True (48, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "images = glob.glob('/media/cat/1TB/dan/*.jpg')\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    #ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #gray = img[:,:,2]\n",
    "    \n",
    "    ret = True\n",
    "    useHarrisDetector=True\n",
    "    corners = cv2.goodFeaturesToTrack(gray,1000,0.0001,100).astype('float32')\n",
    "    #corners = np.int0(corners)\n",
    "    \n",
    "    print (ret, corners.shape)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2=cv2.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (7,6), corners2, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# aturesToTrack \t( \tInputArray  \timage,\n",
    "# \t\tOutputArray  \tcorners,\n",
    "# \t\tint  \tmaxCorners,\n",
    "# \t\tdouble  \tqualityLevel,\n",
    "# \t\tdouble  \tminDistance,\n",
    "# \t\tInputArray  \tmask = noArray(),\n",
    "# \t\tint  \tblockSize = 3,\n",
    "# \t\tbool  \tuseHarrisDetector = false,\n",
    "# \t\tdouble  \tk = 0.04 \n",
    "# \t) \t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "False None\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(fname)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "print (img)\n",
    "a, b = cv2.findChessboardCorners(img, (14, 15))\n",
    "\n",
    "print (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-7m_g9lbm/opencv/modules/calib3d/src/fisheye.cpp:742: error: (-215:Assertion failed) objectPoints.type() == CV_32FC3 || objectPoints.type() == CV_64FC3 in function 'calibrate'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-25995cc1b86d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcalibration_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERM_CRITERIA_EPS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERM_CRITERIA_MAX_ITER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-7m_g9lbm/opencv/modules/calib3d/src/fisheye.cpp:742: error: (-215:Assertion failed) objectPoints.type() == CV_32FC3 || objectPoints.type() == CV_64FC3 in function 'calibrate'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculate K & D\n",
    "N_imm = 1 # number of calibration images\n",
    "K = np.zeros((3, 3))\n",
    "D = np.zeros((4, 1))\n",
    "rvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(N_imm)]\n",
    "tvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(N_imm)]\n",
    "retval, K, D, rvecs, tvecs = cv2.fisheye.calibrate(\n",
    "    objpoints,\n",
    "    imgpoints,\n",
    "    gray.shape[::-1],\n",
    "    K,\n",
    "    D,\n",
    "    rvecs,\n",
    "    tvecs,\n",
    "    calibration_flags,\n",
    "    (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-7m_g9lbm/opencv/modules/calib3d/src/fisheye.cpp:741: error: (-215:Assertion failed) !objectPoints.empty() && !imagePoints.empty() && objectPoints.total() == imagePoints.total() in function 'calibrate'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-14f56ebd3162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mtvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mcalibration_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERM_CRITERIA_EPS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERM_CRITERIA_MAX_ITER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m )\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-7m_g9lbm/opencv/modules/calib3d/src/fisheye.cpp:741: error: (-215:Assertion failed) !objectPoints.empty() && !imagePoints.empty() && objectPoints.total() == imagePoints.total() in function 'calibrate'\n"
     ]
    }
   ],
   "source": [
    "# Checkboard dimensions\n",
    "CHECKERBOARD = (6,9)\n",
    "subpix_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1)\n",
    "calibration_flags = cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC + cv2.fisheye.CALIB_CHECK_COND + cv2.fisheye.CALIB_FIX_SKEW\n",
    "objp = np.zeros((1, CHECKERBOARD[0]*CHECKERBOARD[1], 3), np.float32)\n",
    "objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "### read images and for each image:\n",
    "fname = '/media/cat/1TB/dan/checkerboard1.jpg'\n",
    "img = cv2.imread(fname)\n",
    "img_shape = img.shape[:2]\n",
    "\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# Find the chess board corners\n",
    "ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH+cv2.CALIB_CB_FAST_CHECK+cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "# If found, add object points, image points (after refining them)\n",
    "if ret == True:\n",
    "    objpoints.append(objp)\n",
    "    cv2.cornerSubPix(gray,corners,(3,3),(-1,-1),subpix_criteria)\n",
    "    imgpoints.append(corners)\n",
    "###\n",
    "\n",
    "# calculate K & D\n",
    "N_imm = 1 # number of calibration images\n",
    "K = np.zeros((3, 3))\n",
    "D = np.zeros((4, 1))\n",
    "rvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(N_imm)]\n",
    "tvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(N_imm)]\n",
    "retval, K, D, rvecs, tvecs = cv2.fisheye.calibrate(\n",
    "    objpoints,\n",
    "    imgpoints,\n",
    "    gray.shape[::-1],\n",
    "    K,\n",
    "    D,\n",
    "    rvecs,\n",
    "    tvecs,\n",
    "    calibration_flags,\n",
    "    (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#\n",
    "k = np.array([[ 512 ,   0.    ,      640],\n",
    "             [   0.      ,    640  , 640],\n",
    "             [   0.     ,       0.    ,        1.        ]])\n",
    "\n",
    "d = np.array([[ 0.16],\n",
    "             [ 0.0112638],\n",
    "             [ 0.01004722],\n",
    "             [-0.00593285]])\n",
    "\n",
    "d = np.array([[ 0.056],\n",
    "             [ 0.06],\n",
    "             [ 0.05],\n",
    "             [-0.00593285]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:03<00:00, 31.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange, tqdm\n",
    "nk = k.copy()\n",
    "nk[0,0]=k[0,0]/1.5\n",
    "nk[1,1]=k[1,1]/1.5\n",
    "# Just by scaling the matrix coefficients!\n",
    "\n",
    "map1, map2 = cv2.fisheye.initUndistortRectifyMap(k, d, np.eye(3), nk, \n",
    "                                                 (1280,1024), cv2.CV_16SC2)  # Pass k in 1st parameter, nk in 4th parameter\n",
    "\n",
    "fname = '/home/cat/Downloads/cohort2/20560.jpg'\n",
    "for p in trange(100):\n",
    "    img = cv2.imread(fname)\n",
    "    #print (img)\n",
    "    nemImg = cv2.remap(img, \n",
    "                       map1, \n",
    "                       map2, \n",
    "                       interpolation=cv2.INTER_LINEAR, \n",
    "                       borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "    cv2.imwrite(fname[:-4]+\"_fixed.jpg\", nemImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_shape:  (1024, 1280)\n",
      "False\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-7m_g9lbm/opencv/modules/calib3d/src/fisheye.cpp:741: error: (-215:Assertion failed) !objectPoints.empty() && !imagePoints.empty() && objectPoints.total() == imagePoints.total() in function 'calibrate'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-adeaf923cf66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mcalibration_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-6))\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-7m_g9lbm/opencv/modules/calib3d/src/fisheye.cpp:741: error: (-215:Assertion failed) !objectPoints.empty() && !imagePoints.empty() && objectPoints.total() == imagePoints.total() in function 'calibrate'\n"
     ]
    }
   ],
   "source": [
    "# Checkboard dimensions\n",
    "CHECKERBOARD = (6,9)\n",
    "subpix_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1)\n",
    "calibration_flags = cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC + cv2.fisheye.CALIB_CHECK_COND + cv2.fisheye.CALIB_FIX_SKEW\n",
    "objp = np.zeros((1, CHECKERBOARD[0]*CHECKERBOARD[1], 3), np.float32)\n",
    "objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "### read images and for each image:\n",
    "img = cv2.imread(fname)\n",
    "img_shape = img.shape[:2]\n",
    "print (\"img_shape: \", img_shape)\n",
    "\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find the chess board corners\n",
    "ret, corners = cv2.findChessboardCorners(gray, \n",
    "                                         CHECKERBOARD, \n",
    "                                         cv2.CALIB_CB_ADAPTIVE_THRESH+cv2.CALIB_CB_FAST_CHECK+cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "\n",
    "print (ret)\n",
    "# If found, add object points, image points (after refining them)\n",
    "if ret == True:\n",
    "    objpoints.append(objp)\n",
    "    cv2.cornerSubPix(gray,corners,(3,3),(-1,-1),subpix_criteria)\n",
    "    imgpoints.append(corners)\n",
    "###\n",
    "\n",
    "# calculate K & D\n",
    "N_imm = 1 # number of calibration images\n",
    "K = np.zeros((3, 3))\n",
    "D = np.zeros((4, 1))\n",
    "rvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(N_imm)]\n",
    "tvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(N_imm)]\n",
    "retval, K, D, rvecs, tvecs = cv2.fisheye.calibrate(\n",
    "    objpoints,\n",
    "    imgpoints,\n",
    "    gray.shape[::-1],\n",
    "    K,\n",
    "    D,\n",
    "    rvecs,\n",
    "    tvecs,\n",
    "    calibration_flags,\n",
    "    (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-6))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5387a4faa37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/home/cat/Downloads/cohort2/11988{dtype}_{format}_{pfov}_{fov}.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefisheye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpfov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpfov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fish/lib/python3.7/site-packages/defisheye/defisheye.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, infile, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image format not recognized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mxcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "dtype = 'linear'\n",
    "format = 'fullframe'\n",
    "fov = 190\n",
    "pfov = 140\n",
    "\n",
    "img = \"/home/cat/Downloads/cohort2/11988.jpg\"\n",
    "img_out = f\"/home/cat/Downloads/cohort2/11988{dtype}_{format}_{pfov}_{fov}.jpg\"\n",
    "\n",
    "obj = Defisheye(img, dtype=dtype, format=format, fov=fov, pfov=pfov)\n",
    "obj.convert(img_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera(Maker: Nikon Corporation; Model: Nikon D3S; Mount: Nikon F AF; Crop Factor: 1.0; Score: 0)\n",
      "Lens(Maker: Nikon; Model: Nikon AF Nikkor 28mm f/1.4D; Type: RECTILINEAR; Focal: 28.0-28.0; Aperture: 1.399999976158142-None; Crop factor: 1.0; Score: 95)\n"
     ]
    }
   ],
   "source": [
    "import lensfunpy\n",
    "import cv2 # OpenCV library\n",
    "\n",
    "cam_maker = 'NIKON CORPORATION'\n",
    "cam_model = 'NIKON D3S'\n",
    "lens_maker = 'Nikon'\n",
    "lens_model = 'Nikkor 28mm f/1.4D AF'\n",
    "\n",
    "db = lensfunpy.Database()\n",
    "cam = db.find_cameras(cam_maker, cam_model)[0]\n",
    "print (cam)\n",
    "lens = db.find_lenses(cam, lens_maker, lens_model)[0]\n",
    "print (lens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print (lensfunpy.Database.find_cameras(maker=None, model=None, loose_search=False))\n",
    "\n",
    "# db = lensfunpy.Database()\n",
    "# cam = db.find_cameras('flir')\n",
    "# print (cam)\n",
    "# lens = db.find_lenses(cam, 'Nikon', 'Nikkor AF 20mm f/2.8D')[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [01:37<00:00, 16.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import parmap\n",
    "import lensfunpy\n",
    "import cv2 # OpenCV library\n",
    "\n",
    "focal_length = 4.5\n",
    "aperture = 1.8\n",
    "distance = 60\n",
    "root_dir = '/home/cat/Downloads/cohort2/late/jpgs/'\n",
    "root_dir_fixed = '//home/cat/Downloads/cohort2/late/jpgs_fixed/'\n",
    "fnames = np.sort(glob.glob(root_dir+'/*.jpg'))\n",
    "\n",
    "# \n",
    "#\n",
    "def correct(fnames\n",
    "            ):\n",
    "\n",
    "    cam_maker = 'NIKON CORPORATION'\n",
    "    cam_model = 'NIKON D3S'\n",
    "    lens_maker = 'Nikon'\n",
    "    lens_model = 'Nikkor 28mm f/1.4D AF'\n",
    "\n",
    "    db = lensfunpy.Database()\n",
    "    cam = db.find_cameras(cam_maker, cam_model)[0]\n",
    "    lens = db.find_lenses(cam, lens_maker, lens_model)[0]\n",
    "\n",
    "    for image_path in fnames:\n",
    "        im_undistorted = cv2.imread(image_path)\n",
    "        for k in range(6):\n",
    "            if k==0:\n",
    "                im_undistorted = np.roll(im_undistorted, -40, 0)\n",
    "                im_undistorted = np.roll(im_undistorted, -40, 1)\n",
    "\n",
    "            height, width = im_undistorted.shape[0], im_undistorted.shape[1]\n",
    "\n",
    "            mod = lensfunpy.Modifier(lens, cam.crop_factor, width, height)\n",
    "            mod.initialize(focal_length, aperture, distance)\n",
    "\n",
    "            undist_coords = mod.apply_geometry_distortion()\n",
    "            im_undistorted = cv2.remap(im_undistorted, undist_coords, None, cv2.INTER_LANCZOS4)\n",
    "\n",
    "        undistorted_image_path = root_dir_fixed + os.path.split(image_path)[1]\n",
    "        cv2.imwrite(undistorted_image_path, im_undistorted)\n",
    "\n",
    "    \n",
    "if True:\n",
    "    fnames_split = np.array_split(fnames, 6)\n",
    "    parmap.map(correct, \n",
    "               fnames_split,\n",
    "               pm_processes=6,\n",
    "              pm_pbar=True)\n",
    "    \n",
    "\n",
    "print (\"DONE\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
