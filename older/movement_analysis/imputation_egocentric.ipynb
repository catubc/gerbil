{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# \n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# \n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import trange\n",
    "import parmap\n",
    "import glob\n",
    "from sklearn.decomposition import PCA\n",
    "#import umap\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "# \n",
    "from tqdm import tqdm\n",
    "\n",
    "import sleap\n",
    "\n",
    "\n",
    "import sklearn.experimental\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# \n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "# \n",
    "\n",
    "import numba\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "from Imputation import Impute, CentreBody\n",
    "\n",
    "from Imputation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ... median filtering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 296827.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ... rejecting outliers....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 22968.81it/s]\n"
     ]
    }
   ],
   "source": [
    "##################################################   \n",
    "############# GENERATE EGOCENTRIC DATA ###########   \n",
    "##################################################\n",
    "cb = CentreBody()\n",
    "cb.parallel = True\n",
    "cb.root_dir = '/media/cat/1TB/dan/cohort1/slp/'\n",
    "#cb.root_dir = '/media/cat/256GB/dan/slp'\n",
    "\n",
    "#\n",
    "#cb.process_slp()\n",
    "\n",
    "#\n",
    "cb.get_fnames()\n",
    "\n",
    "# median filter data\n",
    "cb.filter_data()\n",
    "\n",
    "# \n",
    "cb.reject_outliers()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [03:29<00:00, 34.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DONE Generating 2-point ground truth datasets for imputation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################   \n",
    "####### GENERATE PAIR-WISE CENTRE DATASETS #######   \n",
    "################################################## \n",
    "\n",
    "# \n",
    "cb.parallel = True\n",
    "\n",
    "# for each recording centre/align every pair of data\n",
    "#     TODO: make a single file otherwise generating 15 files per recording\n",
    "#      TODO : OR MAKE A SINGLE STACK OF DATA\n",
    "cb.centre_and_align_all_pairs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "#################################################        \n",
    "#### TRAIN PAIRWISE MODELS MISSING FEATURES #####\n",
    "#################################################                       \n",
    "\n",
    "# pass cb object into Impute object\n",
    "I = Impute(cb)\n",
    "I.parallel = False\n",
    "I.n_cores = 4\n",
    "\n",
    "# Select best model; \n",
    "#  [\"BayesianRidge\",          0\n",
    "#   \"DecisionTreeRegressor\",  1 \n",
    "#   \"ExtraTreesRegressor\",    2  <--- best performing when tested on female data; but large data, 2.5GB /model\n",
    "#   \"KNeighborsRegressor\"]    3  <--- 2nd best\n",
    "#  VAE also evaluated; but not coded\n",
    "models = [0]\n",
    "for animal_id in I.animal_ids:\n",
    "    I.animal_id = animal_id\n",
    "    for model in models:\n",
    "        I.model_type = model\n",
    "\n",
    "        # this will generate 4 animals x 15 pairwise models = 60 models\n",
    "        I.generate_imputation_models_all_pairs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################################################    \n",
    "# #### LOAD GT DATA AND PREDICT USING SPECIFIC MODEL ####\n",
    "# #######################################################\n",
    "# # select a particular animal\n",
    "# I = Impute(cb)\n",
    "# I.parallel = True\n",
    "# I.n_cores = 4\n",
    "# I.model_type = 0 \n",
    "\n",
    "# #\n",
    "# I.animals_selected = [0]\n",
    "# I.animal_id = 0\n",
    "# I.generate_random_drops = True     # flag used to indicate \n",
    "\n",
    "# # this generates random drops file + evaluates how the trained model does\n",
    "# #I.predict_imputation_ground_truth_all_pairs()\n",
    "\n",
    "# # plot violion plots of errors\n",
    "# #plot_errors(I)\n",
    "\n",
    "# print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #########################################################    \n",
    "# #### LOAD REAL DATA AND PREDICT USING SPECIFIC MODEL ####\n",
    "# #########################################################\n",
    "# # select a particular animal\n",
    "# I = Impute(cb)\n",
    "# I.parallel = False\n",
    "# I.n_cores = 8\n",
    "# I.model_type = 0\n",
    "\n",
    "# # \n",
    "# I.animals_selected = [0]\n",
    "# I.generate_random_drops = False     # flag used to indicate \n",
    "\n",
    "# # \n",
    "# # I.predict_novel_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 14, 2)\n",
      " male:                               (2069710, 14, 2)\n",
      " pup1:                               (2069710, 14, 2)\n",
      " pup2:                               (2069710, 14, 2)\n",
      "(2069710, 14, 2)\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "#### MAKE ALL_DATA DATASETS ####\n",
    "################################\n",
    "\n",
    "# TODO: EMBED THIS INTO ANOTHER FUNCTION EARLY IN PROCESSING\n",
    "#      TODO: probably better to process each hour of data as stand alone - don't want concatenation artifacts etc.\n",
    "\n",
    "def make_this_into_a_function()\n",
    "    f1 = None\n",
    "    f2 = None\n",
    "    feats = load_processed_data_stand_alone(f1,f2,I.March16_file_order, I.root_dir, I.animal_ids, data_type=1, remove_nans=False)\n",
    "    print (np.vstack(feats[0]).shape)\n",
    "    for k in range(I.animal_ids.shape[0]):\n",
    "        fname_out = I.root_dir+'/animalID_'+str(k)+'_alldata.npy'\n",
    "        if os.path.exists(fname_out)==False:\n",
    "            np.save(fname_out, np.vstack(feats[k]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710, 14, 2)\n",
      "INFO:numba.core.transforms:finding looplift candidates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/code/gerbil/movement_analysis/Imputation.py:609: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function parse_data_for_anchors failed at nopython mode lowering due to: \u001b[1m\u001b[1mnon-numeric type in Num\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 615:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "        # count # of non nan entries\n",
      "\u001b[1m        idx = np.where(np.isnan(feats[k,:,0])==False)[0]\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: lowering \"$24.17 = arrayexpr(expr=(<built-in function eq>, [(<ufunc 'isnan'>, [Var($24.14, Imputation.py:615)]), const(bool, False)]), ty=array(bool, 1d, C))\" at /home/cat/code/gerbil/movement_analysis/Imputation.py (615)\u001b[0m\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/cat/code/gerbil/movement_analysis/Imputation.py:609: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"parse_data_for_anchors\" failed type inference due to: \u001b[1m\u001b[1mCannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 613:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "    frame_ids = []\n",
      "\u001b[1m    for k in range(feats.shape[0]):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/cat/anaconda3/envs/gerbil/lib/python3.6/site-packages/numba/core/object_mode_passes.py:152: NumbaWarning: \u001b[1mFunction \"parse_data_for_anchors\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 612:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "\n",
      "\u001b[1m    frame_ids = []\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/home/cat/anaconda3/envs/gerbil/lib/python3.6/site-packages/numba/core/object_mode_passes.py:162: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 612:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "\n",
      "\u001b[1m    frame_ids = []\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/home/cat/code/gerbil/movement_analysis/Imputation.py:609: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"parse_data_for_anchors\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at /home/cat/code/gerbil/movement_analysis/Imputation.py (613)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 613:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "    frame_ids = []\n",
      "\u001b[1m    for k in range(feats.shape[0]):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/cat/anaconda3/envs/gerbil/lib/python3.6/site-packages/numba/core/object_mode_passes.py:152: NumbaWarning: \u001b[1mFunction \"parse_data_for_anchors\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 613:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "    frame_ids = []\n",
      "\u001b[1m    for k in range(feats.shape[0]):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/home/cat/anaconda3/envs/gerbil/lib/python3.6/site-packages/numba/core/object_mode_passes.py:162: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 613:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "    frame_ids = []\n",
      "\u001b[1m    for k in range(feats.shape[0]):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(628094,)\n",
      "(2069710, 14, 2)\n",
      "(518377,)\n",
      "(2069710, 14, 2)\n",
      "(409718,)\n",
      "(2069710, 14, 2)\n",
      "(246257,)\n",
      "(2069710, 14, 2)\n",
      "(230403,)\n",
      "(2069710, 14, 2)\n",
      "(565952,)\n",
      "(2069710, 14, 2)\n",
      "(453972,)\n",
      "(2069710, 14, 2)\n",
      "(274308,)\n",
      "(2069710, 14, 2)\n",
      "(248357,)\n",
      "(2069710, 14, 2)\n",
      "(441885,)\n",
      "(2069710, 14, 2)\n",
      "(260741,)\n",
      "(2069710, 14, 2)\n",
      "(237260,)\n",
      "(2069710, 14, 2)\n",
      "(269522,)\n",
      "(2069710, 14, 2)\n",
      "(244677,)\n",
      "(2069710, 14, 2)\n",
      "(264280,)\n",
      "(2069710, 14, 2)\n",
      "(363199,)\n",
      "(2069710, 14, 2)\n",
      "(203186,)\n",
      "(2069710, 14, 2)\n",
      "(151170,)\n",
      "(2069710, 14, 2)\n",
      "(118263,)\n",
      "(2069710, 14, 2)\n",
      "(120073,)\n",
      "(2069710, 14, 2)\n",
      "(252295,)\n",
      "(2069710, 14, 2)\n",
      "(174017,)\n",
      "(2069710, 14, 2)\n",
      "(142856,)\n",
      "(2069710, 14, 2)\n",
      "(153324,)\n",
      "(2069710, 14, 2)\n",
      "(160547,)\n",
      "(2069710, 14, 2)\n",
      "(116635,)\n",
      "(2069710, 14, 2)\n",
      "(117849,)\n",
      "(2069710, 14, 2)\n",
      "(128634,)\n",
      "(2069710, 14, 2)\n",
      "(123964,)\n",
      "(2069710, 14, 2)\n",
      "(178110,)\n",
      "(2069710, 14, 2)\n",
      "(461638,)\n",
      "(2069710, 14, 2)\n",
      "(302560,)\n",
      "(2069710, 14, 2)\n",
      "(216636,)\n",
      "(2069710, 14, 2)\n",
      "(146693,)\n",
      "(2069710, 14, 2)\n",
      "(176257,)\n",
      "(2069710, 14, 2)\n",
      "(313498,)\n",
      "(2069710, 14, 2)\n",
      "(223687,)\n",
      "(2069710, 14, 2)\n",
      "(150173,)\n",
      "(2069710, 14, 2)\n",
      "(173131,)\n",
      "(2069710, 14, 2)\n",
      "(212970,)\n",
      "(2069710, 14, 2)\n",
      "(145606,)\n",
      "(2069710, 14, 2)\n",
      "(162704,)\n",
      "(2069710, 14, 2)\n",
      "(155983,)\n",
      "(2069710, 14, 2)\n",
      "(150906,)\n",
      "(2069710, 14, 2)\n",
      "(154460,)\n",
      "(2069710, 14, 2)\n",
      "(427591,)\n",
      "(2069710, 14, 2)\n",
      "(322197,)\n",
      "(2069710, 14, 2)\n",
      "(273405,)\n",
      "(2069710, 14, 2)\n",
      "(206672,)\n",
      "(2069710, 14, 2)\n",
      "(220905,)\n",
      "(2069710, 14, 2)\n",
      "(363293,)\n",
      "(2069710, 14, 2)\n",
      "(306520,)\n",
      "(2069710, 14, 2)\n",
      "(241306,)\n",
      "(2069710, 14, 2)\n",
      "(245837,)\n",
      "(2069710, 14, 2)\n",
      "(312305,)\n",
      "(2069710, 14, 2)\n",
      "(230111,)\n",
      "(2069710, 14, 2)\n",
      "(217139,)\n",
      "(2069710, 14, 2)\n",
      "(274359,)\n",
      "(2069710, 14, 2)\n",
      "(245646,)\n",
      "(2069710, 14, 2)\n",
      "(279656,)\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "#### FIND FRAMES WHICH HAVE F1/F2 ANCHORS #####\n",
    "###############################################\n",
    "\n",
    "# parse the data and resave chunks containing centre/anchor point pairs\n",
    "for animal_id in I.animal_ids:\n",
    "    I.animal_id = animal_id\n",
    "    for f1 in range(I.feature_ids.shape[0]):\n",
    "        for f2 in range(f1+1, I.feature_ids.shape[0],1):\n",
    "            break_features_pairs(f1,f2, I)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230403/230403 [00:06<00:00, 34747.42it/s]\n",
      "100%|██████████| 246257/246257 [00:06<00:00, 35555.36it/s]\n",
      "100%|██████████| 274308/274308 [00:09<00:00, 28151.59it/s]\n",
      "100%|██████████| 409718/409718 [00:14<00:00, 27510.26it/s]\n",
      "100%|██████████| 453972/453972 [00:15<00:00, 29237.15it/s]\n",
      "100%|██████████| 248357/248357 [00:08<00:00, 28130.07it/s]\n",
      "100%|██████████| 518377/518377 [00:19<00:00, 27118.90it/s]\n",
      "100%|██████████| 565952/565952 [00:19<00:00, 28429.88it/s]\n",
      "100%|██████████| 260741/260741 [00:09<00:00, 27350.35it/s]\n",
      "100%|██████████| 441885/441885 [00:15<00:00, 28697.51it/s]\n",
      "100%|██████████| 237260/237260 [00:07<00:00, 29740.36it/s]\n",
      "100%|██████████| 244677/244677 [00:07<00:00, 31652.43it/s]\n",
      "100%|██████████| 269522/269522 [00:08<00:00, 30631.89it/s]\n",
      "100%|██████████| 264280/264280 [00:06<00:00, 40528.51it/s]\n",
      "100%|██████████| 628094/628094 [00:36<00:00, 17128.65it/s]\n",
      "100%|██████████| 120073/120073 [00:02<00:00, 42265.02it/s]\n",
      "100%|██████████| 118263/118263 [00:02<00:00, 41218.24it/s]\n",
      "100%|██████████| 151170/151170 [00:03<00:00, 40562.91it/s]\n",
      "100%|██████████| 142856/142856 [00:04<00:00, 30855.03it/s]\n",
      "100%|██████████| 203186/203186 [00:05<00:00, 39043.18it/s]\n",
      "100%|██████████| 174017/174017 [00:05<00:00, 31013.02it/s]\n",
      "100%|██████████| 252295/252295 [00:07<00:00, 31608.42it/s]\n",
      "100%|██████████| 116635/116635 [00:03<00:00, 31735.43it/s]\n",
      "100%|██████████| 153324/153324 [00:04<00:00, 30948.14it/s]\n",
      "100%|██████████| 160547/160547 [00:04<00:00, 32138.95it/s]\n",
      "100%|██████████| 117849/117849 [00:03<00:00, 32294.23it/s]\n",
      "100%|██████████| 128634/128634 [00:03<00:00, 34966.85it/s]\n",
      "100%|██████████| 123964/123964 [00:03<00:00, 35773.81it/s]\n",
      "100%|██████████| 178110/178110 [00:03<00:00, 57217.80it/s]\n",
      "100%|██████████| 363199/363199 [00:18<00:00, 19727.20it/s]\n",
      "100%|██████████| 146693/146693 [00:03<00:00, 37232.02it/s]\n",
      "100%|██████████| 150173/150173 [00:05<00:00, 29949.85it/s]\n",
      "100%|██████████| 176257/176257 [00:05<00:00, 29611.19it/s]\n",
      "100%|██████████| 216636/216636 [00:06<00:00, 35528.93it/s]\n",
      "100%|██████████| 223687/223687 [00:07<00:00, 28138.90it/s]\n",
      "100%|██████████| 313498/313498 [00:11<00:00, 27967.61it/s]\n",
      "100%|██████████| 302560/302560 [00:12<00:00, 25174.64it/s]\n",
      "100%|██████████| 173131/173131 [00:07<00:00, 23808.38it/s]\n",
      "100%|██████████| 145606/145606 [00:06<00:00, 23347.11it/s]\n",
      "100%|██████████| 162704/162704 [00:06<00:00, 23987.38it/s]\n",
      "100%|██████████| 155983/155983 [00:05<00:00, 29945.89it/s]\n",
      "100%|██████████| 212970/212970 [00:08<00:00, 24150.44it/s]\n",
      "100%|██████████| 150906/150906 [00:04<00:00, 37093.93it/s]\n",
      "100%|██████████| 154460/154460 [00:04<00:00, 38403.71it/s]\n",
      "100%|██████████| 461638/461638 [00:25<00:00, 18136.34it/s]\n",
      "100%|██████████| 206672/206672 [00:05<00:00, 40963.92it/s]\n",
      "100%|██████████| 220905/220905 [00:05<00:00, 39331.98it/s]\n",
      "100%|██████████| 273405/273405 [00:07<00:00, 38994.25it/s]\n",
      "100%|██████████| 241306/241306 [00:07<00:00, 30450.25it/s]\n",
      "100%|██████████| 322197/322197 [00:08<00:00, 37273.22it/s]\n",
      "100%|██████████| 306520/306520 [00:10<00:00, 29962.40it/s]\n",
      "100%|██████████| 363293/363293 [00:12<00:00, 30231.58it/s]\n",
      "100%|██████████| 245837/245837 [00:08<00:00, 29649.99it/s]\n",
      "100%|██████████| 230111/230111 [00:07<00:00, 29979.43it/s]\n",
      "100%|██████████| 217139/217139 [00:07<00:00, 30607.73it/s]\n",
      "100%|██████████| 312305/312305 [00:10<00:00, 31011.63it/s]\n",
      "100%|██████████| 274359/274359 [00:08<00:00, 33871.75it/s]\n",
      "100%|██████████| 245646/245646 [00:06<00:00, 35189.50it/s]\n",
      "100%|██████████| 279656/279656 [00:06<00:00, 42862.95it/s]\n",
      "100%|██████████| 427591/427591 [00:24<00:00, 17604.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "#### CENTRE AND ROTATE F1/F2 FRAMES #####\n",
    "#########################################\n",
    "''' This step takes all f1/f2 eligible frames\n",
    "'''\n",
    "# \n",
    "for animal_id in I.animal_ids:\n",
    "    I.animal_id = animal_id\n",
    "    I.parallel = True\n",
    "    centre_rotate_features_pairs(I)\n",
    "            \n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "0 1  frame_ids with min 3 present features in animal:  0  is:  (628094,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 628094/628094 [00:06<00:00, 99136.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 1  frame_ids with min 3 present features in animal:  1  is:  (363199,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363199/363199 [00:03<00:00, 105458.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 1  frame_ids with min 3 present features in animal:  2  is:  (461638,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461638/461638 [00:04<00:00, 100733.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 1  frame_ids with min 3 present features in animal:  3  is:  (427591,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 427591/427591 [00:04<00:00, 93543.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "0 2  frame_ids with min 3 present features in animal:  0  is:  (518377,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 518377/518377 [00:04<00:00, 104198.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/203186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2  frame_ids with min 3 present features in animal:  1  is:  (203186,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203186/203186 [00:01<00:00, 101935.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/302560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2  frame_ids with min 3 present features in animal:  2  is:  (302560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 302560/302560 [00:02<00:00, 101685.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/322197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2  frame_ids with min 3 present features in animal:  3  is:  (322197,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322197/322197 [00:03<00:00, 99489.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "0 3  frame_ids with min 3 present features in animal:  0  is:  (409718,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 409718/409718 [00:03<00:00, 106488.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 3  frame_ids with min 3 present features in animal:  1  is: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6017/151170 [00:00<00:02, 60159.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (151170,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151170/151170 [00:01<00:00, 100695.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 3  frame_ids with min 3 present features in animal:  2  is:  (216636,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216636/216636 [00:02<00:00, 96256.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/273405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3  frame_ids with min 3 present features in animal:  3  is:  (273405,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273405/273405 [00:02<00:00, 101872.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5112/246257 [00:00<00:04, 51115.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4  frame_ids with min 3 present features in animal:  0  is:  (246257,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246257/246257 [00:02<00:00, 99558.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 4  frame_ids with min 3 present features in animal:  1  is:  (118263,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118263/118263 [00:01<00:00, 95985.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 4  frame_ids with min 3 present features in animal:  2  is:  (146693,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146693/146693 [00:01<00:00, 96037.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5855/206672 [00:00<00:03, 58547.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4  frame_ids with min 3 present features in animal:  3  is:  (206672,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206672/206672 [00:02<00:00, 102203.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/230403 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5  frame_ids with min 3 present features in animal:  0  is:  (230403,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230403/230403 [00:02<00:00, 102073.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 5  frame_ids with min 3 present features in animal:  1  is:  (120073,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120073/120073 [00:01<00:00, 101516.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/176257 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5  frame_ids with min 3 present features in animal:  2  is:  (176257,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176257/176257 [00:01<00:00, 100329.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6641/220905 [00:00<00:03, 66402.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5  frame_ids with min 3 present features in animal:  3  is:  (220905,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220905/220905 [00:02<00:00, 96961.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "1 2  frame_ids with min 3 present features in animal:  0  is:  (565952,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 565952/565952 [00:05<00:00, 96823.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 2  frame_ids with min 3 present features in animal:  1  is:  (252295,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 252295/252295 [00:02<00:00, 104086.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 2  frame_ids with min 3 present features in animal:  2  is:  (313498,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313498/313498 [00:03<00:00, 96048.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 2  frame_ids with min 3 present features in animal:  3  is:  (363293,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363293/363293 [00:03<00:00, 97102.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "1 3  frame_ids with min 3 present features in animal:  0  is:  (453972,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 453972/453972 [00:04<00:00, 101667.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 3  frame_ids with min 3 present features in animal:  1  is:  (174017,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174017/174017 [00:02<00:00, 85407.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/223687 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3  frame_ids with min 3 present features in animal:  2  is:  (223687,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223687/223687 [00:02<00:00, 100238.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/306520 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3  frame_ids with min 3 present features in animal:  3  is:  (306520,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306520/306520 [00:03<00:00, 97400.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/274308 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4  frame_ids with min 3 present features in animal:  0  is:  (274308,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274308/274308 [00:02<00:00, 101267.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 4  frame_ids with min 3 present features in animal:  1  is:  (142856,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142856/142856 [00:01<00:00, 102151.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 4  frame_ids with min 3 present features in animal:  2  is:  (150173,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150173/150173 [00:01<00:00, 96728.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/241306 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4  frame_ids with min 3 present features in animal:  3  is:  (241306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241306/241306 [00:02<00:00, 100272.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5234/248357 [00:00<00:04, 52336.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5  frame_ids with min 3 present features in animal:  0  is:  (248357,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248357/248357 [00:02<00:00, 92665.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 5  frame_ids with min 3 present features in animal:  1  is:  (153324,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153324/153324 [00:01<00:00, 100143.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 5  frame_ids with min 3 present features in animal:  2  is:  (173131,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173131/173131 [00:01<00:00, 98825.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 5  frame_ids with min 3 present features in animal:  3  is:  (245837,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245837/245837 [00:02<00:00, 102357.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "2 3  frame_ids with min 3 present features in animal:  0  is:  (441885,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441885/441885 [00:04<00:00, 100983.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4931/160547 [00:00<00:03, 49302.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3  frame_ids with min 3 present features in animal:  1  is:  (160547,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160547/160547 [00:01<00:00, 96200.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/212970 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3  frame_ids with min 3 present features in animal:  2  is:  (212970,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212970/212970 [00:02<00:00, 104239.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 3  frame_ids with min 3 present features in animal:  3  is:  (312305,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312305/312305 [00:03<00:00, 101386.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/260741 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4  frame_ids with min 3 present features in animal:  0  is:  (260741,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260741/260741 [00:02<00:00, 97602.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 4  frame_ids with min 3 present features in animal:  1  is:  (116635,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116635/116635 [00:01<00:00, 97682.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 4  frame_ids with min 3 present features in animal:  2  is:  (145606,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145606/145606 [00:01<00:00, 100237.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4970/230111 [00:00<00:04, 49646.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  frame_ids with min 3 present features in animal:  3  is:  (230111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230111/230111 [00:02<00:00, 101969.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/237260 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 5  frame_ids with min 3 present features in animal:  0  is:  (237260,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237260/237260 [00:02<00:00, 103726.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 5  frame_ids with min 3 present features in animal:  1  is:  (117849,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117849/117849 [00:01<00:00, 93283.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 5  frame_ids with min 3 present features in animal:  2  is:  (162704,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162704/162704 [00:01<00:00, 95618.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 5  frame_ids with min 3 present features in animal:  3  is: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5138/217139 [00:00<00:04, 51376.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (217139,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217139/217139 [00:02<00:00, 96440.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5128/269522 [00:00<00:05, 51273.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4  frame_ids with min 3 present features in animal:  0  is:  (269522,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269522/269522 [00:02<00:00, 100012.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3 4  frame_ids with min 3 present features in animal:  1  is:  (128634,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128634/128634 [00:01<00:00, 96190.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3 4  frame_ids with min 3 present features in animal:  2  is:  (155983,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155983/155983 [00:01<00:00, 91621.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/274359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4  frame_ids with min 3 present features in animal:  3  is:  (274359,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274359/274359 [00:02<00:00, 101089.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244677 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5  frame_ids with min 3 present features in animal:  0  is:  (244677,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244677/244677 [00:02<00:00, 96313.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6480/123964 [00:00<00:01, 64793.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5  frame_ids with min 3 present features in animal:  1  is:  (123964,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123964/123964 [00:01<00:00, 97792.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 7741/150906 [00:00<00:01, 77396.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5  frame_ids with min 3 present features in animal:  2  is:  (150906,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150906/150906 [00:01<00:00, 103396.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/245646 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5  frame_ids with min 3 present features in animal:  3  is:  (245646,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245646/245646 [00:02<00:00, 100476.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/264280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5  frame_ids with min 3 present features in animal:  0  is:  (264280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264280/264280 [00:02<00:00, 101885.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6746/178110 [00:00<00:02, 67454.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5  frame_ids with min 3 present features in animal:  1  is:  (178110,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178110/178110 [00:01<00:00, 102012.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4 5  frame_ids with min 3 present features in animal:  2  is:  (154460,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154460/154460 [00:01<00:00, 103522.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/279656 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5  frame_ids with min 3 present features in animal:  3  is:  (279656,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279656/279656 [00:02<00:00, 100786.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#### IMPUTE MISSING DATA ON THE ROTATED FRAMES ONLY #####\n",
    "#########################################################\n",
    "\n",
    "#  This function loads all data (including nans), + an f1/f2 model, and imputes \n",
    "#  missing data for frames that have at least 3 features including the f1/f2 points\n",
    "# \n",
    "I = Impute(cb)\n",
    "I.parallel = True\n",
    "I.n_cores = 4\n",
    "I.model_type = 0 \n",
    "\n",
    "# for animal_id in I.animal_ids:\n",
    "#     I.animal_id = animal_id\n",
    "I.animal_ids = np.arange(4)\n",
    "I.parallel = False\n",
    "impute_real_data_stand_alone(I)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 22.56it/s]\n",
      "  0%|          | 4700/2069710 [00:00<00:43, 46973.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_a:  (2069710, 6, 2)\n",
      "feats_imputed:  (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [04:03<00:00, 8510.15it/s] \n",
      "100%|██████████| 6/6 [00:00<00:00, 37.18it/s]\n",
      "  0%|          | 5148/2069710 [00:00<00:40, 51477.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_a:  (2069710, 6, 2)\n",
      "feats_imputed:  (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [02:34<00:00, 13371.50it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 34.64it/s]\n",
      "  0%|          | 3497/2069710 [00:00<00:59, 34886.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_a:  (2069710, 6, 2)\n",
      "feats_imputed:  (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [02:45<00:00, 12497.11it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 27.50it/s]\n",
      "  0%|          | 898/2069710 [00:00<03:50, 8978.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_a:  (2069710, 6, 2)\n",
      "feats_imputed:  (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [03:04<00:00, 11218.43it/s]\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "#### REPLACE MISSING DATA WITH MODELS WITH NEARBY FEATURES #####\n",
    "################################################################\n",
    "\n",
    "I = Impute(cb)\n",
    "I.parallel = True\n",
    "I.n_cores = 4\n",
    "I.model_type = 0 \n",
    "\n",
    "I.animal_ids = np.arange(4)\n",
    "I.parallel = False\n",
    "\n",
    "# figure out which model is most optimal for each missing feature\n",
    "# e.g. missing feature 0 ideal model is 1/2 \n",
    "best_models = [              # missing feature index\n",
    "[[1,2],[1,3]],               # 0\n",
    "[[0,2],[0,3],[2,3]],         # 1\n",
    "[[1,3],[1,4],[0,3],[0,1]],         # 2\n",
    "[[2,4],[2,5],[1,4],[1,2]],   # 3\n",
    "[[3,5],[2,5],[2,3]],         # 4\n",
    "[[3,4],[2,4]]                # 5\n",
    "]\n",
    "print (len(best_models))\n",
    "\n",
    "#########################################################\n",
    "animal_ids = np.arange(4)\n",
    "for animal_id in animal_ids:\n",
    "\n",
    "    #####################################################\n",
    "    # load all imputations for that animal_id\n",
    "    feats_imputed_array = []\n",
    "    feats_frames_array = []\n",
    "    for f1 in range(6):\n",
    "        feats_imputed_array.append([])\n",
    "        feats_frames_array.append([])\n",
    "        for f2 in range(6):\n",
    "            feats_imputed_array[f1].append([])\n",
    "            feats_frames_array[f1].append([])\n",
    "\n",
    "    # fill the lists with imputed data\n",
    "    for f1 in trange(6):\n",
    "        for f2 in range(f1+1, 6, 1):\n",
    "\n",
    "            fname_imputed = os.path.join(I.root_dir, 'centre_rotated_animalID_'+str(animal_id)+\n",
    "                                 \"_\"+str(f1)+\"_\"+str(f2)+\"_imputed_original_locations.npz\")\n",
    "\n",
    "            data = np.load(fname_imputed)\n",
    "            temp1 = data['imputed_translated']\n",
    "            temp2 = data['imputed_frames']\n",
    "\n",
    "            feats_imputed_array[f1][f2]= temp1\n",
    "            feats_frames_array[f1][f2]= temp2\n",
    "\n",
    "\n",
    "    #####################################################\n",
    "    # load raw unrotated data\n",
    "    feats = np.load(os.path.join(I.root_dir,'animalID_'+str(animal_id)+\"_alldata.npy\"))\n",
    "    feats_a = feats[:,I.feature_ids]\n",
    "    print (\"feats_a: \", feats_a.shape)\n",
    "\n",
    "    # initialize imputed array \n",
    "    feats_imputed = np.zeros(feats_a.shape,'float32')+np.nan\n",
    "    print (\"feats_imputed: \", feats_imputed.shape)\n",
    "\n",
    "    # loop over all frames\n",
    "    fname_out = os.path.join(I.root_dir, 'animalID_'+str(animal_id)+\"_alldata_imputed.npy\")\n",
    "\n",
    "    #if os.path.exists(fname_out)==False:\n",
    "    verbose=False\n",
    "    if True:\n",
    "\n",
    "        all_feats = np.arange(6)\n",
    "        for f in trange(feats_a.shape[0]):\n",
    "            feats_orig = feats_a[f]\n",
    "            feats_imputed[f] = feats_orig\n",
    "\n",
    "            # grab indexes for nans \n",
    "            idxnan = np.where(np.isnan(feats_orig[:,0]))[0]\n",
    "            idx = np.delete(all_feats, idxnan)    \n",
    "            #print (\"frame: \", f, \" idx: \", idxnan)\n",
    "\n",
    "            # if less than 2 anchors skip frame\n",
    "            if idx.shape[0]<=1:\n",
    "                continue\n",
    "            \n",
    "            # loop over all missing pieces; replace all nans with data from best model regardless of how many nans are present\n",
    "            for id_ in idxnan:\n",
    "                if verbose:\n",
    "                    print (\"frame: \", f, \"missing feature id: \", id_, \"  available features: \", idx)\n",
    "\n",
    "                # search for the best model in order of best fit (as listed above)\n",
    "                models1 = best_models[id_]\n",
    "                for mod in models1:\n",
    "\n",
    "                    # if model is found (i.e. the anchor points are availble): load files and replace data\n",
    "                    if np.intersect1d(mod,idx).shape[0]==2:\n",
    "                        #print (\"MODEL FOUND: \", mod)\n",
    "\n",
    "                        #################################\n",
    "                        frames = feats_frames_array[mod[0]][mod[1]]\n",
    "\n",
    "                        # some of the models were not used to impute \n",
    "                        try:\n",
    "                            idx_local = np.where(frames==f)[0][0]\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        temp = feats_imputed_array[mod[0]][mod[1]]\n",
    "                        temp = temp[idx_local][id_] \n",
    "\n",
    "                        feats_imputed[f,id_] = temp\n",
    "                        \n",
    "                        if verbose:\n",
    "                            print (\"Grabbing model \", mod, \" imputation results at location: \", id_, \" temp: \", temp)\n",
    "\n",
    "                        # do not look for other models to impute at this location;\n",
    "                        break\n",
    "            if verbose:\n",
    "                print ('')\n",
    "        np.save(fname_out, feats_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [00:19<00:00, 105671.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [00:19<00:00, 106272.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [00:19<00:00, 105952.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [00:19<00:00, 108632.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710,)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "animal_ids = np.arange(4)\n",
    "for animal_id in animal_ids:\n",
    "    plt.subplot(2,2,animal_id+1)\n",
    "    feature_ids = np.array([0,5,6,7,8,9])\n",
    "    d = np.load('/media/cat/1TB/dan/cohort1/slp/animalID_'+str(animal_id)+'_alldata.npy')[:,feature_ids]\n",
    "    d_imp = np.load('/media/cat/1TB/dan/cohort1/slp/animalID_'+str(animal_id)+'_alldata_imputed.npy')\n",
    "\n",
    "    n_feats = []\n",
    "    n_feats_imp = []\n",
    "    for k in trange(d.shape[0]):\n",
    "        idx = np.array(np.where(np.isnan(d[k,:,0])==False)[0])\n",
    "        idx2 = np.array(np.where(np.isnan(d_imp[k,:,0])==False)[0])\n",
    "\n",
    "        #print (k, idx, idx.shape)\n",
    "        n_feats.append(idx.shape[0])\n",
    "        n_feats_imp.append(idx2.shape[0])\n",
    "\n",
    "    n_feats = np.array(n_feats)\n",
    "    print (n_feats.shape)\n",
    "    n_feats_imp = np.array(n_feats_imp)\n",
    "\n",
    "    width = 1\n",
    "    bins = np.arange(-0.5,7,width)\n",
    "\n",
    "    y = np.histogram(n_feats,bins=bins)\n",
    "    y2 = np.histogram(n_feats_imp, bins=bins)\n",
    "\n",
    "    plt.plot(y[1][1:]-0.5,y[0],c='black', label = 'Sleap')\n",
    "    plt.plot(y2[1][1:]-0.5,y2[0],c='blue', label = 'Imputation')\n",
    "\n",
    "    cumsum = np.cumsum(y[0][::-1])\n",
    "    plt.plot(y[1][1:][::-1]-0.5,cumsum, c= 'red', label = \"Sleap - cumulative sum\",\n",
    "            linewidth=5)\n",
    "    cumsum = np.cumsum(y2[0][::-1])\n",
    "    plt.plot(y[1][1:][::-1]-0.5,cumsum, '--', c= 'red', label = \"Imputation - cumulative sum\",\n",
    "            linewidth=5)\n",
    "    \n",
    "    #plt.semilogy()\n",
    "    plt.xlim(0.5,6.5)\n",
    "    plt.ylim(0,750000)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.title(\"animal id: \"+ str(animal_id))\n",
    "    plt.ylabel(\"# frames\")\n",
    "    plt.xlabel(\"# of features in frame\")\n",
    "    plt.plot([3,3],[0,750000],'--',c='black',linewidth=3,alpha=.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1243944   86107  160024  146467  182678   31808  218682]\n",
      "[ 218682  250490  433168  579635  739659  825766 2069710]\n"
     ]
    }
   ],
   "source": [
    "print(y[0])\n",
    "print (np.cumsum(y[0][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710,)\n"
     ]
    }
   ],
   "source": [
    "n_feats = np.array(n_feats)\n",
    "print (n_feats.shape)\n",
    "n_feats_imp = np.array(n_feats_imp)\n",
    "\n",
    "width = 1\n",
    "bins = np.arange(0.5,7,width)\n",
    "\n",
    "y = np.histogram(n_feats,bins=bins)\n",
    "y2 = np.histogram(n_feats_imp, bins=bins)\n",
    "\n",
    "plt.plot(y[1][1:]+0.5,y[0],c='black', label = 'Sleap')\n",
    "plt.plot(y2[1][1:]+0.5,y2[0],c='blue', label = 'Sleap + imputation')\n",
    "    \n",
    "#plt.semilogy()\n",
    "plt.xlim(1,7)\n",
    "plt.ylim(bottom=0)\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"animal id: \"+ str(animal_id))\n",
    "plt.ylabel(\"# frames\")\n",
    "# \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 815.5662    248.4631  ]\n",
      "  [ 828.0727    212.18002 ]\n",
      "  [ 856.01      204.01614 ]\n",
      "  [ 865.5865    185.22838 ]\n",
      "  [ 864.8135    163.06822 ]\n",
      "  [ 858.07983   144.82709 ]]\n",
      "\n",
      " [[ 815.54205   248.4631  ]\n",
      "  [ 828.0727    212.19121 ]\n",
      "  [ 855.9853    204.01614 ]\n",
      "  [ 865.57605   185.23795 ]\n",
      "  [ 864.8342    163.0905  ]\n",
      "  [ 858.12427   144.85498 ]]\n",
      "\n",
      " [[ 815.54205   248.4631  ]\n",
      "  [ 828.0727    212.24358 ]\n",
      "  [ 855.9771    204.01614 ]\n",
      "  [ 865.5792    185.2284  ]\n",
      "  [ 864.85626   163.09923 ]\n",
      "  [ 858.176     144.87238 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1003.80945   123.85146 ]\n",
      "  [ 976.056     120.63238 ]\n",
      "  [ 943.31604   132.44987 ]\n",
      "  [ 920.0462    124.01467 ]\n",
      "  [ 904.6494    111.888695]\n",
      "  [ 893.4489    107.69545 ]]\n",
      "\n",
      " [[ 940.41614    99.940254]\n",
      "  [ 915.248     123.777016]\n",
      "  [ 907.865     144.44054 ]\n",
      "  [ 886.83026   155.86105 ]\n",
      "  [ 867.07166   164.44434 ]\n",
      "  [ 858.3316    174.203   ]]\n",
      "\n",
      " [[ 939.6487     99.35089 ]\n",
      "  [ 915.185     123.777016]\n",
      "  [ 907.865     144.2303  ]\n",
      "  [ 887.1728    156.26631 ]\n",
      "  [ 867.86      165.56894 ]\n",
      "  [ 859.4652    175.70676 ]]]\n"
     ]
    }
   ],
   "source": [
    "feature_ids = np.array([0,5,6,7,8,9])\n",
    "d = np.load('/media/cat/1TB/dan/cohort1/slp/animalID_0_alldata.npy')[:,feature_ids]\n",
    "d_imp = np.load('/media/cat/1TB/dan/cohort1/slp/animalID_0_alldata_imputed.npy')\n",
    "\n",
    "\n",
    "idx_all = np.arange(d.shape[0])\n",
    "ctr=0\n",
    "sizes = (np.arange(1,7,1)*0.1)[::-1]\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "while ctr<10:\n",
    "#while True:\n",
    "    idx = np.random.choice(idx_all, 1)[0]\n",
    "    idx2 = np.where(np.isnan(d[idx][:,0])==False)[0]\n",
    "    idx3 = np.where(np.isnan(d_imp[idx,:,0])==False)[0]\n",
    "\n",
    "    if idx2.shape[0] != idx3.shape[0] and idx2.shape[0]>=5:\n",
    "\n",
    "    #if idx2.shape[0]>=2:\n",
    "\n",
    "        #idx3 = np.where(np.isnan(d_imp[idx,:,0])==False)[0]\n",
    "\n",
    "        print (idx, idx2, idx3, sizes[idx2])\n",
    "\n",
    "        print (\"preimupted: \", d[idx])\n",
    "\n",
    "        plt.subplot(2,5,ctr+1)\n",
    "        ss = np.zeros((6))+np.nan\n",
    "        ss[idx3] = sizes[idx3]\n",
    "        plt.scatter(d_imp[idx,:,0],\n",
    "                    d_imp[idx,:,1],\n",
    "                    s=ss,\n",
    "                    c='blue')\n",
    "\n",
    "        ss = np.zeros((6))+np.nan\n",
    "        ss[idx2] = sizes[idx2]\n",
    "        print (\"sizes: \", ss)\n",
    "        plt.scatter(d[idx,:,0],\n",
    "                    d[idx,:,1],\n",
    "                    s=ss,\n",
    "                    c='black')\n",
    " \n",
    "        ctr+=1\n",
    "        plt.title(str(idx)+ \" \" +str(idx2), fontsize=3, pad=0.8)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.xlim(0,1280)\n",
    "        plt.ylim(0,1280)\n",
    "\n",
    "if True:\n",
    "    plt.savefig('/home/cat/impute.png', dpi=300)\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#### VISUALIZE IMPUTATIONS + MOVIES #####\n",
    "#########################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80630288 (89989, 4, 14, 2) 80630144\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "data = np.load('/media/cat/1TB/dan/cohort1/slp/2020_3_16_12_57_12_418305_compressed.npy')\n",
    "print (getsizeof(data), data.shape, data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/media/cat/1TB/dan/cohort1/slp/centre_rotated_animalID_0_0_1.npz', allow_pickle=True)\n",
    "\n",
    "\n",
    "feats = data['feats_rotated']\n",
    "print (feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################    \n",
    "#### UNSHIFT/UNROTATE RESULTS ##\n",
    "################################\n",
    "\n",
    "# visualize before and after results in video form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89988, 4, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/media/cat/1TB/dan/cohort1/slp/2020_3_16_01_57_27_327194_compressed_median_filtered_outliers_centre_aligned_0_1.npz',\n",
    "              allow_pickle=True)\n",
    "\n",
    "feats = data['features_full']\n",
    "print (feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 14, 2)\n",
      " male:                               (2069710, 14, 2)\n",
      " pup1:                               (2069710, 14, 2)\n",
      " pup2:                               (2069710, 14, 2)\n",
      "(2069710, 14, 2)\n"
     ]
    }
   ],
   "source": [
    "f1 = 0\n",
    "f2 = 1\n",
    "feats = load_processed_data_stand_alone(f1,f2,I.March16_file_order, I.root_dir, I.animal_ids, data_type=1, remove_nans=False)\n",
    "print (np.vstack(feats[0]).shape)\n",
    "for k in range(I.animal_ids.shape[0]):\n",
    "    np.save(I.root_dir+'/animalID_'+str(k)+'_alldata.npy', np.vstack(feats[k]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5856  9187  9188 ... 60156 60157 60158] (9581,)\n",
      "(9581, 4, 6, 2)\n",
      "[[[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [-2.6053378e-16 -2.7597610e+01]\n",
      "   [ 4.1872730e+00 -4.4353676e+01]\n",
      "   [ 1.4419242e+01 -5.2421986e+01]\n",
      "   [ 2.2772881e+01 -7.9629517e+01]\n",
      "   [ 1.8599001e+01 -8.9770401e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]\n",
      "\n",
      "\n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.1549951e-15 -3.3143169e+01]\n",
      "   [ 1.9924431e+01 -6.0728550e+01]\n",
      "   [ 4.1260765e+01 -7.2759247e+01]\n",
      "   [ 6.9983749e+01 -9.3388031e+01]\n",
      "   [ 9.0890884e+01 -9.2662331e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]\n",
      "\n",
      "\n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [ 6.4845387e-15 -2.9197412e+01]\n",
      "   [ 2.1278805e+01 -5.5735901e+01]\n",
      "   [ 4.5587433e+01 -5.7687469e+01]\n",
      "   [ 8.0397346e+01 -6.4214302e+01]\n",
      "   [ 9.9035080e+01 -5.4713242e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.6115594e-15 -2.8648689e+01]\n",
      "   [-7.4477320e+00 -4.7606289e+01]\n",
      "   [-1.1588045e+01 -6.8303955e+01]\n",
      "   [-2.6754072e+01 -8.3746643e+01]\n",
      "   [-5.0876167e+01 -8.2087845e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]\n",
      "\n",
      "\n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [ 7.3422713e-15 -2.8082731e+01]\n",
      "   [-3.0128274e+00 -4.8088001e+01]\n",
      "   [-5.2030911e+00 -6.9082230e+01]\n",
      "   [-1.5235621e+01 -8.7014023e+01]\n",
      "   [-4.3044250e+01 -8.6452248e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]\n",
      "\n",
      "\n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.8554778e-15 -3.1283270e+01]\n",
      "   [-4.7501010e-01 -4.8179947e+01]\n",
      "   [-1.5560009e+00 -6.9260033e+01]\n",
      "   [-1.0629916e+01 -8.7695892e+01]\n",
      "   [-3.8429516e+01 -8.8600060e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]]\n"
     ]
    }
   ],
   "source": [
    "idx = np.unique(np.where(np.isnan(feats)==False)[0])\n",
    "print (idx, idx.shape)\n",
    "feats2 = feats[idx]\n",
    "print (feats2.shape)\n",
    "print (feats2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # load filtered + outliner triaged data with Nans removed\n",
    "# I.cb.load_processed_data(f1, f2,\n",
    "#                          data_type=0,\n",
    "#                          remove_nans=True)\n",
    "        \n",
    "        \n",
    "# I.load_models()\n",
    "\n",
    "\n",
    "# # test against ground truth/cleand data \n",
    "# I.fname_dropout = '/home/cat/feats_dropout.tsv'\n",
    "# res, idx_drop = I.predict_imputation_ground_truth(drops=np.arange(3,6,1)) # drops = 'fixed' or None\n",
    "\n",
    "# # check missing features in the data\n",
    "# # I.calculate_missing_features()\n",
    "\n",
    "# # \n",
    "# # I.plot_imputation_results(features_array, animal_id, idx_test, res, idx_drop)\n",
    "# plt.suptitle(\"animal \"+str(animal_id)+ \" imputed vs. ground truth\",fontsize=20)\n",
    "\n",
    "# # \n",
    "# I.evaluate_imputation_error(features_array, animal_id, res, idx_train, idx_test)\n",
    "# plt.suptitle(\"animal \"+str(animal_id)+ \"  Egocentric (fixed nose) errors (pixels)\",fontsize=20)\n",
    "# #plt.suptitle(\"animal \"+str(animal_id)+ \" NON-Egocentric (fixed nose) errors (pixels)\",fontsize=20)\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 5 4]\n",
      " [0 5 1]\n",
      " [2 4 0]\n",
      " ...\n",
      " [0 4 1]\n",
      " [4 5 0]\n",
      " [4 1 5]]\n",
      "(109565,)\n",
      "(109445,)\n",
      "(44043,)\n",
      "[[5 1 2]\n",
      " [1 2 0]\n",
      " [4 1 2]\n",
      " ...\n",
      " [1 5 2]\n",
      " [5 2 1]\n",
      " [1 4 2]]\n"
     ]
    }
   ],
   "source": [
    "# select some random drops for each\n",
    "drops = np.load('/home/cat/temp_f1f2_drops.npy')\n",
    "print (drops)\n",
    "\n",
    "idx1 = np.where(drops==1)[0]\n",
    "idx2 = np.where(drops==2)[0]\n",
    "print (idx1.shape)\n",
    "print (idx2.shape)\n",
    "\n",
    "idx3 = np.intersect1d(idx1, idx2)\n",
    "print (idx3.shape)\n",
    "print (drops[idx3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "random_sample() takes at most 1 positional argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9a00fd32ea32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.sample\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.random_sample\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: random_sample() takes at most 1 positional argument (2 given)"
     ]
    }
   ],
   "source": [
    "idx = np.random.sample(np.arange(6), 1)\n",
    "print (idx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9f4b180bc87c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute the error vs. ground truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_imputation_multivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# VAE CODE NOT USED NOW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/gerbil/movement_analysis/Imputation.py\u001b[0m in \u001b[0;36mevaluate_imputation_multivariate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0mtdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mtdiff\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m                     \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compute the error vs. ground truth\n",
    "I.evaluate_imputation_multivariate()\n",
    "\n",
    "\n",
    "# VAE CODE NOT USED NOW \n",
    "# make_vae_data()\n",
    "\n",
    "# df1 = evaluate_imputation_vae()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218641, 12)\n",
      "(1093205, 12)\n",
      "(218641, 12)\n",
      "(218641, 12)\n",
      "(1093205, 12)\n",
      "(218641, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "dropped_features= [0,1,2]\n",
    "I.plot_vae_scatter(dropped_features)  \n",
    "    \n",
    "#        \n",
    "I.plot_multiple_imputation_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "from scipy.spatial import cKDTree\n",
    "import joblib\n",
    "\n",
    "def knn_triage(th, pca_wf):\n",
    "    tree = cKDTree(pca_wf)\n",
    "    dist, ind = tree.query(pca_wf, k=6)\n",
    "    dist = np.sum(dist, 1)\n",
    "    idx_keep1 = dist <= np.percentile(dist, th)\n",
    "    return idx_keep1\n",
    "\n",
    "\n",
    "\n",
    "# Fit the PCA object, but do not transform the data\n",
    "for k in range(4):\n",
    "    ax=plt.subplot(2,2,k+1)\n",
    "    \n",
    "    temp = features_array[k]\n",
    "    d = []\n",
    "    clrs = []\n",
    "    for p in range(len(temp)):\n",
    "        d.append(temp[p])\n",
    "        clrs.extend(np.zeros(temp[p].shape[0])+p)\n",
    "    \n",
    "    clrs = np.array(clrs)\n",
    "    d = np.vstack(d)\n",
    "    print (\"D: \", d.shape)\n",
    "    d = d.reshape(d.shape[0],-1)\n",
    "    continue\n",
    "    #d = sklearn.preprocessing.normalize(d)\n",
    "\n",
    "    # remove 1% of outliers\n",
    "    if True:\n",
    "        th = 95  # % of data to keep\n",
    "        idx_keep = knn_triage(th, d)\n",
    "        print (\" d before traige: \", d.shape)\n",
    "        d = d[idx_keep]\n",
    "        print (\" d after traige: \", d.shape)\n",
    "        clrs = clrs[idx_keep]\n",
    "    \n",
    "    \n",
    "    if False:\n",
    "        pca = PCA(2)\n",
    "\n",
    "        print (\"... data into pca: \", d.shape)\n",
    "\n",
    "        feats_pca = pca.fit_transform(d)\n",
    "        print (feats_pca.shape)\n",
    "\n",
    "        # \n",
    "        plt.scatter(feats_pca[::5,0],\n",
    "           feats_pca[::5,1],\n",
    "            #c=np.arange(feats_pca.shape[0])[::5],\n",
    "            c=clrs[::5],\n",
    "            alpha=.05)\n",
    "        \n",
    "    if True:\n",
    "        \n",
    "#         import gpumap\n",
    "#         #from sklearn.datasets import load_digits\n",
    "\n",
    "#         #digits = load_digits()\n",
    "#         print (\"Data into gpumap: \", d.shape)\n",
    "#         feats_pca = gpumap.GPUMAP().fit_transform(d)\n",
    "#         print (\"Data out of gpumap: \", feats_pca.shape)\n",
    "\n",
    "        import umap\n",
    "    \n",
    "        umap = umap.UMAP(n_components=2,\n",
    "                        init='random',\n",
    "                        random_state=0)\n",
    "        \n",
    "        d = d[::2]\n",
    "        clrs = clrs[::2]\n",
    "        \n",
    "        print (\"... data into umap: \", d.shape)\n",
    "        \n",
    "        if False:\n",
    "            umap_ = umap.fit(d) #[::10])\n",
    "            feats_pca = umap_.transform(d)\n",
    "        else:\n",
    "            feats_pca = umap.fit_transform(d) #[::10])\n",
    "        \n",
    "        \n",
    "            # remove 1% of outliers\n",
    "        if True:\n",
    "            th = 90  # % of data to keep\n",
    "            idx_keep = knn_triage(th, feats_pca)\n",
    "            print (\" d before traige: \", feats_pca.shape)\n",
    "            feats_pca = feats_pca[idx_keep]\n",
    "            print (\" d after traige: \", feats_pca.shape)\n",
    "            clrs = clrs[idx_keep]\n",
    "        \n",
    "        plt.scatter(feats_pca[:,0],\n",
    "               feats_pca[:,1],\n",
    "                #c=np.arange(feats_pca.shape[0])[::5],\n",
    "                c=clrs,\n",
    "                alpha=.05)\n",
    "    if False:\n",
    "        \n",
    "        #from openTSNE import TSNE\n",
    "        #print (\"... data into tsne: \", d.shape)\n",
    "        #feats_pca = TSNE().fit(d)\n",
    "        \n",
    "        \n",
    "        from fastTSNE import TSNE\n",
    "\n",
    "        tsne = TSNE(\n",
    "            n_components=2, perplexity=30, learning_rate=100, early_exaggeration=12,\n",
    "            n_jobs=4, \n",
    "            #angle=0.5, \n",
    "            initialization='random', metric='euclidean',\n",
    "            n_iter=750, early_exaggeration_iter=250, neighbors='exact',\n",
    "            negative_gradient_method='bh', min_num_intervals=10,\n",
    "            #ints_in_inverval=2, \n",
    "            #late_exaggeration_iter=100, \n",
    "            #late_exaggeration=4,\n",
    "        )\n",
    "        \n",
    "        # \n",
    "        feats_pca = tsne.fit(d)\n",
    "\n",
    "        print (\" output: \", feats_pca.shape)\n",
    "\n",
    "\n",
    "        plt.scatter(feats_pca[:,0],\n",
    "            feats_pca[:,1],\n",
    "            #c=np.arange(feats_pca.shape[0])[::5],\n",
    "            c=clrs,\n",
    "            alpha=.05)\n",
    "\n",
    "    # \n",
    "    plt.title(\"Animal:\"+str(k))\n",
    "    \n",
    "    \n",
    "plt.suptitle(\"Static vertically aligned postures\",fontsize=20)\n",
    "plt.show()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.57  4.58  6.43  8.56]\n"
     ]
    }
   ],
   "source": [
    "lens = [218641, 94647, 132861, 176982]\n",
    "\n",
    "lens = np.array(lens)\n",
    "print (np.round(lens/(23*89900)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 6. 12.]\n",
      " [ 3.  6.]]\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "############### IMPUTE MISSING DATA #############\n",
    "#################################################\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp.fit([[1, 2], [3, 6], [4, 8], [np.nan, 3], [7, np.nan]])\n",
    "X_test = [[np.nan, 2], [6, np.nan], [np.nan, 6]]\n",
    "# the model learns that the second feature is double the first\n",
    "\n",
    "print(np.round(imp.transform(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177945, 25)\n",
      "(77827,)\n",
      "[[0.         0.         0.         ... 0.15860032 0.15860032 0.15860032]\n",
      " [0.         0.         0.         ... 0.15860032 0.15860032 0.15860032]\n",
      " [0.         0.         0.         ... 0.15860032 0.15860032 0.15860032]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "0 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.16658191 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.16658191 0.14309867 0.15860032 0.15860032\n",
      " 0.15860032]\n",
      "\n",
      "1 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.16658191 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.16658191 0.14309867 0.15860032 0.15860032 0.15860032\n",
      " 0.15860032]\n",
      "\n",
      "2 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.16658191 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.16658191 0.14309867 0.15860032 0.15860032 0.15860032 0.15860032\n",
      " 0.15860032]\n",
      "\n",
      "3 [0.         0.         0.         0.         0.         0.\n",
      " 0.16658191 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526 0.16658191\n",
      " 0.14309867 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032\n",
      " 0.15860032]\n",
      "\n",
      "4 [0.         0.         0.         0.         0.         0.16658191\n",
      " 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.15625526 0.15625526 0.16658191 0.14309867\n",
      " 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032\n",
      " 0.15860032]\n",
      "\n",
      "5 [0.         0.         0.         0.         0.16658191 0.15625526\n",
      " 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.15625526 0.16658191 0.14309867 0.15860032\n",
      " 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032\n",
      " 0.15860032]\n",
      "\n",
      "6 [0.         0.         0.         0.16658191 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.16658191 0.14309867 0.15860032 0.15860032\n",
      " 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032\n",
      " 0.15860032]\n",
      "\n",
      "7 [0.         0.         0.16658191 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.16658191 0.14309867 0.15860032 0.15860032 0.15860032\n",
      " 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032\n",
      " 0.15860032]\n",
      "\n",
      "8 [0.         0.16658191 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526 0.15625526\n",
      " 0.16658191 0.14309867 0.15860032 0.15860032 0.15860032 0.15860032\n",
      " 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032 0.15860032\n",
      " 0.15860032]\n",
      "\n",
      "9 [ 0.         -0.01032665 -0.01032665 -0.01032665 -0.01032665 -0.01032665\n",
      " -0.01032665 -0.01032665 -0.01032665 -0.01032665 -0.01032665  0.\n",
      " -0.02348326 -0.00798161 -0.00798161 -0.00798161 -0.00798161 -0.00798161\n",
      " -0.00798161 -0.00798161 -0.00798161 -0.00798161 -0.00798161 -0.00798161\n",
      " -0.00798161]\n",
      "\n",
      "10 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.01032665 -0.0131566\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504]\n",
      "\n",
      "11 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.01032665 -0.0131566   0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504]\n",
      "\n",
      "12 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.01032665 -0.0131566   0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504]\n",
      "\n",
      "13 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.01032665 -0.0131566   0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504]\n",
      "\n",
      "14 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.01032665 -0.0131566   0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504]\n",
      "\n",
      "15 [ 0.          0.          0.          0.          0.          0.01032665\n",
      " -0.0131566   0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504]\n",
      "\n",
      "16 [ 0.          0.          0.          0.          0.01032665 -0.0131566\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504]\n",
      "\n",
      "17 [ 0.          0.          0.          0.01032665 -0.0131566   0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504]\n",
      "\n",
      "18 [ 0.          0.          0.01032665 -0.0131566   0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504]\n",
      "\n",
      "19 [ 0.          0.01032665 -0.0131566   0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504  0.00234504\n",
      "  0.00234504]\n",
      "\n",
      "20 [ 0.         -0.02348326 -0.00798161 -0.00798161 -0.00798161 -0.00798161\n",
      " -0.00798161 -0.00798161 -0.00798161 -0.00798161 -0.00798161 -0.00798161\n",
      " -0.00798161 -0.00798161 -0.00798161 -0.00798161 -0.00798161 -0.00798161\n",
      " -0.00798161 -0.00798161 -0.00798161 -0.00798161 -0.00798161 -0.00798161\n",
      " -0.00798161]\n",
      "\n",
      "21 [0.         0.01550164 0.01550164 0.01550164 0.01550164 0.01550164\n",
      " 0.01550164 0.01550164 0.01550164 0.01550164 0.01550164 0.01550164\n",
      " 0.01550164 0.01550164 0.01550164 0.01550164 0.01550164 0.01550164\n",
      " 0.01550164 0.01550164 0.01550164 0.01550164 0.01550164 0.01550164\n",
      " 0.01550164]\n",
      "\n",
      "22 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "23 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "24 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "25 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "26 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "27 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "28 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "29 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "30 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "31 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "32 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "33 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "34 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "35 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "36 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "37 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "38 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "39 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "40 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "41 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "42 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "43 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "44 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "45 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "46 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "47 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "48 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "49 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "50 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "51 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "52 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "53 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "54 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "55 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "56 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "57 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "58 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "59 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "60 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "61 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "62 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "63 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "64 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "65 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "66 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "67 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "68 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "69 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "70 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "71 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "72 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "73 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "74 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "75 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "76 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "77 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "78 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "79 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "80 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "81 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "82 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "83 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "84 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "85 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "86 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "87 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "88 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "89 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "90 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "91 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "92 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "93 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "94 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "95 [ 0.         -0.00086393 -0.00691694 -0.01165324 -0.01165324 -0.01165324\n",
      " -0.01587209 -0.01799941 -0.01998621 -0.03163252 -0.03112554 -0.03112554\n",
      " -0.03112554 -0.03163252 -0.04225879 -0.04617256 -0.04720333 -0.05056454\n",
      " -0.06289025 -0.06521266 -0.06582214 -0.07289552 -0.09057564 -0.09085298\n",
      " -0.11366384]\n",
      "\n",
      "96 [ 0.         -0.00605304 -0.01078933 -0.01078933 -0.01078933 -0.01500819\n",
      " -0.0171355  -0.0191223  -0.03076862 -0.0302616  -0.0302616  -0.0302616\n",
      " -0.03076862 -0.04139485 -0.04530864 -0.04633937 -0.04970058 -0.06202629\n",
      " -0.0643487  -0.06495818 -0.07203155 -0.08971168 -0.08998902 -0.11279985\n",
      " -0.11350832]\n",
      "\n",
      "97 [ 0.         -0.00473632 -0.00473632 -0.00473632 -0.00895512 -0.01108241\n",
      " -0.01306929 -0.02471557 -0.02420858 -0.02420858 -0.02420858 -0.02471557\n",
      " -0.03534181 -0.03925561 -0.04028637 -0.0436476  -0.0559733  -0.05829569\n",
      " -0.05890519 -0.06597857 -0.08365867 -0.08393604 -0.10674684 -0.10745531\n",
      " -0.10745531]\n",
      "\n",
      "98 [ 0.          0.          0.         -0.0042188  -0.00634609 -0.00833297\n",
      " -0.01997925 -0.01947228 -0.01947228 -0.01947228 -0.01997925 -0.03060547\n",
      " -0.03451931 -0.03555007 -0.03891131 -0.051237   -0.0535594  -0.05416889\n",
      " -0.06124227 -0.07892237 -0.07919975 -0.10201056 -0.10271902 -0.10271902\n",
      " -0.10604733]\n",
      "\n",
      "99 [ 0.          0.         -0.0042188  -0.00634609 -0.00833297 -0.01997925\n",
      " -0.01947228 -0.01947228 -0.01947228 -0.01997925 -0.03060547 -0.03451931\n",
      " -0.03555007 -0.03891131 -0.051237   -0.0535594  -0.05416889 -0.06124227\n",
      " -0.07892237 -0.07919975 -0.10201056 -0.10271902 -0.10271902 -0.10604733\n",
      " -0.7018435 ]\n",
      "\n",
      "100 [ 0.         -0.0042188  -0.00634609 -0.00833297 -0.01997925 -0.01947228\n",
      " -0.01947228 -0.01947228 -0.01997925 -0.03060547 -0.03451931 -0.03555007\n",
      " -0.03891131 -0.051237   -0.0535594  -0.05416889 -0.06124227 -0.07892237\n",
      " -0.07919975 -0.10201056 -0.10271902 -0.10271902 -0.10604733 -0.7018435\n",
      " -0.7018435 ]\n",
      "\n",
      "101 [ 0.         -0.00212729 -0.00411417 -0.01576045 -0.01525344 -0.01525344\n",
      " -0.01525344 -0.01576045 -0.02638666 -0.03030045 -0.03133126 -0.0346925\n",
      " -0.04701819 -0.04934059 -0.04995009 -0.05702346 -0.07470357 -0.07498094\n",
      " -0.09779175 -0.09850022 -0.09850022 -0.10182855 -0.69762474 -0.69762474\n",
      " -0.69762474]\n",
      "\n",
      "102 [ 0.         -0.00198688 -0.01363315 -0.01312612 -0.01312612 -0.01312612\n",
      " -0.01363315 -0.02425938 -0.02817314 -0.0292039  -0.03256514 -0.04489083\n",
      " -0.04721323 -0.04782273 -0.0548961  -0.0725762  -0.07285357 -0.09566443\n",
      " -0.09637292 -0.09637292 -0.09970121 -0.6954974  -0.6954974  -0.6954974\n",
      " -0.6954974 ]\n",
      "\n",
      "103 [ 0.         -0.01164627 -0.01113931 -0.01113931 -0.01113931 -0.01164627\n",
      " -0.02227254 -0.02618632 -0.02721709 -0.03057833 -0.04290402 -0.04522642\n",
      " -0.04583592 -0.05290929 -0.07058939 -0.07086676 -0.09367758 -0.09438602\n",
      " -0.09438602 -0.09771436 -0.69351053 -0.69351053 -0.69351053 -0.69351053\n",
      " -0.6960139 ]\n",
      "\n",
      "104 [ 0.0000000e+00  5.0699501e-04  5.0699501e-04  5.0699501e-04\n",
      "  0.0000000e+00 -1.0626231e-02 -1.4540038e-02 -1.5570783e-02\n",
      " -1.8932022e-02 -3.1257711e-02 -3.3580109e-02 -3.4189604e-02\n",
      " -4.1262981e-02 -5.8943082e-02 -5.9220452e-02 -8.2031257e-02\n",
      " -8.2739726e-02 -8.2739726e-02 -8.6068071e-02 -6.8186420e-01\n",
      " -6.8186420e-01 -6.8186420e-01 -6.8186420e-01 -6.8436760e-01\n",
      " -6.8532103e-01]\n",
      "\n",
      "105 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 -5.0699501e-04\n",
      " -1.1133228e-02 -1.5047050e-02 -1.6077789e-02 -1.9439017e-02\n",
      " -3.1764720e-02 -3.4087125e-02 -3.4696601e-02 -4.1769966e-02\n",
      " -5.9450082e-02 -5.9727453e-02 -8.2538262e-02 -8.3246745e-02\n",
      " -8.3246745e-02 -8.6575069e-02 -6.8237126e-01 -6.8237126e-01\n",
      " -6.8237126e-01 -6.8237126e-01 -6.8487465e-01 -6.8582809e-01\n",
      " -6.8606132e-01]\n",
      "\n",
      "106 [ 0.0000000e+00  0.0000000e+00 -5.0699501e-04 -1.1133228e-02\n",
      " -1.5047050e-02 -1.6077789e-02 -1.9439017e-02 -3.1764720e-02\n",
      " -3.4087125e-02 -3.4696601e-02 -4.1769966e-02 -5.9450082e-02\n",
      " -5.9727453e-02 -8.2538262e-02 -8.3246745e-02 -8.3246745e-02\n",
      " -8.6575069e-02 -6.8237126e-01 -6.8237126e-01 -6.8237126e-01\n",
      " -6.8237126e-01 -6.8487465e-01 -6.8582809e-01 -6.8606132e-01\n",
      " -6.8725485e-01]\n",
      "\n",
      "107 [ 0.0000000e+00 -5.0699501e-04 -1.1133228e-02 -1.5047050e-02\n",
      " -1.6077789e-02 -1.9439017e-02 -3.1764720e-02 -3.4087125e-02\n",
      " -3.4696601e-02 -4.1769966e-02 -5.9450082e-02 -5.9727453e-02\n",
      " -8.2538262e-02 -8.3246745e-02 -8.3246745e-02 -8.6575069e-02\n",
      " -6.8237126e-01 -6.8237126e-01 -6.8237126e-01 -6.8237126e-01\n",
      " -6.8487465e-01 -6.8582809e-01 -6.8606132e-01 -6.8725485e-01\n",
      " -6.9130939e-01]\n",
      "\n",
      "108 [ 0.         -0.01062623 -0.01454004 -0.01557078 -0.01893202 -0.03125771\n",
      " -0.03358011 -0.0341896  -0.04126298 -0.05894308 -0.05922045 -0.08203126\n",
      " -0.08273973 -0.08273973 -0.08606807 -0.6818642  -0.6818642  -0.6818642\n",
      " -0.6818642  -0.6843676  -0.68532103 -0.68555427 -0.68674785 -0.6908024\n",
      " -0.6908575 ]\n",
      "\n",
      "109 [ 0.         -0.0039138  -0.00494457 -0.00830578 -0.02063148 -0.02295389\n",
      " -0.02356336 -0.03063676 -0.04831687 -0.04859421 -0.07140506 -0.07211357\n",
      " -0.07211357 -0.07544186 -0.671238   -0.671238   -0.671238   -0.671238\n",
      " -0.67374134 -0.67469484 -0.67492807 -0.6761216  -0.68017614 -0.68023133\n",
      " -0.67618847]\n",
      "\n",
      "110 [ 0.         -0.00103075 -0.00439198 -0.01671767 -0.01904007 -0.01964954\n",
      " -0.02672293 -0.04440305 -0.0446804  -0.06749126 -0.06819973 -0.06819973\n",
      " -0.07152808 -0.66732424 -0.66732424 -0.66732424 -0.66732424 -0.66982764\n",
      " -0.670781   -0.6710143  -0.67220783 -0.6762624  -0.67631745 -0.67227465\n",
      " -0.6710845 ]\n",
      "\n",
      "111 [ 0.         -0.00336125 -0.01568695 -0.01800933 -0.01861882 -0.02569217\n",
      " -0.04337231 -0.04364966 -0.06646047 -0.06716897 -0.06716897 -0.0704973\n",
      " -0.66629344 -0.66629344 -0.66629344 -0.66629344 -0.6687969  -0.66975033\n",
      " -0.6699835  -0.6711771  -0.6752316  -0.6752867  -0.67124385 -0.6700538\n",
      " -0.6698212 ]\n",
      "\n",
      "112 [ 0.         -0.0123257  -0.01464808 -0.01525758 -0.02233093 -0.04001107\n",
      " -0.04028841 -0.06309926 -0.06380774 -0.06380774 -0.06713603 -0.6629322\n",
      " -0.6629322  -0.6629322  -0.6629322  -0.6654356  -0.66638905 -0.6666222\n",
      " -0.66781586 -0.67187035 -0.6719255  -0.6678827  -0.6666925  -0.66646\n",
      " -0.66646   ]\n",
      "\n",
      "113 [ 0.         -0.00232238 -0.00293188 -0.01000523 -0.02768537 -0.02796271\n",
      " -0.05077354 -0.05148204 -0.05148204 -0.05481035 -0.6506065  -0.6506065\n",
      " -0.6506065  -0.6506065  -0.6531099  -0.65406334 -0.6542966  -0.65549016\n",
      " -0.6595447  -0.6595998  -0.655557   -0.6543668  -0.6541343  -0.6541343\n",
      " -0.6541564 ]\n",
      "\n",
      "114 [ 0.0000000e+00 -6.0949463e-04 -7.6828469e-03 -2.5362989e-02\n",
      " -2.5640329e-02 -4.8451141e-02 -4.9159646e-02 -4.9159646e-02\n",
      " -5.2487981e-02 -6.4828414e-01 -6.4828414e-01 -6.4828414e-01\n",
      " -6.4828414e-01 -6.5078753e-01 -6.5174097e-01 -6.5197420e-01\n",
      " -6.5316778e-01 -6.5722227e-01 -6.5727735e-01 -6.5323454e-01\n",
      " -6.5204442e-01 -6.5181184e-01 -6.5181184e-01 -6.5183401e-01\n",
      " -6.5183401e-01]\n",
      "\n",
      "115 [ 0.         -0.00707335 -0.02475349 -0.02503083 -0.04784168 -0.04855015\n",
      " -0.04855015 -0.05187849 -0.6476747  -0.6476747  -0.6476747  -0.6476747\n",
      " -0.6501781  -0.6511315  -0.65136474 -0.65255827 -0.6566128  -0.6566679\n",
      " -0.652625   -0.6514349  -0.6512024  -0.6512024  -0.6512245  -0.6512245\n",
      " -0.6503474 ]\n",
      "\n",
      "116 [ 0.         -0.01768014 -0.01795748 -0.04076828 -0.04147678 -0.04147678\n",
      " -0.0448051  -0.6406013  -0.6406013  -0.6406013  -0.6406013  -0.6431047\n",
      " -0.64405805 -0.64429134 -0.6454849  -0.6495395  -0.64959455 -0.6455517\n",
      " -0.64436156 -0.644129   -0.644129   -0.6441511  -0.6441511  -0.643274\n",
      " -0.6408338 ]\n",
      "\n",
      "117 [ 0.0000000e+00 -2.7734134e-04 -2.3088168e-02 -2.3796665e-02\n",
      " -2.3796665e-02 -2.7124990e-02 -6.2292117e-01 -6.2292117e-01\n",
      " -6.2292117e-01 -6.2292117e-01 -6.2542456e-01 -6.2637794e-01\n",
      " -6.2661117e-01 -6.2780482e-01 -6.3185930e-01 -6.3191438e-01\n",
      " -6.2787157e-01 -6.2668139e-01 -6.2644887e-01 -6.2644887e-01\n",
      " -6.2647098e-01 -6.2647098e-01 -6.2559396e-01 -6.2315369e-01\n",
      " -6.2315369e-01]\n",
      "\n",
      "118 [ 0.         -0.0228108  -0.02351931 -0.02351931 -0.02684763 -0.6226438\n",
      " -0.6226438  -0.6226438  -0.6226438  -0.6251472  -0.6261006  -0.62633383\n",
      " -0.6275274  -0.63158196 -0.63163704 -0.6275942  -0.62640405 -0.62617147\n",
      " -0.62617147 -0.62619364 -0.62619364 -0.62531656 -0.62287635 -0.62287635\n",
      " -0.62287635]\n",
      "\n",
      "119 [ 0.         -0.00070849 -0.00070849 -0.00403684 -0.599833   -0.599833\n",
      " -0.599833   -0.599833   -0.6023364  -0.60328984 -0.6035231  -0.60471666\n",
      " -0.60877115 -0.60882616 -0.60478336 -0.60359323 -0.6033607  -0.6033607\n",
      " -0.6033828  -0.6033828  -0.6025057  -0.6000655  -0.6000655  -0.6000655\n",
      " -0.6000655 ]\n",
      "\n",
      "120 [ 0.          0.         -0.00332834 -0.5991245  -0.5991245  -0.5991245\n",
      " -0.5991245  -0.6016279  -0.6025813  -0.6028145  -0.60400814 -0.6080626\n",
      " -0.6081177  -0.6040749  -0.6028847  -0.60265225 -0.60265225 -0.60267437\n",
      " -0.60267437 -0.6017973  -0.59935707 -0.59935707 -0.59935707 -0.59935707\n",
      " -0.01526741]\n",
      "\n",
      "121 [ 0.         -0.00332834 -0.5991245  -0.5991245  -0.5991245  -0.5991245\n",
      " -0.6016279  -0.6025813  -0.6028145  -0.60400814 -0.6080626  -0.6081177\n",
      " -0.6040749  -0.6028847  -0.60265225 -0.60265225 -0.60267437 -0.60267437\n",
      " -0.6017973  -0.59935707 -0.59935707 -0.59935707 -0.59935707 -0.01526741\n",
      " -0.01526741]\n",
      "\n",
      "122 [ 0.         -0.5957962  -0.5957962  -0.5957962  -0.5957962  -0.59829956\n",
      " -0.599253   -0.59948623 -0.60067976 -0.6047343  -0.6047894  -0.6007466\n",
      " -0.59955645 -0.59932387 -0.59932387 -0.5993459  -0.5993459  -0.5984689\n",
      " -0.59602875 -0.59602875 -0.59602875 -0.59602875 -0.01193909 -0.01193909\n",
      " -0.01193909]\n",
      "\n",
      "123 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      " -2.5033869e-03 -3.4568161e-03 -3.6900360e-03 -4.8836144e-03\n",
      " -8.9381384e-03 -8.9932233e-03 -4.9503981e-03 -3.7602629e-03\n",
      " -3.5277158e-03 -3.5277158e-03 -3.5498114e-03 -3.5498114e-03\n",
      " -2.6727370e-03 -2.3252597e-04 -2.3252597e-04 -2.3252597e-04\n",
      " -2.3252597e-04  5.8385706e-01  5.8385706e-01  5.8385706e-01\n",
      "  5.8385706e-01]\n",
      "\n",
      "124 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 -2.5033869e-03\n",
      " -3.4568161e-03 -3.6900360e-03 -4.8836144e-03 -8.9381384e-03\n",
      " -8.9932233e-03 -4.9503981e-03 -3.7602629e-03 -3.5277158e-03\n",
      " -3.5277158e-03 -3.5498114e-03 -3.5498114e-03 -2.6727370e-03\n",
      " -2.3252597e-04 -2.3252597e-04 -2.3252597e-04 -2.3252597e-04\n",
      "  5.8385706e-01  5.8385706e-01  5.8385706e-01  5.8385706e-01\n",
      "  5.8385706e-01]\n",
      "\n",
      "125 [ 0.0000000e+00  0.0000000e+00 -2.5033869e-03 -3.4568161e-03\n",
      " -3.6900360e-03 -4.8836144e-03 -8.9381384e-03 -8.9932233e-03\n",
      " -4.9503981e-03 -3.7602629e-03 -3.5277158e-03 -3.5277158e-03\n",
      " -3.5498114e-03 -3.5498114e-03 -2.6727370e-03 -2.3252597e-04\n",
      " -2.3252597e-04 -2.3252597e-04 -2.3252597e-04  5.8385706e-01\n",
      "  5.8385706e-01  5.8385706e-01  5.8385706e-01  5.8385706e-01\n",
      "  5.8385706e-01]\n",
      "\n",
      "126 [ 0.0000000e+00 -2.5033869e-03 -3.4568161e-03 -3.6900360e-03\n",
      " -4.8836144e-03 -8.9381384e-03 -8.9932233e-03 -4.9503981e-03\n",
      " -3.7602629e-03 -3.5277158e-03 -3.5277158e-03 -3.5498114e-03\n",
      " -3.5498114e-03 -2.6727370e-03 -2.3252597e-04 -2.3252597e-04\n",
      " -2.3252597e-04 -2.3252597e-04  5.8385706e-01  5.8385706e-01\n",
      "  5.8385706e-01  5.8385706e-01  5.8385706e-01  5.8385706e-01\n",
      "  5.8385706e-01]\n",
      "\n",
      "127 [ 0.0000000e+00 -9.5342926e-04 -1.1866490e-03 -2.3802279e-03\n",
      " -6.4347517e-03 -6.4898380e-03 -2.4470137e-03 -1.2568781e-03\n",
      " -1.0243311e-03 -1.0243311e-03 -1.0464235e-03 -1.0464235e-03\n",
      " -1.6934965e-04  2.2708585e-03  2.2708585e-03  2.2708585e-03\n",
      "  2.2708585e-03  5.8636045e-01  5.8636045e-01  5.8636045e-01\n",
      "  5.8636045e-01  5.8636045e-01  5.8636045e-01  5.8636045e-01\n",
      "  5.8636045e-01]\n",
      "\n",
      "128 [ 0.0000000e+00 -2.3321983e-04 -1.4267986e-03 -5.4813223e-03\n",
      " -5.5364077e-03 -1.4935831e-03 -3.0344754e-04 -7.0900460e-05\n",
      " -7.0900460e-05 -9.2993367e-05 -9.2993367e-05  7.8407989e-04\n",
      "  3.2242900e-03  3.2242900e-03  3.2242900e-03  3.2242900e-03\n",
      "  5.8731389e-01  5.8731389e-01  5.8731389e-01  5.8731389e-01\n",
      "  5.8731389e-01  5.8731389e-01  5.8731389e-01  5.8731389e-01\n",
      "  5.8731389e-01]\n",
      "\n",
      "129 [ 0.0000000e+00 -1.1935788e-03 -5.2481024e-03 -5.3031868e-03\n",
      " -1.2603623e-03 -7.0226779e-05  1.6232030e-04  1.6232030e-04\n",
      "  1.4022701e-04  1.4022701e-04  1.0172983e-03  3.4575097e-03\n",
      "  3.4575097e-03  3.4575097e-03  3.4575097e-03  5.8754718e-01\n",
      "  5.8754718e-01  5.8754718e-01  5.8754718e-01  5.8754718e-01\n",
      "  5.8754718e-01  5.8754718e-01  5.8754718e-01  5.8754718e-01\n",
      "  5.8754718e-01]\n",
      "\n",
      "130 [ 0.0000000e+00 -4.0545235e-03 -4.1096089e-03 -6.6784480e-05\n",
      "  1.1233510e-03  1.3558982e-03  1.3558982e-03  1.3338053e-03\n",
      "  1.3338053e-03  2.2108785e-03  4.6510883e-03  4.6510883e-03\n",
      "  4.6510883e-03  4.6510883e-03  5.8874071e-01  5.8874071e-01\n",
      "  5.8874071e-01  5.8874071e-01  5.8874071e-01  5.8874071e-01\n",
      "  5.8874071e-01  5.8874071e-01  5.8874071e-01  5.8874071e-01\n",
      "  5.8874071e-01]\n",
      "\n",
      "131 [ 0.0000000e+00 -5.5085002e-05  3.9877393e-03  5.1778750e-03\n",
      "  5.4104221e-03  5.4104221e-03  5.3883293e-03  5.3883293e-03\n",
      "  6.2654014e-03  8.7056123e-03  8.7056123e-03  8.7056123e-03\n",
      "  8.7056123e-03  5.9279525e-01  5.9279525e-01  5.9279525e-01\n",
      "  5.9279525e-01  5.9279525e-01  5.9279525e-01  5.9279525e-01\n",
      "  5.9279525e-01  5.9279525e-01  5.9279525e-01  5.9279525e-01\n",
      "  5.9279525e-01]\n",
      "\n",
      "132 [0.         0.00404282 0.00523296 0.00546551 0.00546551 0.00544342\n",
      " 0.00544342 0.00632049 0.0087607  0.0087607  0.0087607  0.0087607\n",
      " 0.5928503  0.5928503  0.5928503  0.5928503  0.5928503  0.5928503\n",
      " 0.5928503  0.5928503  0.5928503  0.5928503  0.5928503  0.5928503\n",
      " 0.5928503 ]\n",
      "\n",
      "133 [0.         0.00119013 0.00142268 0.00142268 0.00140059 0.00140059\n",
      " 0.00227766 0.00471787 0.00471787 0.00471787 0.00471787 0.5888075\n",
      " 0.5888075  0.5888075  0.5888075  0.5888075  0.5888075  0.5888075\n",
      " 0.5888075  0.5888075  0.5888075  0.5888075  0.5888075  0.5888075\n",
      " 0.5888075 ]\n",
      "\n",
      "134 [0.0000000e+00 2.3254802e-04 2.3254802e-04 2.1045475e-04 2.1045475e-04\n",
      " 1.0875275e-03 3.5277365e-03 3.5277365e-03 3.5277365e-03 3.5277365e-03\n",
      " 5.8761740e-01 5.8761740e-01 5.8761740e-01 5.8761740e-01 5.8761740e-01\n",
      " 5.8761740e-01 5.8761740e-01 5.8761740e-01 5.8761740e-01 5.8761740e-01\n",
      " 5.8761740e-01 5.8761740e-01 5.8761740e-01 5.8761740e-01 5.8761740e-01]\n",
      "\n",
      "135 [ 0.0000000e+00  0.0000000e+00 -2.2092909e-05 -2.2092909e-05\n",
      "  8.5498177e-04  3.2951899e-03  3.2951899e-03  3.2951899e-03\n",
      "  3.2951899e-03  5.8738482e-01  5.8738482e-01  5.8738482e-01\n",
      "  5.8738482e-01  5.8738482e-01  5.8738482e-01  5.8738482e-01\n",
      "  5.8738482e-01  5.8738482e-01  5.8738482e-01  5.8738482e-01\n",
      "  5.8738482e-01  5.8738482e-01  5.8738482e-01  5.8738482e-01\n",
      "  5.8738482e-01]\n",
      "\n",
      "136 [ 0.0000000e+00 -2.2092909e-05 -2.2092909e-05  8.5498177e-04\n",
      "  3.2951899e-03  3.2951899e-03  3.2951899e-03  3.2951899e-03\n",
      "  5.8738482e-01  5.8738482e-01  5.8738482e-01  5.8738482e-01\n",
      "  5.8738482e-01  5.8738482e-01  5.8738482e-01  5.8738482e-01\n",
      "  5.8738482e-01  5.8738482e-01  5.8738482e-01  5.8738482e-01\n",
      "  5.8738482e-01  5.8738482e-01  5.8738482e-01  5.8738482e-01\n",
      "  5.8738482e-01]\n",
      "\n",
      "137 [0.         0.         0.00087707 0.00331729 0.00331729 0.00331729\n",
      " 0.00331729 0.5874069  0.5874069  0.5874069  0.5874069  0.5874069\n",
      " 0.5874069  0.5874069  0.5874069  0.5874069  0.5874069  0.5874069\n",
      " 0.5874069  0.5874069  0.5874069  0.5874069  0.5874069  0.5874069\n",
      " 0.5874069 ]\n",
      "\n",
      "138 [0.         0.00087707 0.00331729 0.00331729 0.00331729 0.00331729\n",
      " 0.5874069  0.5874069  0.5874069  0.5874069  0.5874069  0.5874069\n",
      " 0.5874069  0.5874069  0.5874069  0.5874069  0.5874069  0.5874069\n",
      " 0.5874069  0.5874069  0.5874069  0.5874069  0.5874069  0.5874069\n",
      " 0.5874069 ]\n",
      "\n",
      "139 [0.         0.00244021 0.00244021 0.00244021 0.00244021 0.5865298\n",
      " 0.5865298  0.5865298  0.5865298  0.5865298  0.5865298  0.5865298\n",
      " 0.5865298  0.5865298  0.5865298  0.5865298  0.5865298  0.5865298\n",
      " 0.5865298  0.5865298  0.5865298  0.5865298  0.5865298  0.5865298\n",
      " 0.5865298 ]\n",
      "\n",
      "140 [0.        0.        0.        0.        0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896]\n",
      "\n",
      "141 [0.        0.        0.        0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896]\n",
      "\n",
      "142 [0.        0.        0.5840896 0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896]\n",
      "\n",
      "143 [0.        0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896 0.5840896\n",
      " 0.5840896 0.5840896 0.5840896 0.5840896]\n",
      "\n",
      "144 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "145 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "146 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "147 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "148 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "149 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "150 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "151 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "152 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "153 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.00685779]\n",
      "\n",
      "154 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.00685779\n",
      " -0.00685779]\n",
      "\n",
      "155 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.00685779 -0.00685779\n",
      " -0.00685779]\n",
      "\n",
      "156 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         -0.00685779 -0.00685779 -0.00685779\n",
      " -0.00685779]\n",
      "\n",
      "157 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.00685779 -0.00685779 -0.00685779 -0.00685779\n",
      " -0.00685779]\n",
      "\n",
      "158 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.00685779\n",
      " -0.64508456]\n",
      "\n",
      "159 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.64508456\n",
      " -0.64508456]\n",
      "\n",
      "160 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.00685779\n",
      " -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.64508456 -0.64508456\n",
      " -0.64508456]\n",
      "\n",
      "161 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.00685779 -0.00685779\n",
      " -0.00685779 -0.00685779 -0.00685779 -0.64508456 -0.64508456 -0.64508456\n",
      " -0.6616371 ]\n",
      "\n",
      "162 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         -0.00685779 -0.00685779 -0.00685779\n",
      " -0.00685779 -0.00685779 -0.64508456 -0.64508456 -0.64508456 -0.6616371\n",
      " -0.6616371 ]\n",
      "\n",
      "163 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.00685779 -0.00685779 -0.00685779 -0.00685779\n",
      " -0.00685779 -0.64508456 -0.64508456 -0.64508456 -0.6616371  -0.6616371\n",
      " -0.6616371 ]\n",
      "\n",
      "164 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.00685779\n",
      " -0.64508456 -0.64508456 -0.64508456 -0.6616371  -0.6616371  -0.6616371\n",
      " -0.6616371 ]\n",
      "\n",
      "165 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.64508456\n",
      " -0.64508456 -0.64508456 -0.6616371  -0.6616371  -0.6616371  -0.6616371\n",
      " -0.6616645 ]\n",
      "\n",
      "166 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.00685779\n",
      " -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.64508456 -0.64508456\n",
      " -0.64508456 -0.6616371  -0.6616371  -0.6616371  -0.6616371  -0.6616645\n",
      " -0.6616645 ]\n",
      "\n",
      "167 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.00685779 -0.00685779\n",
      " -0.00685779 -0.00685779 -0.00685779 -0.64508456 -0.64508456 -0.64508456\n",
      " -0.6616371  -0.6616371  -0.6616371  -0.6616371  -0.6616645  -0.6616645\n",
      " -0.67041725]\n",
      "\n",
      "168 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         -0.00685779 -0.00685779 -0.00685779\n",
      " -0.00685779 -0.00685779 -0.64508456 -0.64508456 -0.64508456 -0.6616371\n",
      " -0.6616371  -0.6616371  -0.6616371  -0.6616645  -0.6616645  -0.67041725\n",
      " -0.6960043 ]\n",
      "\n",
      "169 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.00685779 -0.00685779 -0.00685779 -0.00685779\n",
      " -0.00685779 -0.64508456 -0.64508456 -0.64508456 -0.6616371  -0.6616371\n",
      " -0.6616371  -0.6616371  -0.6616645  -0.6616645  -0.67041725 -0.6960043\n",
      " -0.6980393 ]\n",
      "\n",
      "170 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.00685779\n",
      " -0.64508456 -0.64508456 -0.64508456 -0.6616371  -0.6616371  -0.6616371\n",
      " -0.6616371  -0.6616645  -0.6616645  -0.67041725 -0.6960043  -0.6980393\n",
      " -0.6993911 ]\n",
      "\n",
      "171 [ 0.          0.          0.          0.          0.          0.\n",
      " -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.64508456\n",
      " -0.64508456 -0.64508456 -0.6616371  -0.6616371  -0.6616371  -0.6616371\n",
      " -0.6616645  -0.6616645  -0.67041725 -0.6960043  -0.6980393  -0.6993911\n",
      " -0.70012057]\n",
      "\n",
      "172 [ 0.          0.          0.          0.          0.         -0.00685779\n",
      " -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.64508456 -0.64508456\n",
      " -0.64508456 -0.6616371  -0.6616371  -0.6616371  -0.6616371  -0.6616645\n",
      " -0.6616645  -0.67041725 -0.6960043  -0.6980393  -0.6993911  -0.70012057\n",
      " -0.700389  ]\n",
      "\n",
      "173 [ 0.          0.          0.          0.         -0.00685779 -0.00685779\n",
      " -0.00685779 -0.00685779 -0.00685779 -0.64508456 -0.64508456 -0.64508456\n",
      " -0.6616371  -0.6616371  -0.6616371  -0.6616371  -0.6616645  -0.6616645\n",
      " -0.67041725 -0.6960043  -0.6980393  -0.6993911  -0.70012057 -0.700389\n",
      " -0.70051533]\n",
      "\n",
      "174 [ 0.          0.          0.         -0.00685779 -0.00685779 -0.00685779\n",
      " -0.00685779 -0.00685779 -0.64508456 -0.64508456 -0.64508456 -0.6616371\n",
      " -0.6616371  -0.6616371  -0.6616371  -0.6616645  -0.6616645  -0.67041725\n",
      " -0.6960043  -0.6980393  -0.6993911  -0.70012057 -0.700389   -0.70051533\n",
      " -0.71108586]\n",
      "\n",
      "175 [ 0.          0.         -0.00685779 -0.00685779 -0.00685779 -0.00685779\n",
      " -0.00685779 -0.64508456 -0.64508456 -0.64508456 -0.6616371  -0.6616371\n",
      " -0.6616371  -0.6616371  -0.6616645  -0.6616645  -0.67041725 -0.6960043\n",
      " -0.6980393  -0.6993911  -0.70012057 -0.700389   -0.70051533 -0.71108586\n",
      " -0.7131653 ]\n",
      "\n",
      "176 [ 0.         -0.00685779 -0.00685779 -0.00685779 -0.00685779 -0.00685779\n",
      " -0.64508456 -0.64508456 -0.64508456 -0.6616371  -0.6616371  -0.6616371\n",
      " -0.6616371  -0.6616645  -0.6616645  -0.67041725 -0.6960043  -0.6980393\n",
      " -0.6993911  -0.70012057 -0.700389   -0.70051533 -0.71108586 -0.7131653\n",
      " -0.7131653 ]\n",
      "\n",
      "177 [ 0.          0.          0.          0.          0.         -0.6382268\n",
      " -0.6382268  -0.6382268  -0.6547794  -0.6547794  -0.6547794  -0.6547794\n",
      " -0.6548067  -0.6548067  -0.66355944 -0.6891465  -0.69118154 -0.6925333\n",
      " -0.69326276 -0.6935312  -0.6936576  -0.7042281  -0.7063075  -0.7063075\n",
      " -0.7063075 ]\n",
      "\n",
      "178 [ 0.          0.          0.          0.         -0.6382268  -0.6382268\n",
      " -0.6382268  -0.6547794  -0.6547794  -0.6547794  -0.6547794  -0.6548067\n",
      " -0.6548067  -0.66355944 -0.6891465  -0.69118154 -0.6925333  -0.69326276\n",
      " -0.6935312  -0.6936576  -0.7042281  -0.7063075  -0.7063075  -0.7063075\n",
      " -0.7063075 ]\n",
      "\n",
      "179 [ 0.          0.          0.         -0.6382268  -0.6382268  -0.6382268\n",
      " -0.6547794  -0.6547794  -0.6547794  -0.6547794  -0.6548067  -0.6548067\n",
      " -0.66355944 -0.6891465  -0.69118154 -0.6925333  -0.69326276 -0.6935312\n",
      " -0.6936576  -0.7042281  -0.7063075  -0.7063075  -0.7063075  -0.7063075\n",
      " -0.7063075 ]\n",
      "\n",
      "180 [ 0.          0.         -0.6382268  -0.6382268  -0.6382268  -0.6547794\n",
      " -0.6547794  -0.6547794  -0.6547794  -0.6548067  -0.6548067  -0.66355944\n",
      " -0.6891465  -0.69118154 -0.6925333  -0.69326276 -0.6935312  -0.6936576\n",
      " -0.7042281  -0.7063075  -0.7063075  -0.7063075  -0.7063075  -0.7063075\n",
      " -0.7123586 ]\n",
      "\n",
      "181 [ 0.         -0.6382268  -0.6382268  -0.6382268  -0.6547794  -0.6547794\n",
      " -0.6547794  -0.6547794  -0.6548067  -0.6548067  -0.66355944 -0.6891465\n",
      " -0.69118154 -0.6925333  -0.69326276 -0.6935312  -0.6936576  -0.7042281\n",
      " -0.7063075  -0.7063075  -0.7063075  -0.7063075  -0.7063075  -0.7123586\n",
      " -0.7156987 ]\n",
      "\n",
      "182 [ 0.          0.          0.         -0.01655258 -0.01655258 -0.01655258\n",
      " -0.01655258 -0.01657992 -0.01657992 -0.02533265 -0.05091972 -0.05295473\n",
      " -0.05430653 -0.05503596 -0.05530444 -0.05543078 -0.06600129 -0.06808066\n",
      " -0.06808066 -0.06808066 -0.06808066 -0.06808066 -0.07413177 -0.0774719\n",
      " -0.0774719 ]\n",
      "\n",
      "183 [ 0.          0.         -0.01655258 -0.01655258 -0.01655258 -0.01655258\n",
      " -0.01657992 -0.01657992 -0.02533265 -0.05091972 -0.05295473 -0.05430653\n",
      " -0.05503596 -0.05530444 -0.05543078 -0.06600129 -0.06808066 -0.06808066\n",
      " -0.06808066 -0.06808066 -0.06808066 -0.07413177 -0.0774719  -0.0774719\n",
      " -0.0774719 ]\n",
      "\n",
      "184 [ 0.         -0.01655258 -0.01655258 -0.01655258 -0.01655258 -0.01657992\n",
      " -0.01657992 -0.02533265 -0.05091972 -0.05295473 -0.05430653 -0.05503596\n",
      " -0.05530444 -0.05543078 -0.06600129 -0.06808066 -0.06808066 -0.06808066\n",
      " -0.06808066 -0.06808066 -0.07413177 -0.0774719  -0.0774719  -0.0774719\n",
      " -0.0774719 ]\n",
      "\n",
      "185 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      " -2.7343563e-05 -2.7343563e-05 -8.7800752e-03 -3.4367144e-02\n",
      " -3.6402162e-02 -3.7753943e-02 -3.8483378e-02 -3.8751863e-02\n",
      " -3.8878199e-02 -4.9448710e-02 -5.1528085e-02 -5.1528085e-02\n",
      " -5.1528085e-02 -5.1528085e-02 -5.1528085e-02 -5.7579197e-02\n",
      " -6.0919326e-02 -6.0919326e-02 -6.0919326e-02 -6.0919326e-02\n",
      " -6.0535159e-02]\n",
      "\n",
      "186 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 -2.7343563e-05\n",
      " -2.7343563e-05 -8.7800752e-03 -3.4367144e-02 -3.6402162e-02\n",
      " -3.7753943e-02 -3.8483378e-02 -3.8751863e-02 -3.8878199e-02\n",
      " -4.9448710e-02 -5.1528085e-02 -5.1528085e-02 -5.1528085e-02\n",
      " -5.1528085e-02 -5.1528085e-02 -5.7579197e-02 -6.0919326e-02\n",
      " -6.0919326e-02 -6.0919326e-02 -6.0919326e-02 -6.0535159e-02\n",
      " -6.0201563e-02]\n",
      "\n",
      "187 [ 0.0000000e+00  0.0000000e+00 -2.7343563e-05 -2.7343563e-05\n",
      " -8.7800752e-03 -3.4367144e-02 -3.6402162e-02 -3.7753943e-02\n",
      " -3.8483378e-02 -3.8751863e-02 -3.8878199e-02 -4.9448710e-02\n",
      " -5.1528085e-02 -5.1528085e-02 -5.1528085e-02 -5.1528085e-02\n",
      " -5.1528085e-02 -5.7579197e-02 -6.0919326e-02 -6.0919326e-02\n",
      " -6.0919326e-02 -6.0919326e-02 -6.0535159e-02 -6.0201563e-02\n",
      " -6.5845057e-02]\n",
      "\n",
      "188 [ 0.0000000e+00 -2.7343563e-05 -2.7343563e-05 -8.7800752e-03\n",
      " -3.4367144e-02 -3.6402162e-02 -3.7753943e-02 -3.8483378e-02\n",
      " -3.8751863e-02 -3.8878199e-02 -4.9448710e-02 -5.1528085e-02\n",
      " -5.1528085e-02 -5.1528085e-02 -5.1528085e-02 -5.1528085e-02\n",
      " -5.7579197e-02 -6.0919326e-02 -6.0919326e-02 -6.0919326e-02\n",
      " -6.0919326e-02 -6.0535159e-02 -6.0201563e-02 -6.5845057e-02\n",
      " -6.5429270e-02]\n",
      "\n",
      "189 [ 0.          0.         -0.00875274 -0.0343398  -0.03637482 -0.0377266\n",
      " -0.03845603 -0.03872452 -0.03885086 -0.04942137 -0.05150075 -0.05150075\n",
      " -0.05150075 -0.05150075 -0.05150075 -0.05755185 -0.06089198 -0.06089198\n",
      " -0.06089198 -0.06089198 -0.06050782 -0.06017422 -0.06581771 -0.06540193\n",
      " -0.06540193]\n",
      "\n",
      "190 [ 0.         -0.00875274 -0.0343398  -0.03637482 -0.0377266  -0.03845603\n",
      " -0.03872452 -0.03885086 -0.04942137 -0.05150075 -0.05150075 -0.05150075\n",
      " -0.05150075 -0.05150075 -0.05755185 -0.06089198 -0.06089198 -0.06089198\n",
      " -0.06089198 -0.06050782 -0.06017422 -0.06581771 -0.06540193 -0.06540193\n",
      " -0.06485163]\n",
      "\n",
      "191 [ 0.         -0.02558707 -0.02762209 -0.02897387 -0.0297033  -0.02997179\n",
      " -0.03009813 -0.04066864 -0.04274802 -0.04274802 -0.04274802 -0.04274802\n",
      " -0.04274802 -0.04879912 -0.05213925 -0.05213925 -0.05213925 -0.05213925\n",
      " -0.05175509 -0.05142149 -0.05706498 -0.05664919 -0.05664919 -0.0560989\n",
      " -0.05015965]\n",
      "\n",
      "192 [ 0.         -0.00203502 -0.0033868  -0.00411624 -0.00438472 -0.00451107\n",
      " -0.01508158 -0.01716094 -0.01716094 -0.01716094 -0.01716094 -0.01716094\n",
      " -0.02321205 -0.02655218 -0.02655218 -0.02655218 -0.02655218 -0.02616802\n",
      " -0.02583443 -0.03147791 -0.03106212 -0.03106212 -0.03051183 -0.02457258\n",
      " -0.02442783]\n",
      "\n",
      "193 [ 0.         -0.00135178 -0.00208122 -0.0023497  -0.00247604 -0.01304655\n",
      " -0.01512591 -0.01512591 -0.01512591 -0.01512591 -0.01512591 -0.02117702\n",
      " -0.02451716 -0.02451716 -0.02451716 -0.02451716 -0.024133   -0.0237994\n",
      " -0.02944289 -0.0290271  -0.0290271  -0.02847681 -0.02253756 -0.02239281\n",
      " -0.02239281]\n",
      "\n",
      "194 [ 0.         -0.00072944 -0.00099792 -0.00112426 -0.01169478 -0.01377414\n",
      " -0.01377414 -0.01377414 -0.01377414 -0.01377414 -0.01982525 -0.02316538\n",
      " -0.02316538 -0.02316538 -0.02316538 -0.02278122 -0.02244762 -0.02809111\n",
      " -0.02767532 -0.02767532 -0.02712503 -0.02118578 -0.02104103 -0.02104103\n",
      " -0.02103434]\n",
      "\n",
      "195 [ 0.         -0.00026848 -0.00039482 -0.01096534 -0.01304471 -0.01304471\n",
      " -0.01304471 -0.01304471 -0.01304471 -0.01909582 -0.02243596 -0.02243596\n",
      " -0.02243596 -0.02243596 -0.02205179 -0.0217182  -0.02736167 -0.02694588\n",
      " -0.02694588 -0.0263956  -0.02045636 -0.0203116  -0.0203116  -0.0203049\n",
      " -0.0203049 ]\n",
      "\n",
      "196 [ 0.         -0.00012634 -0.01069686 -0.01277622 -0.01277622 -0.01277622\n",
      " -0.01277622 -0.01277622 -0.01882732 -0.02216746 -0.02216746 -0.02216746\n",
      " -0.02216746 -0.0217833  -0.0214497  -0.02709318 -0.0266774  -0.0266774\n",
      " -0.02612711 -0.02018786 -0.02004311 -0.02004311 -0.02003641 -0.02003641\n",
      " -0.02003641]\n",
      "\n",
      "197 [ 0.         -0.01057051 -0.01264988 -0.01264988 -0.01264988 -0.01264988\n",
      " -0.01264988 -0.01870098 -0.02204113 -0.02204113 -0.02204113 -0.02204113\n",
      " -0.02165696 -0.02132337 -0.02696685 -0.02655106 -0.02655106 -0.02600078\n",
      " -0.02006153 -0.01991677 -0.01991677 -0.01991008 -0.01991008 -0.01991008\n",
      " -0.01991008]\n",
      "\n",
      "198 [ 0.         -0.00207936 -0.00207936 -0.00207936 -0.00207936 -0.00207936\n",
      " -0.00813047 -0.01147061 -0.01147061 -0.01147061 -0.01147061 -0.01108645\n",
      " -0.01075285 -0.01639633 -0.01598055 -0.01598055 -0.01543026 -0.00949101\n",
      " -0.00934626 -0.00934626 -0.00933957 -0.00933957 -0.00933957 -0.00933957\n",
      " -0.00933957]\n",
      "\n",
      "199 [ 0.          0.          0.          0.          0.         -0.00605111\n",
      " -0.00939125 -0.00939125 -0.00939125 -0.00939125 -0.00900709 -0.00867349\n",
      " -0.01431696 -0.01390117 -0.01390117 -0.01335089 -0.00741165 -0.00726689\n",
      " -0.00726689 -0.00726018 -0.00726018 -0.00726018 -0.00726018 -0.00726018\n",
      " -0.00726018]\n",
      "\n",
      "200 [ 0.          0.          0.          0.         -0.00605111 -0.00939125\n",
      " -0.00939125 -0.00939125 -0.00939125 -0.00900709 -0.00867349 -0.01431696\n",
      " -0.01390117 -0.01390117 -0.01335089 -0.00741165 -0.00726689 -0.00726689\n",
      " -0.00726018 -0.00726018 -0.00726018 -0.00726018 -0.00726018 -0.00726018\n",
      " -0.00726018]\n",
      "\n",
      "201 [ 0.          0.          0.         -0.00605111 -0.00939125 -0.00939125\n",
      " -0.00939125 -0.00939125 -0.00900709 -0.00867349 -0.01431696 -0.01390117\n",
      " -0.01390117 -0.01335089 -0.00741165 -0.00726689 -0.00726689 -0.00726018\n",
      " -0.00726018 -0.00726018 -0.00726018 -0.00726018 -0.00726018 -0.00726018\n",
      " -0.00726018]\n",
      "\n",
      "202 [ 0.          0.         -0.00605111 -0.00939125 -0.00939125 -0.00939125\n",
      " -0.00939125 -0.00900709 -0.00867349 -0.01431696 -0.01390117 -0.01390117\n",
      " -0.01335089 -0.00741165 -0.00726689 -0.00726689 -0.00726018 -0.00726018\n",
      " -0.00726018 -0.00726018 -0.00726018 -0.00726018 -0.00726018 -0.00726018\n",
      " -0.00726018]\n",
      "\n",
      "203 [ 0.         -0.00605111 -0.00939125 -0.00939125 -0.00939125 -0.00939125\n",
      " -0.00900709 -0.00867349 -0.01431696 -0.01390117 -0.01390117 -0.01335089\n",
      " -0.00741165 -0.00726689 -0.00726689 -0.00726018 -0.00726018 -0.00726018\n",
      " -0.00726018 -0.00726018 -0.00726018 -0.00726018 -0.00726018 -0.00726018\n",
      " -0.00726018]\n",
      "\n",
      "204 [ 0.         -0.00334015 -0.00334015 -0.00334015 -0.00334015 -0.00295599\n",
      " -0.00262238 -0.00826586 -0.00785007 -0.00785007 -0.00729978 -0.00136054\n",
      " -0.00121579 -0.00121579 -0.00120908 -0.00120908 -0.00120908 -0.00120908\n",
      " -0.00120908 -0.00120908 -0.00120908 -0.00120908 -0.00120908 -0.00120908\n",
      " -0.00120908]\n",
      "\n",
      "205 [ 0.          0.          0.          0.          0.00038415  0.00071776\n",
      " -0.00492572 -0.00450994 -0.00450994 -0.00395964  0.0019796   0.00212435\n",
      "  0.00212435  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106\n",
      "  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106\n",
      "  0.00213106]\n",
      "\n",
      "206 [ 0.          0.          0.          0.00038415  0.00071776 -0.00492572\n",
      " -0.00450994 -0.00450994 -0.00395964  0.0019796   0.00212435  0.00212435\n",
      "  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106\n",
      "  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106\n",
      "  0.01026407]\n",
      "\n",
      "207 [ 0.          0.          0.00038415  0.00071776 -0.00492572 -0.00450994\n",
      " -0.00450994 -0.00395964  0.0019796   0.00212435  0.00212435  0.00213106\n",
      "  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106\n",
      "  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106  0.01026407\n",
      "  0.01026407]\n",
      "\n",
      "208 [ 0.          0.00038415  0.00071776 -0.00492572 -0.00450994 -0.00450994\n",
      " -0.00395964  0.0019796   0.00212435  0.00212435  0.00213106  0.00213106\n",
      "  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106  0.00213106\n",
      "  0.00213106  0.00213106  0.00213106  0.00213106  0.01026407  0.01026407\n",
      "  0.0136876 ]\n",
      "\n",
      "209 [ 0.          0.0003336  -0.00530989 -0.0048941  -0.0048941  -0.0043438\n",
      "  0.00159544  0.0017402   0.0017402   0.00174689  0.00174689  0.00174689\n",
      "  0.00174689  0.00174689  0.00174689  0.00174689  0.00174689  0.00174689\n",
      "  0.00174689  0.00174689  0.00174689  0.0098799   0.0098799   0.01330344\n",
      "  0.01543927]\n",
      "\n",
      "210 [ 0.         -0.00564348 -0.0052277  -0.0052277  -0.0046774   0.00126184\n",
      "  0.00140659  0.00140659  0.00141329  0.00141329  0.00141329  0.00141329\n",
      "  0.00141329  0.00141329  0.00141329  0.00141329  0.00141329  0.00141329\n",
      "  0.00141329  0.00141329  0.00954631  0.00954631  0.01296984  0.01510568\n",
      "  0.0190774 ]\n",
      "\n",
      "211 [0.         0.00041578 0.00041578 0.00096608 0.00690533 0.00705009\n",
      " 0.00705009 0.00705678 0.00705678 0.00705678 0.00705678 0.00705678\n",
      " 0.00705678 0.00705678 0.00705678 0.00705678 0.00705678 0.00705678\n",
      " 0.00705678 0.0151898  0.0151898  0.01861333 0.02074917 0.02472089\n",
      " 0.02589078]\n",
      "\n",
      "212 [0.         0.         0.00055029 0.00648954 0.0066343  0.0066343\n",
      " 0.00664099 0.00664099 0.00664099 0.00664099 0.00664099 0.00664099\n",
      " 0.00664099 0.00664099 0.00664099 0.00664099 0.00664099 0.00664099\n",
      " 0.01477402 0.01477402 0.01819754 0.02033338 0.0243051  0.02547499\n",
      " 0.02636939]\n",
      "\n",
      "213 [0.         0.00055029 0.00648954 0.0066343  0.0066343  0.00664099\n",
      " 0.00664099 0.00664099 0.00664099 0.00664099 0.00664099 0.00664099\n",
      " 0.00664099 0.00664099 0.00664099 0.00664099 0.00664099 0.01477402\n",
      " 0.01477402 0.01819754 0.02033338 0.0243051  0.02547499 0.02636939\n",
      " 0.03044638]\n",
      "\n",
      "214 [0.         0.00593925 0.00608401 0.00608401 0.00609071 0.00609071\n",
      " 0.00609071 0.00609071 0.00609071 0.00609071 0.00609071 0.00609071\n",
      " 0.00609071 0.00609071 0.00609071 0.00609071 0.01422372 0.01422372\n",
      " 0.01764726 0.01978309 0.02375481 0.02492471 0.0258191  0.0298961\n",
      " 0.03515708]\n",
      "\n",
      "215 [0.         0.00014475 0.00014475 0.00015146 0.00015146 0.00015146\n",
      " 0.00015146 0.00015146 0.00015146 0.00015146 0.00015146 0.00015146\n",
      " 0.00015146 0.00015146 0.00015146 0.00828446 0.00828446 0.011708\n",
      " 0.01384384 0.01781556 0.01898545 0.01987985 0.02395684 0.02921784\n",
      " 0.02856481]\n",
      "\n",
      "216 [0.0000000e+00 0.0000000e+00 6.6960847e-06 6.6960847e-06 6.6960847e-06\n",
      " 6.6960847e-06 6.6960847e-06 6.6960847e-06 6.6960847e-06 6.6960847e-06\n",
      " 6.6960847e-06 6.6960847e-06 6.6960847e-06 6.6960847e-06 8.1397146e-03\n",
      " 8.1397146e-03 1.1563250e-02 1.3699084e-02 1.7670801e-02 1.8840695e-02\n",
      " 1.9735092e-02 2.3812084e-02 2.9073082e-02 2.8420057e-02 3.5425313e-02]\n",
      "\n",
      "217 [0.0000000e+00 6.6960847e-06 6.6960847e-06 6.6960847e-06 6.6960847e-06\n",
      " 6.6960847e-06 6.6960847e-06 6.6960847e-06 6.6960847e-06 6.6960847e-06\n",
      " 6.6960847e-06 6.6960847e-06 6.6960847e-06 8.1397146e-03 8.1397146e-03\n",
      " 1.1563250e-02 1.3699084e-02 1.7670801e-02 1.8840695e-02 1.9735092e-02\n",
      " 2.3812084e-02 2.9073082e-02 2.8420057e-02 3.5425313e-02 3.5425313e-02]\n",
      "\n",
      "218 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00813302 0.00813302 0.01155655 0.01369239 0.0176641  0.018834\n",
      " 0.0197284  0.02380539 0.02906638 0.02841336 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "219 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00813302\n",
      " 0.00813302 0.01155655 0.01369239 0.0176641  0.018834   0.0197284\n",
      " 0.02380539 0.02906638 0.02841336 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "220 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00813302 0.00813302\n",
      " 0.01155655 0.01369239 0.0176641  0.018834   0.0197284  0.02380539\n",
      " 0.02906638 0.02841336 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "221 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00813302 0.00813302 0.01155655\n",
      " 0.01369239 0.0176641  0.018834   0.0197284  0.02380539 0.02906638\n",
      " 0.02841336 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "222 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00813302 0.00813302 0.01155655 0.01369239\n",
      " 0.0176641  0.018834   0.0197284  0.02380539 0.02906638 0.02841336\n",
      " 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "223 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00813302 0.00813302 0.01155655 0.01369239 0.0176641\n",
      " 0.018834   0.0197284  0.02380539 0.02906638 0.02841336 0.03541861\n",
      " 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "224 [0.         0.         0.         0.         0.         0.\n",
      " 0.00813302 0.00813302 0.01155655 0.01369239 0.0176641  0.018834\n",
      " 0.0197284  0.02380539 0.02906638 0.02841336 0.03541861 0.03541861\n",
      " 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "225 [0.         0.         0.         0.         0.         0.00813302\n",
      " 0.00813302 0.01155655 0.01369239 0.0176641  0.018834   0.0197284\n",
      " 0.02380539 0.02906638 0.02841336 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "226 [0.         0.         0.         0.         0.00813302 0.00813302\n",
      " 0.01155655 0.01369239 0.0176641  0.018834   0.0197284  0.02380539\n",
      " 0.02906638 0.02841336 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "227 [0.         0.         0.         0.00813302 0.00813302 0.01155655\n",
      " 0.01369239 0.0176641  0.018834   0.0197284  0.02380539 0.02906638\n",
      " 0.02841336 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "228 [0.         0.         0.00813302 0.00813302 0.01155655 0.01369239\n",
      " 0.0176641  0.018834   0.0197284  0.02380539 0.02906638 0.02841336\n",
      " 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "229 [0.         0.00813302 0.00813302 0.01155655 0.01369239 0.0176641\n",
      " 0.018834   0.0197284  0.02380539 0.02906638 0.02841336 0.03541861\n",
      " 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861 0.03541861\n",
      " 0.03541861]\n",
      "\n",
      "230 [0.         0.         0.00342353 0.00555937 0.00953109 0.01070098\n",
      " 0.01159538 0.01567237 0.02093336 0.02028035 0.0272856  0.0272856\n",
      " 0.0272856  0.0272856  0.0272856  0.0272856  0.0272856  0.0272856\n",
      " 0.0272856  0.0272856  0.0272856  0.0272856  0.0272856  0.0272856\n",
      " 0.0272856 ]\n",
      "\n",
      "231 [0.         0.00342353 0.00555937 0.00953109 0.01070098 0.01159538\n",
      " 0.01567237 0.02093336 0.02028035 0.0272856  0.0272856  0.0272856\n",
      " 0.0272856  0.0272856  0.0272856  0.0272856  0.0272856  0.0272856\n",
      " 0.0272856  0.0272856  0.0272856  0.0272856  0.0272856  0.0272856\n",
      " 0.0272856 ]\n",
      "\n",
      "232 [0.         0.00213583 0.00610755 0.00727745 0.00817184 0.01224883\n",
      " 0.01750983 0.01685681 0.02386206 0.02386206 0.02386206 0.02386206\n",
      " 0.02386206 0.02386206 0.02386206 0.02386206 0.02386206 0.02386206\n",
      " 0.02386206 0.02386206 0.02386206 0.02386206 0.02386206 0.02386206\n",
      " 0.02386206]\n",
      "\n",
      "233 [0.         0.00397172 0.00514161 0.00603601 0.010113   0.015374\n",
      " 0.01472098 0.02172623 0.02172623 0.02172623 0.02172623 0.02172623\n",
      " 0.02172623 0.02172623 0.02172623 0.02172623 0.02172623 0.02172623\n",
      " 0.02172623 0.02172623 0.02172623 0.02172623 0.02172623 0.02172623\n",
      " 0.02172623]\n",
      "\n",
      "234 [0.         0.00116989 0.00206429 0.00614128 0.01140227 0.01074926\n",
      " 0.01775451 0.01775451 0.01775451 0.01775451 0.01775451 0.01775451\n",
      " 0.01775451 0.01775451 0.01775451 0.01775451 0.01775451 0.01775451\n",
      " 0.01775451 0.01775451 0.01775451 0.01775451 0.01775451 0.01775451\n",
      " 0.01775451]\n",
      "\n",
      "235 [0.         0.0008944  0.00497139 0.01023238 0.00957936 0.01658462\n",
      " 0.01658462 0.01658462 0.01658462 0.01658462 0.01658462 0.01658462\n",
      " 0.01658462 0.01658462 0.01658462 0.01658462 0.01658462 0.01658462\n",
      " 0.01658462 0.01658462 0.01658462 0.01658462 0.01658462 0.01658462\n",
      " 0.01658462]\n",
      "\n",
      "236 [0.         0.00407699 0.00933799 0.00868497 0.01569022 0.01569022\n",
      " 0.01569022 0.01569022 0.01569022 0.01569022 0.01569022 0.01569022\n",
      " 0.01569022 0.01569022 0.01569022 0.01569022 0.01569022 0.01569022\n",
      " 0.01569022 0.01569022 0.01569022 0.01569022 0.01569022 0.01569022\n",
      " 0.01569022]\n",
      "\n",
      "237 [0.         0.00526099 0.00460798 0.01161323 0.01161323 0.01161323\n",
      " 0.01161323 0.01161323 0.01161323 0.01161323 0.01161323 0.01161323\n",
      " 0.01161323 0.01161323 0.01161323 0.01161323 0.01161323 0.01161323\n",
      " 0.01161323 0.01161323 0.01161323 0.01161323 0.01161323 0.01161323\n",
      " 0.01161323]\n",
      "\n",
      "238 [ 0.         -0.00065301  0.00635224  0.00635224  0.00635224  0.00635224\n",
      "  0.00635224  0.00635224  0.00635224  0.00635224  0.00635224  0.00635224\n",
      "  0.00635224  0.00635224  0.00635224  0.00635224  0.00635224  0.00635224\n",
      "  0.00635224  0.00635224  0.00635224  0.00635224  0.00635224  0.00635224\n",
      "  0.00635224]\n",
      "\n",
      "239 [0.         0.00700526 0.00700526 0.00700526 0.00700526 0.00700526\n",
      " 0.00700526 0.00700526 0.00700526 0.00700526 0.00700526 0.00700526\n",
      " 0.00700526 0.00700526 0.00700526 0.00700526 0.00700526 0.00700526\n",
      " 0.00700526 0.00700526 0.00700526 0.00700526 0.00700526 0.00700526\n",
      " 0.00700526]\n",
      "\n",
      "240 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "241 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "242 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "243 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.69592977]\n",
      "\n",
      "244 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "245 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "246 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "247 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "248 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "249 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "250 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "251 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "252 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "253 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "254 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "255 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "256 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "257 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "258 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "259 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "260 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.69592977]\n",
      "\n",
      "261 [0.         0.         0.         0.         0.         0.\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "262 [0.         0.         0.         0.         0.         0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "263 [0.         0.         0.         0.         0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "264 [0.         0.         0.         0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "265 [0.         0.         0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "266 [0.         0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977 0.69592977\n",
      " 0.69592977]\n",
      "\n",
      "267 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "268 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "269 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "270 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "271 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "272 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "273 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "274 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "275 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "276 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "277 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "278 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "279 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "280 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "281 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "282 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "283 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "284 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "285 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "286 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "287 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "288 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "289 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "290 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "291 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "292 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "293 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "294 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "295 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "296 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "297 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "298 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "299 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "300 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "301 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "302 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "303 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "304 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "305 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "306 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "307 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "308 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "309 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "310 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "311 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "312 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "313 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "314 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "315 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "316 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "317 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "318 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "319 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "320 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "321 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "322 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "323 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "324 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "325 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "326 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "327 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "328 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "329 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "330 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "331 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "332 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "333 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "334 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "335 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "336 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "337 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "338 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "339 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "340 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "341 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "342 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "343 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "344 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "345 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "346 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "347 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "348 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "349 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "350 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "351 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "352 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "353 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "354 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "355 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "356 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "357 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "358 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "359 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "360 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "361 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "362 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "363 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "364 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "365 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "366 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "367 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "368 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "369 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "370 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "371 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "372 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "373 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "374 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "375 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "376 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "377 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "378 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "379 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "380 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "381 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "382 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "383 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "384 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "385 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "386 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "387 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "388 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "389 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "390 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "391 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "392 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "393 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "394 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "395 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.66992927]\n",
      "\n",
      "396 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "397 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "398 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "399 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "400 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "401 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "402 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "403 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "404 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "405 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "406 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "407 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "408 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "409 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "410 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "411 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "412 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "413 [ 0.          0.          0.          0.          0.          0.\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "414 [ 0.          0.          0.          0.          0.         -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "415 [ 0.          0.          0.          0.         -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "416 [ 0.          0.          0.         -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "417 [ 0.          0.         -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "418 [ 0.         -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927 -0.66992927\n",
      " -0.66992927]\n",
      "\n",
      "419 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "420 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "421 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "422 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "423 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "424 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "425 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "426 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "427 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "428 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "429 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "430 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "431 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "432 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "433 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "434 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "435 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "436 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "437 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "438 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "439 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "440 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "441 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "442 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "443 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "444 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "445 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "446 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "447 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "448 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      " -0.6779532]\n",
      "\n",
      "449 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        -0.6779532\n",
      " -0.6524395]\n",
      "\n",
      "450 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        -0.6779532 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "451 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        -0.6779532 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "452 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        -0.6779532 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "453 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        -0.6779532 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "454 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      " -0.6779532 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "455 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        -0.6779532\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "456 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        -0.6779532 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "457 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        -0.6779532 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "458 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        -0.6779532 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "459 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        -0.6779532 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "460 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      " -0.6779532 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "461 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        -0.6779532\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "462 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        -0.6779532 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "463 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        -0.6779532 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "464 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        -0.6779532 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "465 [ 0.         0.         0.         0.         0.         0.\n",
      "  0.        -0.6779532 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "466 [ 0.         0.         0.         0.         0.         0.\n",
      " -0.6779532 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "467 [ 0.         0.         0.         0.         0.        -0.6779532\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "468 [ 0.         0.         0.         0.        -0.6779532 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "469 [ 0.         0.         0.        -0.6779532 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "470 [ 0.         0.        -0.6779532 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "471 [ 0.        -0.6779532 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395 -0.6524395\n",
      " -0.6524395]\n",
      "\n",
      "472 [0.        0.0255137 0.0255137 0.0255137 0.0255137 0.0255137 0.0255137\n",
      " 0.0255137 0.0255137 0.0255137 0.0255137 0.0255137 0.0255137 0.0255137\n",
      " 0.0255137 0.0255137 0.0255137 0.0255137 0.0255137 0.0255137 0.0255137\n",
      " 0.0255137 0.0255137 0.0255137 0.0255137]\n",
      "\n",
      "473 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "474 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "475 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "476 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "477 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "478 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "479 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "480 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "481 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "482 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "483 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "484 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "485 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "486 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "487 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "488 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "489 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "490 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "491 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "492 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "493 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "494 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "495 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "496 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "497 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "498 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "499 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "500 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "501 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "502 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "503 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "504 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "505 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "506 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "507 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "508 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "509 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "510 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "511 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "512 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "513 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "514 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "515 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "516 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "517 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "518 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "519 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "520 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "521 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "522 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "523 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "524 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "525 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "526 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "527 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "528 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "529 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "530 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "531 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "532 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "533 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "534 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "535 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "536 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "537 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "538 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "539 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "540 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "541 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "542 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "543 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "544 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "545 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "546 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "547 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "548 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "549 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "550 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "551 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "552 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "553 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "554 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "555 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "556 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "557 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "558 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "559 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "560 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "561 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "562 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "563 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "564 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "565 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "566 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "567 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "568 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "569 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "570 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "571 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "572 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "573 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "574 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "575 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "576 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "577 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "578 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "579 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "580 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "581 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "582 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "583 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "584 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "585 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "586 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "587 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "588 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "589 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "590 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "591 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "592 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "593 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "594 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "595 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "596 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "597 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "598 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "599 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "600 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "601 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "602 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "603 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "604 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "605 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "606 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "607 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "608 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "609 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "610 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "611 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "612 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "613 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "614 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "615 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "616 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "617 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "618 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "619 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "620 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "621 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "622 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "623 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "624 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "625 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "626 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "627 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "628 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "629 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "630 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "631 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "632 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "633 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "634 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "635 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "636 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "637 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "638 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "639 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "640 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "641 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "642 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "643 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "644 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "645 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "646 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "647 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "648 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "649 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "650 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "651 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "652 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "653 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "654 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "655 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "656 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "657 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "658 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "659 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "660 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "661 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "662 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "663 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "664 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "665 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "666 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "667 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "668 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "669 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "670 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "671 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "672 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "673 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "674 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "675 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "676 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "677 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "678 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "679 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "680 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "681 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "682 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "683 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "684 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "685 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "686 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "687 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "688 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "689 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "690 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "691 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "692 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "693 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "694 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "695 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "696 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "697 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "698 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "699 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "700 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "701 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "702 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "703 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "704 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "705 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "706 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "707 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "708 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "709 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "710 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "711 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "712 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "713 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "714 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "715 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "716 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "717 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "718 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "719 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "720 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "721 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "722 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "723 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "724 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "725 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "726 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "727 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "728 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "729 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "730 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "731 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "732 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "733 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "734 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "735 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "736 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "737 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "738 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "739 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "740 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "741 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "742 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "743 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "744 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "745 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "746 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "747 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "748 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "749 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "750 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "751 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "752 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "753 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "754 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "755 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "756 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "757 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "758 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "759 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "760 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "761 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "762 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "763 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "764 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "765 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "766 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "767 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "768 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "769 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "770 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "771 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "772 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "773 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "774 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "775 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "776 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "777 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "778 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "779 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "780 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "781 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "782 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "783 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "784 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "785 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "786 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "787 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "788 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "789 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "790 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "791 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "792 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "793 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "794 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "795 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "796 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "797 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "798 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "799 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "800 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "801 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "802 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "803 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "804 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "805 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "806 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "807 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "808 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "809 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "810 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "811 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "812 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "813 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "814 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "815 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "816 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "817 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "818 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "819 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "820 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "821 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "822 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "823 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "824 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "825 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "826 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "827 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "828 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "829 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "830 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "831 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "832 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "833 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "834 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "835 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "836 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "837 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "838 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "839 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "840 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "841 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "842 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "843 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "844 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "845 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "846 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "847 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "848 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "849 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "850 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "851 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "852 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "853 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "854 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "855 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "856 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "857 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "858 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "859 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "860 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "861 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "862 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "863 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "864 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "865 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "866 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "867 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "868 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "869 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "870 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "871 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "872 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "873 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "874 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "875 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "876 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "877 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "878 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "879 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "880 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "881 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "882 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "883 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "884 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "885 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "886 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "887 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "888 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "889 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "890 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "891 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "892 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "893 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "894 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "895 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "896 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "897 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "898 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "899 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "900 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "901 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "902 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "903 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "904 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "905 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "906 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "907 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "908 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "909 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "910 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "911 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "912 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "913 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "914 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "915 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "916 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "917 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "918 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "919 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "920 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "921 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "922 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "923 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "924 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "925 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "926 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "927 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "928 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "929 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "930 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "931 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "932 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "933 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "934 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "935 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "936 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "937 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "938 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "939 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "940 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "941 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "942 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "943 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "944 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "945 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "946 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "947 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "948 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "949 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "950 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "951 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "952 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "953 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "954 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "955 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "956 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "957 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "958 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "959 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "960 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "961 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "962 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "963 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "964 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "965 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "966 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "967 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "968 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "969 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "970 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "971 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "972 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "973 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "974 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "975 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "976 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "977 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "\n",
      "978 [ 0.0000000e+00  5.6406175e-04  5.6406175e-04  5.6406175e-04\n",
      "  5.6406175e-04  5.6406175e-04  5.6406175e-04 -1.8323311e-01\n",
      " -1.8323311e-01 -1.8323311e-01 -1.8323311e-01 -1.8323311e-01\n",
      " -1.8323311e-01 -1.8323311e-01 -1.8323311e-01 -1.8323311e-01\n",
      "  1.3523619e-01  1.3523619e-01  5.6406175e-04 -1.3328393e-04\n",
      " -1.3328393e-04 -1.3328393e-04 -1.3328393e-04 -1.7685845e-01\n",
      " -1.7716818e-01]\n",
      "\n",
      "979 [ 0.          0.          0.          0.          0.          0.\n",
      " -0.18379715 -0.18379715 -0.18379715 -0.18379715 -0.18379715 -0.18379715\n",
      " -0.18379715 -0.18379715 -0.18379715  0.13467212  0.13467212  0.\n",
      " -0.00069734 -0.00069734 -0.00069734 -0.00069734 -0.17742251 -0.17773224\n",
      " -0.17775561]\n",
      "\n",
      "980 [ 0.          0.          0.          0.          0.         -0.18379715\n",
      " -0.18379715 -0.18379715 -0.18379715 -0.18379715 -0.18379715 -0.18379715\n",
      " -0.18379715 -0.18379715  0.13467212  0.13467212  0.         -0.00069734\n",
      " -0.00069734 -0.00069734 -0.00069734 -0.17742251 -0.17773224 -0.17775561\n",
      " -0.17775561]\n",
      "\n",
      "981 [ 0.          0.          0.          0.         -0.18379715 -0.18379715\n",
      " -0.18379715 -0.18379715 -0.18379715 -0.18379715 -0.18379715 -0.18379715\n",
      " -0.18379715  0.13467212  0.13467212  0.         -0.00069734 -0.00069734\n",
      " -0.00069734 -0.00069734 -0.17742251 -0.17773224 -0.17775561 -0.17775561\n",
      " -0.17775561]\n",
      "\n",
      "982 [ 0.          0.          0.         -0.18379715 -0.18379715 -0.18379715\n",
      " -0.18379715 -0.18379715 -0.18379715 -0.18379715 -0.18379715 -0.18379715\n",
      "  0.13467212  0.13467212  0.         -0.00069734 -0.00069734 -0.00069734\n",
      " -0.00069734 -0.17742251 -0.17773224 -0.17775561 -0.17775561 -0.17775561\n",
      " -0.17777583]\n",
      "\n",
      "983 [ 0.          0.         -0.18379715 -0.18379715 -0.18379715 -0.18379715\n",
      " -0.18379715 -0.18379715 -0.18379715 -0.18379715 -0.18379715  0.13467212\n",
      "  0.13467212  0.         -0.00069734 -0.00069734 -0.00069734 -0.00069734\n",
      " -0.17742251 -0.17773224 -0.17775561 -0.17775561 -0.17775561 -0.17777583\n",
      " -0.17644319]\n",
      "\n",
      "984 [ 0.         -0.18379715 -0.18379715 -0.18379715 -0.18379715 -0.18379715\n",
      " -0.18379715 -0.18379715 -0.18379715 -0.18379715  0.13467212  0.13467212\n",
      "  0.         -0.00069734 -0.00069734 -0.00069734 -0.00069734 -0.17742251\n",
      " -0.17773224 -0.17775561 -0.17775561 -0.17775561 -0.17777583 -0.17644319\n",
      " -0.17643653]\n",
      "\n",
      "985 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3184693  0.3184693  0.18379715\n",
      " 0.1830998  0.1830998  0.1830998  0.1830998  0.00637464 0.00606494\n",
      " 0.00604158 0.00604158 0.00604158 0.00602134 0.00735399 0.00736064\n",
      " 0.00495586]\n",
      "\n",
      "986 [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3184693  0.3184693  0.18379715 0.1830998\n",
      " 0.1830998  0.1830998  0.1830998  0.00637464 0.00606494 0.00604158\n",
      " 0.00604158 0.00604158 0.00602134 0.00735399 0.00736064 0.00495586\n",
      " 0.00495586]\n",
      "\n",
      "987 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.3184693   0.3184693   0.18379715  0.1830998   0.1830998\n",
      "  0.1830998   0.1830998   0.00637464  0.00606494  0.00604158  0.00604158\n",
      "  0.00604158  0.00602134  0.00735399  0.00736064  0.00495586  0.00495586\n",
      " -0.00793622]\n",
      "\n",
      "988 [ 0.          0.          0.          0.          0.          0.\n",
      "  0.3184693   0.3184693   0.18379715  0.1830998   0.1830998   0.1830998\n",
      "  0.1830998   0.00637464  0.00606494  0.00604158  0.00604158  0.00604158\n",
      "  0.00602134  0.00735399  0.00736064  0.00495586  0.00495586 -0.00793622\n",
      " -0.01110569]\n",
      "\n",
      "989 [ 0.          0.          0.          0.          0.          0.3184693\n",
      "  0.3184693   0.18379715  0.1830998   0.1830998   0.1830998   0.1830998\n",
      "  0.00637464  0.00606494  0.00604158  0.00604158  0.00604158  0.00602134\n",
      "  0.00735399  0.00736064  0.00495586  0.00495586 -0.00793622 -0.01110569\n",
      " -0.01110569]\n",
      "\n",
      "990 [ 0.          0.          0.          0.          0.3184693   0.3184693\n",
      "  0.18379715  0.1830998   0.1830998   0.1830998   0.1830998   0.00637464\n",
      "  0.00606494  0.00604158  0.00604158  0.00604158  0.00602134  0.00735399\n",
      "  0.00736064  0.00495586  0.00495586 -0.00793622 -0.01110569 -0.01110569\n",
      " -0.01110569]\n",
      "\n",
      "991 [ 0.          0.          0.          0.3184693   0.3184693   0.18379715\n",
      "  0.1830998   0.1830998   0.1830998   0.1830998   0.00637464  0.00606494\n",
      "  0.00604158  0.00604158  0.00604158  0.00602134  0.00735399  0.00736064\n",
      "  0.00495586  0.00495586 -0.00793622 -0.01110569 -0.01110569 -0.01110569\n",
      " -0.0111037 ]\n",
      "\n",
      "992 [ 0.          0.          0.3184693   0.3184693   0.18379715  0.1830998\n",
      "  0.1830998   0.1830998   0.1830998   0.00637464  0.00606494  0.00604158\n",
      "  0.00604158  0.00604158  0.00602134  0.00735399  0.00736064  0.00495586\n",
      "  0.00495586 -0.00793622 -0.01110569 -0.01110569 -0.01110569 -0.0111037\n",
      " -0.01329419]\n",
      "\n",
      "993 [ 0.          0.3184693   0.3184693   0.18379715  0.1830998   0.1830998\n",
      "  0.1830998   0.1830998   0.00637464  0.00606494  0.00604158  0.00604158\n",
      "  0.00604158  0.00602134  0.00735399  0.00736064  0.00495586  0.00495586\n",
      " -0.00793622 -0.01110569 -0.01110569 -0.01110569 -0.0111037  -0.01329419\n",
      " -0.01329419]\n",
      "\n",
      "994 [ 0.          0.         -0.13467212 -0.13536948 -0.13536948 -0.13536948\n",
      " -0.13536948 -0.31209466 -0.31240433 -0.3124277  -0.3124277  -0.3124277\n",
      " -0.31244794 -0.3111153  -0.31110865 -0.3135134  -0.3135134  -0.32640547\n",
      " -0.32957494 -0.32957494 -0.32957494 -0.32957298 -0.33176348 -0.33176348\n",
      " -0.3320084 ]\n",
      "\n",
      "995 [ 0.         -0.13467212 -0.13536948 -0.13536948 -0.13536948 -0.13536948\n",
      " -0.31209466 -0.31240433 -0.3124277  -0.3124277  -0.3124277  -0.31244794\n",
      " -0.3111153  -0.31110865 -0.3135134  -0.3135134  -0.32640547 -0.32957494\n",
      " -0.32957494 -0.32957494 -0.32957298 -0.33176348 -0.33176348 -0.3320084\n",
      " -0.3328303 ]\n",
      "\n",
      "996 [ 0.         -0.00069734 -0.00069734 -0.00069734 -0.00069734 -0.17742251\n",
      " -0.17773224 -0.17775561 -0.17775561 -0.17775561 -0.17777583 -0.17644319\n",
      " -0.17643653 -0.17884131 -0.17884131 -0.19173339 -0.19490285 -0.19490285\n",
      " -0.19490285 -0.19490086 -0.19709136 -0.19709136 -0.1973363  -0.19815817\n",
      " -0.19894701]\n",
      "\n",
      "997 [ 0.          0.          0.          0.         -0.17672516 -0.17703488\n",
      " -0.17705826 -0.17705826 -0.17705826 -0.17707849 -0.17574583 -0.17573918\n",
      " -0.17814396 -0.17814396 -0.19103605 -0.19420551 -0.19420551 -0.19420551\n",
      " -0.19420351 -0.19639401 -0.19639401 -0.19663894 -0.19746083 -0.19824965\n",
      " -0.20139825]\n",
      "\n",
      "998 [ 0.          0.          0.         -0.17672516 -0.17703488 -0.17705826\n",
      " -0.17705826 -0.17705826 -0.17707849 -0.17574583 -0.17573918 -0.17814396\n",
      " -0.17814396 -0.19103605 -0.19420551 -0.19420551 -0.19420551 -0.19420351\n",
      " -0.19639401 -0.19639401 -0.19663894 -0.19746083 -0.19824965 -0.20139825\n",
      " -0.20983036]\n",
      "\n",
      "999 [ 0.          0.         -0.17672516 -0.17703488 -0.17705826 -0.17705826\n",
      " -0.17705826 -0.17707849 -0.17574583 -0.17573918 -0.17814396 -0.17814396\n",
      " -0.19103605 -0.19420551 -0.19420551 -0.19420551 -0.19420351 -0.19639401\n",
      " -0.19639401 -0.19663894 -0.19746083 -0.19824965 -0.20139825 -0.20983036\n",
      " -0.21326427]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/home/cat/angles_ego_animalID_3_duration_25.npy')\n",
    "print (data.shape)\n",
    "\n",
    "idx = np.where(data<0)[0]\n",
    "idx2 = np.unique(idx)\n",
    "print (idx2.shape)\n",
    "print (data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "########## FEATURIZE BEHAVIOR CHUNKS #########\n",
    "##############################################\n",
    "from sklearn import decomposition\n",
    "import sklearn\n",
    "\n",
    "fig = plt.figure()\n",
    "X_all = []\n",
    "n_events = []\n",
    "for animal_id in animal_ids:\n",
    "    X = X4[animal_id].copy()\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    print (X.shape)\n",
    "    X_all.append(X)\n",
    "    n_events.append(X.shape[0])\n",
    "\n",
    "#     \n",
    "X_all = np.vstack(X_all)\n",
    "print (X_all.shape)\n",
    "X = sklearn.preprocessing.normalize(X_all)\n",
    "\n",
    "#\n",
    "if True:\n",
    "    pca = decomposition.PCA(n_components=3)\n",
    "\n",
    "    X_pca = pca.fit_transform(X_all)\n",
    "    print (X_pca.shape)\n",
    "    \n",
    "if False:\n",
    "    import umap\n",
    "    umap = umap.UMAP(n_components=2,\n",
    "                    init='random',\n",
    "                    random_state=0)\n",
    "\n",
    "    umap_ = umap.fit(X_all[::10])\n",
    "\n",
    "    X_pca = umap_.transform(X_all)\n",
    "        \n",
    "\n",
    "print (\"plotting: \", X_pca.shape)\n",
    "\n",
    "\n",
    "print (n_events)\n",
    "fig=plt.figure()\n",
    "for k in range(4):\n",
    "    ax = plt.subplot(2,2,k+1)\n",
    "    start = np.int32(n_events[:k]).sum()\n",
    "    end = np.int32(n_events[:k+1]).sum()\n",
    "    print (start, end)\n",
    "    plt.scatter(X_pca[start:end,0],\n",
    "                X_pca[start:end,1],\n",
    "               alpha=.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
