{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/cat/code/gerbil/utils/')\n",
    "\n",
    "#\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "from visualize import Visualize\n",
    "from track import Track, detect_id_switch3\n",
    "\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "#\n",
    "import sleap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  /media/cat/256GB/dan/id_switch/day/2020_07_30_17_34_43_625922_compressed_Day.slp\n",
      "movie:  /media/cat/256GB/dan/id_switch/day/2020_07_30_17_34_43_625922_compressed_defished_shrink_cropped.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finding id switches in movie: 100%|██████████| 28801/28801 [00:11<00:00, 2537.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found:  0  switches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finding id switches in movie: 100%|██████████| 28801/28801 [00:11<00:00, 2543.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found:  5  switches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finding id switches in movie: 100%|██████████| 28801/28801 [00:09<00:00, 3071.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found:  2  switches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finding id switches in movie: 100%|██████████| 28801/28801 [00:08<00:00, 3402.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found:  15  switches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finding id switches in movie: 100%|██████████| 28801/28801 [00:08<00:00, 3279.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found:  5  switches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finding id switches in movie: 100%|██████████| 28801/28801 [00:09<00:00, 3002.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found:  14  switches\n",
      "DONE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#\n",
    "fnames_list = '/home/cat/data/dan/id_switch/day/fnames_day.txt'\n",
    "fnames_list = '/media/cat/4TB/dan/id_switch/day/fnames.txt'\n",
    "fnames_list = '/media/cat/256GB/dan/id_switch/day/fnames.txt'\n",
    "\n",
    "#\n",
    "fnames = np.loadtxt(fnames_list, \n",
    "                    dtype='str')\n",
    "\n",
    "#\n",
    "animal_ids = np.arange(6)\n",
    "all_frames = []\n",
    "#\n",
    "for fname_slp in fnames:\n",
    "    print (\"Loading: \", fname_slp)\n",
    "    \n",
    "    #fname_slp = '/home/cat/data/dan/2020_07_30_00_34_28_393297/day/2020_07_30_07_58_21_812233_compressed_Day.slp'\n",
    "    track = Track(fname_slp)\n",
    "    track.track_type = 'features'\n",
    "    track.use_dynamic_centroid = True   # True: alg. serches for the first non-nan value in this body order [2,3,1,0,4,5]\n",
    "    track.load_tracks()\n",
    "    \n",
    "    #\n",
    "    fname_movie = glob.glob(fname_slp[:-10]+\"*.mp4\")[0]\n",
    "    print (\"movie: \", fname_movie)\n",
    "    \n",
    "    #### FIND ALL ID SWITCHES IN MOVIE ####\n",
    "    all_frames = []\n",
    "    \n",
    "    for animal_id in animal_ids:\n",
    "    #for animal_id in [2]:\n",
    "        frame_ids = detect_id_switch3(track.tracks, \n",
    "                                      animal_id)\n",
    "        if len(frame_ids)>0:\n",
    "            all_frames.append(frame_ids)\n",
    "    break\n",
    "    \n",
    "print (\"DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "    \n",
    "# #\n",
    "# search_frames = np.int32(np.vstack(all_frames.copy()))\n",
    "# #search_frames = np.vstack((search_frames,\n",
    "# #                           [1000000,1000000,10]))\n",
    "\n",
    "# idx = np.argsort(search_frames[:,0])\n",
    "# search_frames = search_frames[idx]\n",
    "# print (search_frames[:,0])\n",
    "# #print (search_frames)\n",
    "\n",
    "\n",
    "# fname = '/home/cat/data/dan/id_switch/day/2020_07_30_07_58_21_812233_compressed_Day.slp'\n",
    "\n",
    "# #\n",
    "# names = ['female','male','pup1','pup2','pup3','pup4']\n",
    "\n",
    "\n",
    "# labels = sleap.load_file(fname)\n",
    "# n_videos = len(labels.videos)\n",
    "\n",
    "# #\n",
    "# n_all=0\n",
    "# for video_idx in range(n_videos):\n",
    "    \n",
    "#     # Change this select the video of interest from the labels.video list\n",
    "#     video = labels.videos[video_idx]\n",
    "#     labeled_frames_from_video = labels.get(video)\n",
    "    \n",
    "#     # Find indices of labeled frames to keep, note these are the indices of the `LabeledFrame`s in the labels.labeled_frames list\n",
    "#     lf_indices = search_frames[:,0] #[0, 2, 7, 101]  # Replace with list of labeled frame indices (NOT the same as video indices)\n",
    "    \n",
    "#     # Create a new `Labels` object containing only the matched `LabeledFrame`s\n",
    "#     labels_keep = labels.extract(lf_indices, copy=True)\n",
    "\n",
    "#     # Loop through matched `LabeledFrame`s\n",
    "#     ctr=0\n",
    "#     for lf, track_to_keep in zip(labels_keep.labeled_frames, tracks_to_keep):\n",
    "        \n",
    "#         #\n",
    "#         for inst_idx, inst in enumerate(lf.predicted_instances):\n",
    "            \n",
    "#             # get the predicted name\n",
    "#             name_predicted = lf.predicted_instances[inst_idx].track.name\n",
    "\n",
    "#             #  see if it matches the track to keep name \n",
    "#             if name_predicted!=track_to_keep:\n",
    "#                 lf.predicted_instances.remove(inst)                                                   #<----- dosn't work\n",
    "#                 del labels_keep.labeled_frames[ctr].predicted_instances[inst_idx]   #<-------------these functions don'tseem to work\n",
    "#                 labels_keep.labeled_frames[ctr].predicted_instances.remove(inst)    #  i.e. the saved file has all the tracks still\n",
    "#         ctr+=1\n",
    "        \n",
    "# # Save new slp\n",
    "# new_slp_path = fname[:-4]+\"_deleted.slp\"\n",
    "# labels_keep.save_file(labels_keep, new_slp_path)                          #<----- these files still have all the tracks in each predicted instance\n",
    "# sleap.Labels.save_file(labels_keep, new_slp_path[:-4]+\"_2.slp\")    #<----- same\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all frames:  [4718, 4719, 5111, 5112, 5112, 5113, 5113, 5114, 6202, 6203, 6258, 6259, 7603, 7604, 7608, 7609, 7610, 7611, 7618, 7619, 7831, 7832, 8388, 8389, 8392, 8393, 8440, 8441, 8544, 8545, 8573, 8574, 8591, 8592, 8592, 8593, 8634, 8635, 8644, 8645, 8876, 8877, 9135, 9136, 9189, 9190, 9302, 9303, 9383, 9384, 16224, 16225, 16225, 16226, 16491, 16492, 16493, 16494, 17159, 17160, 20936, 20937, 22341, 22342, 22351, 22352, 22730, 22731, 23393, 23394, 23394, 23395, 23395, 23396, 24003, 24004, 24004, 24005, 24005, 24006, 26591, 26592]\n",
      "['male', 'pup2', 'pup4', 'male', 'male', 'pup2', 'pup2', 'male', 'pup3', 'pup4', 'pup1', 'pup3', 'pup3', 'pup4', 'pup4', 'pup1', 'pup1', 'pup4', 'pup4', 'pup3', 'pup2', 'male', 'pup4', 'pup2', 'pup2', 'pup4', 'pup4', 'pup3', 'pup4', 'pup2', 'pup3', 'pup4', 'pup4', 'pup2', 'pup2', 'pup4', 'pup4', 'pup2', 'pup2', 'pup4', 'pup2', 'pup4', 'pup2', 'pup4', 'pup2', 'pup4', 'pup4', 'pup2', 'pup2', 'pup4', 'male', 'pup4', 'pup4', 'male', 'pup4', 'pup2', 'pup2', 'pup4', 'pup4', 'pup2', 'pup4', 'pup3', 'pup3', 'pup2', 'pup2', 'pup3', 'male', 'female', 'pup2', 'pup4', 'pup4', 'pup2', 'pup2', 'pup4', 'pup2', 'male', 'male', 'pup2', 'pup2', 'male', 'pup3', 'pup1']\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "# \n",
    "search_frames = np.vstack(all_frames.copy())\n",
    "# print (search_frames)\n",
    "# search_frames = np.vstack((search_frames,\n",
    "#                           [1000000,1000000,6,6]))\n",
    "\n",
    "# \n",
    "idx = np.argsort(search_frames[:,0])\n",
    "search_frames = search_frames[idx]\n",
    "# print (search_frames)\n",
    "\n",
    "# merge the frame pairs into each other\n",
    "all_ = []\n",
    "names_idx = []\n",
    "for k in range(len(search_frames)):\n",
    "    all_.append(search_frames[k,0])\n",
    "    all_.append(search_frames[k,1])\n",
    "    names_idx.append(search_frames[k,2])\n",
    "    names_idx.append(search_frames[k,3])\n",
    "\n",
    "#\n",
    "print (\"all frames: \", all_)\n",
    "\n",
    "#\n",
    "fname = '/media/cat/256GB/dan/id_switch/day/2020_07_30_17_34_43_625922_compressed_Day.slp'\n",
    "\n",
    "#\n",
    "names = ['female','male','pup1','pup2','pup3','pup4','none']\n",
    "\n",
    "#\n",
    "tracks_to_keep = []\n",
    "for idx in names_idx:\n",
    "    #print (idx)\n",
    "    tracks_to_keep.append(names[idx])\n",
    "#\n",
    "print (tracks_to_keep)\n",
    "\n",
    "#\n",
    "labels = sleap.load_file(fname)\n",
    "n_videos = len(labels.videos)\n",
    "\n",
    "#\n",
    "n_all=0\n",
    "for video_idx in range(n_videos):\n",
    "    \n",
    "    # Change this select the video of interest from the labels.video list\n",
    "    video = labels.videos[video_idx]\n",
    "    labeled_frames_from_video = labels.get(video)\n",
    "    \n",
    "    # Find indices of labeled frames to keep, note these are the indices of the `LabeledFrame`s in the labels.labeled_frames list\n",
    "    #lf_indices = search_frames[:,0] #[0, 2, 7, 101]  # Replace with list of labeled frame indices (NOT the same as video indices)\n",
    "    lf_indices = all_ #[0, 2, 7, 101]  # Replace with list of labeled frame indices (NOT the same as video indices)\n",
    "    \n",
    "    # Create a new `Labels` object containing only the matched `LabeledFrame`s\n",
    "    labels_keep = labels.extract(lf_indices, copy=True)\n",
    "\n",
    "    # Loop through matched `LabeledFrame`s\n",
    "    ctr=0\n",
    "    for lf, track_to_keep in zip(labels_keep.labeled_frames, tracks_to_keep):\n",
    "        \n",
    "        #\n",
    "        ctr_del = 0\n",
    "        for inst_idx, inst in enumerate(lf.predicted_instances):\n",
    "            \n",
    "            # get the predicted name\n",
    "            #print (\"instd idx: \", inst_idx)\n",
    "            name_predicted = lf.predicted_instances[inst_idx+ctr_del].track.name\n",
    "\n",
    "            #  see if it matches the track to keep name \n",
    "            if name_predicted!=track_to_keep:\n",
    "                lf.instances.remove(inst)\n",
    "                \n",
    "                \n",
    "                ctr_del-=1\n",
    "                #del labels_keep.labeled_frames[ctr].predicted_instances[inst_idx]   #<-------------these functions don'tseem to work\n",
    "                #labels_keep.labeled_frames[ctr].predicted_instances.remove(inst)    #  i.e. the saved file has all the tracks still\n",
    "        ctr+=1\n",
    "        \n",
    "# Save new slp\n",
    "new_slp_path = fname[:-4]+\"_deleted.slp\"\n",
    "labels_keep.save_file(labels_keep, new_slp_path)\n",
    "#sleap.Labels.save_file(labels_keep, new_slp_path[:-4]+\"_2.slp\")\n",
    "\n",
    "print (\"Done...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video(filename=/media/cat/256GB/dan/id_switch/day/test/output.mp4, shape=(102, 700, 900, 3), backend=MediaVideo)\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "############################################################\n",
    "############################################################\n",
    "\n",
    "#\n",
    "slp_files = [\n",
    "    \"/media/cat/256GB/dan/id_switch/day/test/2020_07_30_17_34_43_625922_compressed_Day_deleted.slp\",\n",
    "    \"/media/cat/256GB/dan/id_switch/day/test/2020_07_30_07_58_21_812233_compressed_Day_deleted.slp\",\n",
    "]\n",
    "\n",
    "# merged_video = sleap.load_video(\"merged_video.mp4\")\n",
    "# This is a hack since I don't have the merged video:\n",
    "#merged_video = sleap.load_file(slp_files[0]).videos[0]  # Comment this out!\n",
    "\n",
    "#\n",
    "merged_video = sleap.load_video('/media/cat/256GB/dan/id_switch/day/test/output.mp4')\n",
    "print (merged_video)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE...\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "############################################################\n",
    "############################################################\n",
    "\n",
    "\n",
    "\n",
    "n_frames = 0\n",
    "all_frames = []\n",
    "reference_tracks = {}\n",
    "\n",
    "first_labels = None\n",
    "for slp_file in slp_files:\n",
    "    # Load saved labels.\n",
    "    labels = sleap.load_file(slp_file, match_to=first_labels)\n",
    "    if first_labels is None:\n",
    "        first_labels = labels\n",
    "\n",
    "    new_frames = []\n",
    "    for i, lf in enumerate(labels):\n",
    "\n",
    "        # Update reference to merged video.\n",
    "        lf.video = merged_video\n",
    "\n",
    "        # Update frame index to the frame number within the merged video.\n",
    "        lf.frame_idx = n_frames + i\n",
    "\n",
    "        # Update the track reference to use the reference tracks to prevent duplication.\n",
    "        for instance in lf:\n",
    "            if instance.track is not None:\n",
    "                if instance.track.name in reference_tracks:\n",
    "                    instance.track = reference_tracks[instance.track.name]\n",
    "                else:\n",
    "                    reference_tracks[instance.track.name] = instance.track\n",
    "        \n",
    "        # Append the labeled frame to the list of frames we're keeping from these labels.\n",
    "        new_frames.append(lf)\n",
    "\n",
    "    all_frames.extend(new_frames)\n",
    "    n_frames += len(new_frames)\n",
    "\n",
    "merged_labels = sleap.Labels(all_frames)\n",
    "root_dir = '/media/cat/256GB/dan/id_switch/day/test/'\n",
    "merged_labels.save(root_dir+\"/merged_labels.slp\")\n",
    "\n",
    "print (\"DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.9'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "root_dir = '/media/cat/256GB/dan/id_switch/day/test/'\n",
    "merged_labels.save(root_dir+\"/merged_labels.slp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:00<00:00, 25.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "205\n",
      "173\n",
      "359\n",
      "287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:00<00:00, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464\n",
      "512\n",
      "306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [00:00<00:00, 15.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n",
      "354\n",
      "377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n",
      "4258\n",
      "locs:  (25548, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "############ VISUALIZE DELETED TRACKS ##############\n",
    "####################################################\n",
    "\n",
    "fname = \"/media/cat/256GB/dan/testing_track_cleanup_code/cohort2_night_1000/videos/cohort2_night.1000_deleted.slp\"\n",
    "labels = sleap.load_file(fname)\n",
    "\n",
    "labels.videos  # Use in ipython to print list of videos in the labels object\n",
    "n_videos = len(labels.videos)\n",
    "\n",
    "#\n",
    "locs = []\n",
    "for video_idx in trange(n_videos):\n",
    "    #video_idx =   # Change this select the video of interest from the labels.video list\n",
    "    video = labels.videos[video_idx]\n",
    "    labeled_frames_from_video = labels.get(video)\n",
    "\n",
    "    # Loop through all labeled frames (from a specific video)\n",
    "    n_frames = 0\n",
    "    for ctr1, lf in enumerate(labeled_frames_from_video):\n",
    "\n",
    "        # Loop through all user instances in the current labeled frame\n",
    "        for ctr2, inst in enumerate(lf.user_instances):\n",
    "\n",
    "            #\n",
    "            remove_inst = False\n",
    "            points_array = inst.points_array  # Returns a (num_nodes, 2) np.recarray\n",
    "            \n",
    "            #\n",
    "            #print (points_array[:,0])\n",
    "            #print (points_array[:,1])\n",
    "            idx1 = np.where(points_array[:,0]<200)[0]\n",
    "            idx2 = np.where(points_array[:,1]<200)[0]\n",
    "            \n",
    "            inter = list(set(idx1) & set(idx2))\n",
    "            locs.append(points_array)\n",
    "            \n",
    "            n_all+=1\n",
    "            n_frames+=1\n",
    "    print (n_frames)\n",
    "    \n",
    "print (n_all)\n",
    "locs = np.vstack(locs)\n",
    "print (\"locs: \", locs.shape)\n",
    "\n",
    "#\n",
    "plt.figure()\n",
    "plt.scatter(locs[:,0],\n",
    "            locs[:,1])\n",
    "plt.xlim(0,900)\n",
    "plt.ylim(0,700)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
