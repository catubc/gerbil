{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.use('Agg')\n",
    "#%matplotlib tk\n",
    "%autosave 180\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/cat/code/gerbil/utils/')\n",
    "\n",
    "#\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "#\n",
    "from visualize import Visualize\n",
    "from track import (find_id_switches_single_file,\n",
    "                  make_deleted_slp_files,\n",
    "                  make_hybrid_video_from_list)\n",
    "\n",
    "#\n",
    "import sleap\n",
    "\n",
    "#\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "#\n",
    "from tqdm import tqdm\n",
    "import parmap\n",
    "\n",
    "#\n",
    "from track import make_human_label_only_slp, make_human_label_only_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename completed:  /home/cat/data/dan/test_cohort_merge/2020_07_20_10_38_20_043555_compressed_Day.slp\n",
      "all frames:  (27, 4)\n",
      "filename completed:  /home/cat/data/dan/test_cohort_merge/2020_07_20_11_00_31_566455_compressed_Day.slp\n",
      "all frames:  (0,)\n",
      "filename completed:  /home/cat/data/dan/test_cohort_merge/2020_07_20_10_16_08_629297_compressed_Day.slp\n",
      "all frames:  (0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making deleted .slp file: 100%|███████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 12761.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n",
      "['/home/cat/data/dan/test_cohort_merge/2020_07_20_10_38_20_043555_compressed_defished_shrink_cropped.mp4', '/home/cat/data/dan/test_cohort_merge/2020_07_20_11_00_31_566455_compressed_defished_shrink_cropped.mp4', '/home/cat/data/dan/test_cohort_merge/2020_07_20_10_16_08_629297_compressed_defished_shrink_cropped.mp4']\n",
      "Fname hybrid movie:  /home/cat/data/dan/test_cohort_merge/hybrid_cropped.mp4\n",
      "/home/cat/data/dan/test_cohort_merge/2020_07_20_10_38_20_043555_*cropped*.mp4\n",
      "fname found:  /home/cat/data/dan/test_cohort_merge/2020_07_20_10_38_20_043555_compressed_defished_shrink_cropped.mp4\n",
      "/home/cat/data/dan/test_cohort_merge/2020_07_20_10_38_20_043555_compressed_defished_shrink_cropped.mp4 doesn't match ext for json or json.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "No file format adaptor could read this file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m d\u001b[38;5;241m.\u001b[39mmake_hybrid_video_from_list \u001b[38;5;241m=\u001b[39m make_hybrid_video_from_list\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_id_switch_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDONE...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 42\u001b[0m, in \u001b[0;36mDatabaseLoader.make_id_switch_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_deleted_slp_files(fnames_slp)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# make the hybrid video containing all the id-switch frames\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_hybrid_video_from_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfnames_vids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/gerbil/utils/track.py:2097\u001b[0m, in \u001b[0;36mmake_hybrid_video_from_list\u001b[0;34m(fnames_slp)\u001b[0m\n\u001b[1;32m   2095\u001b[0m track\u001b[38;5;241m.\u001b[39mtrack_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2096\u001b[0m track\u001b[38;5;241m.\u001b[39muse_dynamic_centroid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# True: alg. serches for the first non-nan value in this body order [2,3,1,0,4,5]\u001b[39;00m\n\u001b[0;32m-> 2097\u001b[0m \u001b[43mtrack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_tracks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;66;03m# load current vid\u001b[39;00m\n\u001b[1;32m   2100\u001b[0m original_vid \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(fname_movie)\n",
      "File \u001b[0;32m~/code/gerbil/utils/track.py:102\u001b[0m, in \u001b[0;36mTrack.load_tracks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... npy missing, converting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslp_to_npy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... done loading npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/gerbil/utils/track.py:74\u001b[0m, in \u001b[0;36mTrack.slp_to_npy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... h5 file missing, converting now...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslp_to_h5\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... done loading h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/gerbil/utils/track.py:62\u001b[0m, in \u001b[0;36mTrack.slp_to_h5\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m fname_h5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfname_slp[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m#print(\"... slp file not loaded, loading now...\")\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_slp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... done loading slp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/gerbil/utils/track.py:54\u001b[0m, in \u001b[0;36mTrack.load_slp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_slp\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslp \u001b[38;5;241m=\u001b[39m \u001b[43msleap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfname_slp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sleap/io/dataset.py:2681\u001b[0m, in \u001b[0;36mload_file\u001b[0;34m(filename, detect_videos, search_paths, match_to)\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m search_paths \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2680\u001b[0m         search_paths \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(filename)\n\u001b[0;32m-> 2681\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch_to\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2682\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Labels\u001b[38;5;241m.\u001b[39mload_file(filename, match_to\u001b[38;5;241m=\u001b[39mmatch_to)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sleap/io/dataset.py:1949\u001b[0m, in \u001b[0;36mLabels.load_file\u001b[0;34m(cls, filename, video_search, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;124;03m\"\"\"Load file, detecting format from filename.\"\"\"\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read\n\u001b[0;32m-> 1949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfor_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_search\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sleap/io/format/main.py:113\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, for_object, as_format, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[38;5;66;03m# print(f\"[registering format adaptor for {format_name}]\")\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m         disp\u001b[38;5;241m.\u001b[39mregister_list(default_labels_adaptors)\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo adaptors for this object type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sleap/io/format/dispatch.py:58\u001b[0m, in \u001b[0;36mDispatch.read\u001b[0;34m(self, filename, *args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m adaptor\u001b[38;5;241m.\u001b[39mcan_read_file(file):\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m adaptor\u001b[38;5;241m.\u001b[39mread(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file format adaptor could read this file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: No file format adaptor could read this file."
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "########### SET FNAMES FOR HUMAN AND ID SWITCH FILES ###########\n",
    "################################################################\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DatabaseLoader():\n",
    "    \n",
    "    #\n",
    "    def __init__(self, fname):\n",
    "        df = pd.read_excel(fname)\n",
    "        # print (\"DF: \", df)\n",
    "\n",
    "        self.df = df\n",
    "\n",
    "    #\n",
    "    def make_id_switch_files(self):\n",
    "        \n",
    "        # parse \n",
    "        fnames_slp = []\n",
    "        fnames_vids = []\n",
    "        for dd in D.df.iterrows():\n",
    "\n",
    "            #\n",
    "            if dd[1]['NN Type']==\"Day\":\n",
    "\n",
    "                fname_vid = dd[1]['Filename']\n",
    "                fname_slp = dd[1]['Slp filename']\n",
    "                fnames_slp.append(self.root_dir + fname_slp)\n",
    "                fnames_vids.append(self.root_dir + fname_vid)\n",
    "                \n",
    "                #\n",
    "                self.find_id_switches_single_file(self.root_dir + fname_slp,\n",
    "                                                 self.root_dir + fname_vid)\n",
    "\n",
    "                \n",
    "                \n",
    "        # make the id-switch only deleted slp files\n",
    "        self.make_deleted_slp_files(fnames_slp)\n",
    "                \n",
    "        # make the hybrid video containing all the id-switch frames\n",
    "        self.make_hybrid_video_from_list(fnames_vids)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#\n",
    "#     def load_sessions(self, animal_id):\n",
    "#         idx = np.where(self.df['Mouse_id'] == animal_id)[0].squeeze()\n",
    "#         P_start = int(self.df.iloc[idx]['Pday_start'])\n",
    "#         P_end = int(self.df.iloc[idx]['Pday_end'])\n",
    "#         #print(\"start: end: \", P_start, P_end)\n",
    "\n",
    "#         #\n",
    "#         session_ids = self.df.iloc[idx]['Session_ids'].split(',')\n",
    "#         session_ids = [x.strip(' ') for x in session_ids]\n",
    "\n",
    "#         self.sessions = session_ids\n",
    "\n",
    " \n",
    "#####################################################################\n",
    "#\n",
    "root_dir = '/home/cat/data/dan/test_cohort_merge/'\n",
    "fname_database = 'database.xlsx'\n",
    "\n",
    "#\n",
    "d = DatabaseLoader(root_dir + fname_database)\n",
    "d.root_dir = root_dir\n",
    "d.find_id_switches_single_file = find_id_switches_single_file\n",
    "d.make_deleted_slp_files = make_deleted_slp_files\n",
    "d.make_hybrid_video_from_list = make_hybrid_video_from_list\n",
    "\n",
    "#\n",
    "d.make_id_switch_files()\n",
    "\n",
    "#\n",
    "print (\"DONE...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "########### SET FNAMES FOR HUMAN AND ID SWITCH FILES ###########\n",
    "################################################################\n",
    "#\n",
    "fname_human_slp = '/home/cat/data/dan/human_labeled_data/hybrid.slp'\n",
    "fname_human_video = '/home/cat/data/dan/human_labeled_data/hybrid.avi'\n",
    "fname_idswitch_slp = '/home/cat/data/dan/id_switch/day/hybrid_cropped.slp'\n",
    "fname_idswitch_video = '/home/cat/data/dan/id_switch/day/hybrid_cropped.mp4'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video(filename=/home/cat/data/dan/human_labeled_data/hybrid_merged.avi, shape=(1537, 700, 900, 3), backend=MediaVideo)\n",
      "DONE...\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "####################### MERGE SLP FILES ########################\n",
    "################################################################\n",
    "\n",
    "def merge_slp_files(fname_slp1, fname_slp2):\n",
    "    \n",
    "    #\n",
    "    fname_hybrid_video = fname_slp1[:-4]+\"_merged.avi\"\n",
    "    \n",
    "    #\n",
    "    merged_video = sleap.load_video(fname_hybrid_video)\n",
    "    print(merged_video)\n",
    "\n",
    "    #\n",
    "    fname_hybrid_slp = fname_hybrid_video[:-4] + \".slp\"\n",
    "\n",
    "    #\n",
    "    slp_files = [fname_slp1,\n",
    "                 fname_slp2\n",
    "                ]\n",
    "    \n",
    "    n_frames = 0\n",
    "    all_frames = []\n",
    "    reference_tracks = {}\n",
    "\n",
    "    first_labels = None\n",
    "    for slp_file in slp_files:\n",
    "        \n",
    "        # Load saved labels.\n",
    "        labels = sleap.load_file(slp_file)#, match_to=first_labels)\n",
    "        if first_labels is None:\n",
    "            first_labels = labels\n",
    "\n",
    "        new_frames = []\n",
    "        for i, lf in enumerate(labels):\n",
    "\n",
    "            # Update reference to merged video.\n",
    "            lf.video = merged_video\n",
    "\n",
    "            # Update frame index to the frame number within the merged video.\n",
    "            lf.frame_idx = n_frames + i\n",
    "\n",
    "            # # Update the track reference to use the reference tracks to prevent duplication.\n",
    "            for instance in lf:\n",
    "                if instance.track is not None:\n",
    "                    if instance.track.name in reference_tracks:\n",
    "                        instance.track = reference_tracks[instance.track.name]\n",
    "                    else:\n",
    "                        reference_tracks[instance.track.name] = instance.track\n",
    "\n",
    "            # Append the labeled frame to the list of frames we're keeping from these labels.\n",
    "            new_frames.append(lf)\n",
    "\n",
    "        all_frames.extend(new_frames)\n",
    "        n_frames += len(new_frames)\n",
    "\n",
    "    merged_labels = sleap.Labels(all_frames)\n",
    "\n",
    "    # save stuff\n",
    "    merged_labels.save(fname_hybrid_slp)\n",
    "\n",
    "    print(\"DONE...\")\n",
    "\n",
    "# \n",
    "merge_slp_files(fname_human_slp,\n",
    "                fname_idswitch_slp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fname hybrid movie:  /home/cat/data/dan/human_labeled_data/hybrid_merged.avi\n",
      "done...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "def merge_video_files(fname_video1, \n",
    "                      fname_video2):\n",
    "    #\n",
    "    #root_dir = os.path.split(fnames_videos[0])[0] + '/'\n",
    "\n",
    "    fnames = [\n",
    "        fname_video1,\n",
    "        fname_video2        \n",
    "    ]\n",
    "    \n",
    "    # make new video video settings\n",
    "    size_vid = np.int32(np.array([900, 700]))\n",
    "    fps_out = 1\n",
    "    dot_size = 4\n",
    "    thickness = -1\n",
    "    window = 100\n",
    "    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'X264')\n",
    "    # #fourcc = cv2.VideoWriter_fourcc(*args[\"codec\"])\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    # fourcc = cv2.VideoWriter_fourcc('p', 'n', 'g', '')\n",
    "\n",
    "    # load videos\n",
    "    fname_out = fname_video1[:-4]+\"_merged.avi\"\n",
    "\n",
    "    #\n",
    "    print(\"Fname hybrid movie: \", fname_out)\n",
    "\n",
    "    # make new video video settings\n",
    "    size_vid = np.int32(np.array([900, 700]))\n",
    "    fps_out = 1\n",
    "\n",
    "    #\n",
    "    video_out = cv2.VideoWriter(fname_out,\n",
    "                                fourcc,\n",
    "                                fps_out,\n",
    "                                (size_vid[0], size_vid[1]),\n",
    "                                True)\n",
    "\n",
    "    # loop over each video file\n",
    "    ctr = 0\n",
    "    #for idx, fname_video in tqdm(zip(idxs, fnames_videos)):\n",
    "    for fname_video in fnames:\n",
    "        print (\"processing: \", fname_video)\n",
    "        # load current vid\n",
    "        original_vid = cv2.VideoCapture(fname_video)\n",
    "        #original_vid.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        \n",
    "        while True:\n",
    "            #\n",
    "            ret, img_out = original_vid.read()\n",
    "            \n",
    "            if ret==False:\n",
    "                break\n",
    "            \n",
    "            #\n",
    "            video_out.write(img_out)\n",
    "\n",
    "        # fname_video_old = fname_video\n",
    "        original_vid.release()\n",
    "\n",
    "        ctr += 1\n",
    "\n",
    "    video_out.release()\n",
    "\n",
    "    print(\"done...\")\n",
    "\n",
    "merge_video_files(fname_human_video, \n",
    "                    fname_idswitch_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fname hybrid movie:  /home/cat/data/dan/merge_hybrid_slp//hybrid.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [06:04,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "############ MAKE HYBRID HUMAN LABELED VIDEO ################\n",
    "#############################################################\n",
    "\n",
    "#\n",
    "fname_idx = np.load(fname_merged_video[:-4]+'_frames_idx.npy')\n",
    "fnames_videos = np.load(fname_merged_video[:-4]+'_fnames.npy')\n",
    "\n",
    "# make hybrid video from indexes\n",
    "make_human_label_only_video(fname_idx, \n",
    "                                fnames_videos)\n",
    "\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001,)\n"
     ]
    }
   ],
   "source": [
    "d = np.load('/home/cat/data/dan/merge_hybrid_slp/cohort2_day.1000_deleted_fnames.npy')\n",
    "print (d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_21_11_26_07_855478_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_22_11_26_41_511545_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_23_12_34_43_379948_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_24_11_07_26_770344_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_25_11_53_43_289403_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_26_11_33_46_565149_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_27_19_21_59_379709_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_28_11_38_02_143208_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_29_11_36_24_541088_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_30_11_30_11_732262_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_07_31_11_22_34_209876_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format='')), Video(backend=MediaVideo(filename='/home/cat/data/dan/merge_hybrid_slp/2020_08_01_11_27_15_857870_compressed_corrected.mp4', grayscale=False, bgr=True, dataset='', input_format=''))]\n"
     ]
    }
   ],
   "source": [
    "labels = sleap.load_file('/home/cat/data/dan/merge_hybrid_slp/cohort2_day.1000.slp')\n",
    "print (labels.videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/cat/data/dan/merge_hybrid_slp/2020_07_29_11_36_24_541088_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_29_11_36_24_541088_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_29_11_36_24_541088_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_29_11_36_24_541088_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_29_11_36_24_541088_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_29_11_36_24_541088_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_29_11_36_24_541088_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_29_11_36_24_541088_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_30_11_30_11_732262_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_30_11_30_11_732262_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_30_11_30_11_732262_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_30_11_30_11_732262_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_30_11_30_11_732262_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_31_11_22_34_209876_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_31_11_22_34_209876_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_31_11_22_34_209876_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_31_11_22_34_209876_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_31_11_22_34_209876_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_31_11_22_34_209876_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_31_11_22_34_209876_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_07_31_11_22_34_209876_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_08_01_11_27_15_857870_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_08_01_11_27_15_857870_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_08_01_11_27_15_857870_compressed_corrected.mp4'\n",
      " '/home/cat/data/dan/merge_hybrid_slp/2020_08_01_11_27_15_857870_compressed_corrected.mp4']\n"
     ]
    }
   ],
   "source": [
    "d = np.load('/home/cat/data/dan/merge_hybrid_slp/hybrid_fnames.npy')\n",
    "print (d[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instance(video=Video(filename=/home/cat/code/sleap/cohort2/day/2020_07_29_11_36_24_541088_compressed_corrected.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=0, points=[nose: (408.9, 343.6), spine1: (431.6, 357.6), spine2: (459.1, 362.0), spine3: (489.8, 362.6), spine4: (520.0, 361.8), spine5: (546.6, 362.7)], track=Track(spawned_on=0, name='male')),\n",
       " Instance(video=Video(filename=/home/cat/code/sleap/cohort2/day/2020_07_29_11_36_24_541088_compressed_corrected.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=0, points=[nose: (703.2, 511.3), spine1: (739.6, 528.7), spine2: (766.3, 542.4), spine3: (789.6, 545.7), spine4: (803.2, 531.5), spine5: (802.1, 510.7)], track=Track(spawned_on=0, name='female')),\n",
       " Instance(video=Video(filename=/home/cat/code/sleap/cohort2/day/2020_07_29_11_36_24_541088_compressed_corrected.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=0, points=[nose: (632.9, 318.0), spine1: (655.7, 296.2), spine2: (669.7, 281.9), spine3: (686.9, 270.3), spine4: (704.9, 268.2), spine5: (719.7, 278.5)], track=Track(spawned_on=0, name='pup3')),\n",
       " Instance(video=Video(filename=/home/cat/code/sleap/cohort2/day/2020_07_29_11_36_24_541088_compressed_corrected.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=0, points=[nose: (739.2, 262.4), spine1: (733.4, 227.3), spine2: (727.6, 211.5), spine3: (717.7, 195.1), spine4: (705.7, 181.0), spine5: (689.5, 171.5)], track=Track(spawned_on=0, name='pup1')),\n",
       " Instance(video=Video(filename=/home/cat/code/sleap/cohort2/day/2020_07_29_11_36_24_541088_compressed_corrected.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=0, points=[nose: (876.0, 281.6), spine1: (866.3, 303.0), spine2: (855.3, 324.4), spine3: (832.8, 339.6), spine4: (803.2, 343.3), spine5: (780.0, 321.6)], track=Track(spawned_on=0, name='pup4')),\n",
       " Instance(video=Video(filename=/home/cat/code/sleap/cohort2/day/2020_07_29_11_36_24_541088_compressed_corrected.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=0, points=[nose: (731.9, 150.8), spine1: (765.0, 170.0), spine2: (773.6, 179.7), spine3: (779.5, 193.8), spine4: (784.9, 212.2), spine5: (784.2, 237.5)], track=Track(spawned_on=0, name='pup2'))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf.user_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fname = \"/media/cat/256GB/dan/testing_track_cleanup_code/cohort2_night_1000/videos/cohort2_night.1000.slp\"\n",
    "labels = sleap.load_file(fname)\n",
    "\n",
    "labels.videos  # Use in ipython to print list of videos in the labels object\n",
    "n_videos = len(labels.videos)\n",
    "\n",
    "#\n",
    "#huddle_location = np.array([150,150])\n",
    "#min_dist = 100\n",
    "huddle_block = np.array([200,\n",
    "                         200])\n",
    "\n",
    "\n",
    "#\n",
    "n_all=0\n",
    "for video_idx in trange(n_videos):\n",
    "    #video_idx =   # Change this select the video of interest from the labels.video list\n",
    "    video = labels.videos[video_idx]\n",
    "    labeled_frames_from_video = labels.get(video)\n",
    "\n",
    "    # Loop through all labeled frames (from a specific video)\n",
    "    n_frames = 0\n",
    "    for ctr1, lf in enumerate(labeled_frames_from_video):\n",
    "\n",
    "        # Loop through all user instances in the current labeled frame\n",
    "        for ctr2, inst in enumerate(lf.user_instances):\n",
    "\n",
    "            #\n",
    "            remove_inst = False\n",
    "            points_array = inst.points_array  # Returns a (num_nodes, 2) np.recarray\n",
    "\n",
    "            # SQUARE EXCLUDE this checks for any features at all in the exclusion radius\n",
    "            if True:\n",
    "                idx = np.where(np.isnan(points_array.sum(1))==False)[0]\n",
    "                points_array = points_array[idx]\n",
    "                \n",
    "                # check the x and y locatoins\n",
    "                idx1 = np.where(points_array[:,0]<huddle_block[0])[0]\n",
    "                idx2 = np.where(points_array[:,1]<huddle_block[1])[0]\n",
    "                \n",
    "                # if any point is in both lists then it's in the huddle zone\n",
    "                if set(idx1) & set(idx2):\n",
    "                    lf.instances.remove(inst)\n",
    "                    #\n",
    "                #dist = np.linalg.norm(points_array-huddle_location, axis=1)\n",
    "                #dist = np.min(dist)\n",
    "\n",
    "\n",
    "            #print ('')\n",
    "\n",
    "# Save the modified slp\n",
    "new_filename = fname[:-4]+\"_deleted.slp\"  # Use a different path from the current slp to be safe\n",
    "labels.save_file(labels, new_filename)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fname hybrid movie:  /media/cat/4TB/dan/id_switch/day/hybrid_cropped.mp4\n",
      "fname found:  /media/cat/4TB/dan/id_switch/day/2020_07_30_07_58_21_812233_compressed_defished_shrink_cropped.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding frames to movies: 100%|██████████| 10/10 [00:01<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname found:  /media/cat/4TB/dan/id_switch/day/2020_07_30_11_06_03_274369_compressed_defished_shrink_cropped.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding frames to movies: 100%|██████████| 67/67 [00:07<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname found:  /media/cat/4TB/dan/id_switch/day/2020_07_30_14_11_50_567584_compressed_defished_shrink_cropped.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding frames to movies: 100%|██████████| 97/97 [00:10<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname found:  /media/cat/4TB/dan/id_switch/day/2020_07_30_17_34_43_625922_compressed_defished_shrink_cropped.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding frames to movies: 100%|██████████| 41/41 [00:04<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname found:  /media/cat/4TB/dan/id_switch/day/2020_07_30_19_25_43_717047_compressed_defished_shrink_cropped.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding frames to movies: 100%|██████████| 53/53 [00:05<00:00,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "############ MAKE THE HYBRID VIDEO ################\n",
    "###################################################\n",
    "\n",
    "# make hybrid video\n",
    "make_hybrid_video(fnames_slp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making deleted .slp file:  20%|██        | 1/5 [00:03<00:15,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making deleted .slp file:  40%|████      | 2/5 [00:09<00:14,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making deleted .slp file:  60%|██████    | 3/5 [00:14<00:09,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making deleted .slp file:  80%|████████  | 4/5 [00:19<00:04,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making deleted .slp file: 100%|██████████| 5/5 [00:24<00:00,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "################# CLEAN UP .SLP FILES ########################\n",
    "##############################################################\n",
    "\n",
    "#\n",
    "make_deleted_slp_files(fnames_slp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video(filename=/media/cat/4TB/dan/id_switch/day/hybrid_cropped.mp4, shape=(536, 700, 900, 3), backend=MediaVideo)\n",
      "DONE...\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "################# MAKE HYBRID .SLP FILE ######################\n",
    "##############################################################\n",
    "\n",
    "#\n",
    "fname_hybrid_video = os.path.split(fnames_slp_list)[0]+'/hybrid_cropped.mp4'\n",
    "make_hybrid_slp(fnames_slp_list,\n",
    "                fname_hybrid_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
