{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/cat/code/gerbil/utils/')\n",
    "\n",
    "#\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "from visualize import Visualize\n",
    "from track import Track, detect_id_switch2\n",
    "\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "#\n",
    "import sleap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  /home/cat/data/dan/id_switch/day/2020_07_30_07_58_21_812233_compressed_Day.slp\n",
      "movie:  /home/cat/data/dan/id_switch/day/2020_07_30_07_58_21_812233_compressed.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finding id switches in movie: 100%|██████████████████████████| 28801/28801 [00:04<00:00, 6142.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found:  6  switches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#\n",
    "fnames_list = '/home/cat/data/dan/id_switch/day/fnames_day.txt'\n",
    "\n",
    "#\n",
    "fnames = np.loadtxt(fnames_list, \n",
    "                    dtype='str')\n",
    "\n",
    "#\n",
    "animal_ids = np.arange(6)\n",
    "\n",
    "#\n",
    "for fname_slp in fnames:\n",
    "    print (\"Loading: \", fname_slp)\n",
    "    \n",
    "    #fname_slp = '/home/cat/data/dan/2020_07_30_00_34_28_393297/day/2020_07_30_07_58_21_812233_compressed_Day.slp'\n",
    "    track = Track(fname_slp)\n",
    "    track.track_type = 'features'\n",
    "    track.use_dynamic_centroid = True   # True: alg. serches for the first non-nan value in this body order [2,3,1,0,4,5]\n",
    "    track.load_tracks()\n",
    "    \n",
    "    #\n",
    "    fname_movie = glob.glob(fname_slp[:-10]+\"*.mp4\")[0]\n",
    "    print (\"movie: \", fname_movie)\n",
    "    \n",
    "    #### FIND ALL ID SWITCHES IN MOVIE ####\n",
    "    all_frames = []\n",
    "    \n",
    "    #for animal_id in animal_ids:\n",
    "    for animal_id in [2]:\n",
    "        frame_ids = detect_id_switch2(track.tracks, \n",
    "                                      animal_id)\n",
    "        if len(frame_ids)>0:\n",
    "            for f in frame_ids:\n",
    "                all_frames.append([f[0], f[1], animal_id])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12959, 12960, 2], [13016, 13017, 2], [14566, 14567, 2], [14678, 14679, 2], [16416, 16417, 2], [16580, 16581, 2]]\n",
      "12959 True\n",
      "pup1 pup1\n",
      "inst:  PredictedInstance(video=Video(filename=/scratch/cm5635/cohort2/2020_07_30_07_58_21_812233_compressed_defished_shrink_cropped.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=12959, points=[nose: (415.3, 400.4, 0.73), spine1: (400.4, 371.6, 0.75), spine2: (392.6, 351.8, 0.68), spine3: (396.0, 332.2, 0.78), spine4: (411.8, 320.7, 0.52), spine5: (428.4, 316.4, 0.77)], score=0.81, track=Track(spawned_on=0, name='pup1'), tracking_score=0.00)\n",
      "13016 True\n",
      "pup1 pup1\n",
      "inst:  PredictedInstance(video=Video(filename=/scratch/cm5635/cohort2/2020_07_30_07_58_21_812233_compressed_defished_shrink_cropped.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=13016, points=[nose: (396.3, 411.2, 0.81), spine1: (400.9, 387.6, 0.78), spine2: (408.1, 367.6, 0.85), spine3: (416.3, 348.2, 0.71), spine4: (424.3, 328.1, 0.67), spine5: (435.9, 308.2, 0.93)], score=0.89, track=Track(spawned_on=0, name='pup1'), tracking_score=0.00)\n",
      "14566 True\n",
      "pup1 pup1\n",
      "inst:  PredictedInstance(video=Video(filename=/scratch/cm5635/cohort2/2020_07_30_07_58_21_812233_compressed_defished_shrink_cropped.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=14566, points=[nose: (352.0, 404.8, 0.77), spine1: (319.9, 399.9, 0.71), spine2: (307.8, 395.7, 0.81), spine3: (299.5, 391.1, 0.84), spine4: (292.3, 383.4, 0.76), spine5: (287.5, 379.3, 0.64)], score=0.88, track=Track(spawned_on=0, name='pup1'), tracking_score=0.00)\n",
      "14678 True\n",
      "pup1 pup1\n",
      "inst:  PredictedInstance(video=Video(filename=/scratch/cm5635/cohort2/2020_07_30_07_58_21_812233_compressed_defished_shrink_cropped.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=14678, points=[nose: (343.9, 351.5, 0.83), spine1: (320.0, 375.6, 0.69), spine2: (312.5, 380.4, 0.81), spine3: (304.4, 388.5, 0.84), spine4: (299.4, 395.9, 0.84), spine5: (291.9, 396.8, 0.58)], score=0.96, track=Track(spawned_on=0, name='pup1'), tracking_score=0.00)\n",
      "16416 True\n",
      "pup1 pup1\n",
      "inst:  PredictedInstance(video=Video(filename=/scratch/cm5635/cohort2/2020_07_30_07_58_21_812233_compressed_defished_shrink_cropped.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=16416, points=[nose: (372.0, 423.9, 0.30), spine1: (360.2, 455.8, 0.59), spine2: (360.3, 463.9, 0.82), spine3: (368.1, 475.5, 0.65), spine4: (384.1, 476.2, 0.65), spine5: (399.3, 476.0, 0.73)], score=0.74, track=Track(spawned_on=0, name='pup1'), tracking_score=0.00)\n",
      "16580 True\n",
      "pup1 pup1\n",
      "inst:  PredictedInstance(video=Video(filename=/scratch/cm5635/cohort2/2020_07_30_07_58_21_812233_compressed_defished_shrink_cropped.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=16580, points=[nose: (532.3, 547.6, 1.00), spine1: (551.8, 563.2, 0.69), spine2: (168.0, 515.4, 0.24), spine3: (164.6, 500.3, 0.73), spine4: (612.3, 575.1, 0.62), spine5: (631.6, 563.8, 0.85)], score=0.70, track=Track(spawned_on=0, name='pup1'), tracking_score=0.00)\n",
      "Labels(labeled_frames=28802, videos=1, skeletons=1, tracks=6)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "No adaptors for object type <class 'list'> (None).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [61], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Save the modified slp\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     new_filename \u001b[38;5;241m=\u001b[39m fname[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_deleted.slp\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Use a different path from the current slp to be safe\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabeled_frames_from_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDONE...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gerbils/lib/python3.10/site-packages/sleap/io/dataset.py:1975\u001b[0m, in \u001b[0;36mLabels.save_file\u001b[0;34m(cls, labels, filename, default_suffix, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1971\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(filename), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1973\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m write\n\u001b[0;32m-> 1975\u001b[0m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gerbils/lib/python3.10/site-packages/sleap/io/format/main.py:164\u001b[0m, in \u001b[0;36mwrite\u001b[0;34m(filename, source_object, as_format, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     disp\u001b[38;5;241m.\u001b[39mregister_list(default_labels_adaptors)\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disp\u001b[38;5;241m.\u001b[39mwrite(filename, source_object, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo adaptors for object type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(source_object)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mas_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: No adaptors for object type <class 'list'> (None)."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "    \n",
    "#\n",
    "print (all_frames)\n",
    "search_frames = all_frames.copy()\n",
    "search_frames = np.vstack((search_frames,\n",
    "                           [1000000,1000000,10]))\n",
    "\n",
    "fname = '/home/cat/data/dan/id_switch/day/2020_07_30_07_58_21_812233_compressed_Day.slp'\n",
    "\n",
    "#\n",
    "names = ['female','male','pup1','pup2','pup3','pup4']\n",
    "\n",
    "#\n",
    "labels = sleap.load_file(fname)\n",
    "\n",
    "labels.videos  # Use in ipython to print list of videos in the labels object\n",
    "n_videos = len(labels.videos)\n",
    "\n",
    "#\n",
    "n_all=0\n",
    "for video_idx in range(n_videos):\n",
    "    #video_idx =   # Change this select the video of interest from the labels.video list\n",
    "    video = labels.videos[video_idx]\n",
    "    labeled_frames_from_video = labels.get(video)\n",
    "\n",
    "    # Loop through all labeled frames (from a specific video)\n",
    "    n_frames = 0\n",
    "    ctr1=0\n",
    "    for lf in labeled_frames_from_video:\n",
    "\n",
    "        #\n",
    "        if ctr1==search_frames[0][0]:\n",
    "            print (ctr1, lf.has_predicted_instances)\n",
    "            #\n",
    "            name_switched = names[search_frames[0][2]]\n",
    "            \n",
    "            #\n",
    "            n_inst = np.arange(lf.n_predicted_instances)\n",
    "            \n",
    "            #\n",
    "            for k, inst in zip(n_inst, lf.predicted_instances):\n",
    "                \n",
    "                #\n",
    "                name_predicted = lf.predicted_instances[k].track.name\n",
    "                \n",
    "                if name_predicted == name_switched:\n",
    "                    print (name_predicted, name_switched)\n",
    "                    print (\"inst: \", inst)\n",
    "                # delete the non-important instances:\n",
    "                else:\n",
    "                    lf.predicted_instances.remove(inst)\n",
    "                    \n",
    "            search_frames = search_frames[1:]\n",
    "        else:\n",
    "            for inst in lf.predicted_instances:\n",
    "                \n",
    "                lf.predicted_instances.remove(inst)\n",
    "        ctr1+=1\n",
    "        \n",
    "\n",
    "    print (labels)\n",
    "    # Save the modified slp\n",
    "    new_filename = fname[:-4]+\"_deleted.slp\"  # Use a different path from the current slp to be safe\n",
    "    labels.save_file(labeled_frames_from_video, new_filename)\n",
    "print (\"DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n",
      "pup1\n",
      "pup4\n",
      "\n",
      "[PredictedInstance(video=Video(filename=/scratch/cm5635/cohort2/2020_07_30_07_58_21_812233_compressed_defished_shrink_cropped.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=28801, points=[nose: (283.1, 547.9, 0.33), spine2: (223.5, 528.1, 0.44), spine3: (200.0, 532.1, 0.42), spine4: (183.5, 547.4, 0.51), spine5: (168.1, 552.7, 0.56)], score=0.80, track=Track(spawned_on=0, name='female'), tracking_score=0.00), PredictedInstance(video=Video(filename=/scratch/cm5635/cohort2/2020_07_30_07_58_21_812233_compressed_defished_shrink_cropped.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=28801, points=[spine3: (180.1, 504.1, 0.36), spine4: (208.2, 495.8, 0.46)], score=0.32, track=Track(spawned_on=0, name='pup1'), tracking_score=0.00), PredictedInstance(video=Video(filename=/scratch/cm5635/cohort2/2020_07_30_07_58_21_812233_compressed_defished_shrink_cropped.mp4, shape=(None, None, None, None), backend=MediaVideo), frame_idx=28801, points=[nose: (168.4, 464.3, 0.28), spine1: (144.5, 460.4, 0.69), spine2: (131.1, 455.9, 0.75), spine3: (120.6, 448.2, 0.64), spine4: (120.1, 439.8, 0.30), spine5: (216.5, 468.1, 0.44)], score=0.89, track=Track(spawned_on=0, name='pup4'), tracking_score=0.00)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:00<00:00, 25.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "205\n",
      "173\n",
      "359\n",
      "287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:00<00:00, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464\n",
      "512\n",
      "306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [00:00<00:00, 15.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n",
      "354\n",
      "377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n",
      "4258\n",
      "locs:  (25548, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "############ VISUALIZE DELETED TRACKS ##############\n",
    "####################################################\n",
    "\n",
    "fname = \"/media/cat/256GB/dan/testing_track_cleanup_code/cohort2_night_1000/videos/cohort2_night.1000_deleted.slp\"\n",
    "labels = sleap.load_file(fname)\n",
    "\n",
    "labels.videos  # Use in ipython to print list of videos in the labels object\n",
    "n_videos = len(labels.videos)\n",
    "\n",
    "#\n",
    "locs = []\n",
    "for video_idx in trange(n_videos):\n",
    "    #video_idx =   # Change this select the video of interest from the labels.video list\n",
    "    video = labels.videos[video_idx]\n",
    "    labeled_frames_from_video = labels.get(video)\n",
    "\n",
    "    # Loop through all labeled frames (from a specific video)\n",
    "    n_frames = 0\n",
    "    for ctr1, lf in enumerate(labeled_frames_from_video):\n",
    "\n",
    "        # Loop through all user instances in the current labeled frame\n",
    "        for ctr2, inst in enumerate(lf.user_instances):\n",
    "\n",
    "            #\n",
    "            remove_inst = False\n",
    "            points_array = inst.points_array  # Returns a (num_nodes, 2) np.recarray\n",
    "            \n",
    "            #\n",
    "            #print (points_array[:,0])\n",
    "            #print (points_array[:,1])\n",
    "            idx1 = np.where(points_array[:,0]<200)[0]\n",
    "            idx2 = np.where(points_array[:,1]<200)[0]\n",
    "            \n",
    "            inter = list(set(idx1) & set(idx2))\n",
    "            locs.append(points_array)\n",
    "            \n",
    "            n_all+=1\n",
    "            n_frames+=1\n",
    "    print (n_frames)\n",
    "    \n",
    "print (n_all)\n",
    "locs = np.vstack(locs)\n",
    "print (\"locs: \", locs.shape)\n",
    "\n",
    "#\n",
    "plt.figure()\n",
    "plt.scatter(locs[:,0],\n",
    "            locs[:,1])\n",
    "plt.xlim(0,900)\n",
    "plt.ylim(0,700)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
