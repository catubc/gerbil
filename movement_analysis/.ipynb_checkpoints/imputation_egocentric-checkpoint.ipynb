{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# \n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# \n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import trange\n",
    "import parmap\n",
    "import glob\n",
    "from sklearn.decomposition import PCA\n",
    "#import umap\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "# \n",
    "from tqdm import tqdm\n",
    "\n",
    "import sleap\n",
    "\n",
    "\n",
    "import sklearn.experimental\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# \n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "# \n",
    "\n",
    "import numba\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "from Imputation import Impute, CentreBody\n",
    "\n",
    "from Imputation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ... median filtering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 296827.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ... rejecting outliers....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 22968.81it/s]\n"
     ]
    }
   ],
   "source": [
    "##################################################   \n",
    "############# GENERATE EGOCENTRIC DATA ###########   \n",
    "##################################################\n",
    "cb = CentreBody()\n",
    "cb.parallel = True\n",
    "cb.root_dir = '/media/cat/1TB/dan/cohort1/slp/'\n",
    "#cb.root_dir = '/media/cat/256GB/dan/slp'\n",
    "\n",
    "#\n",
    "#cb.process_slp()\n",
    "\n",
    "#\n",
    "cb.get_fnames()\n",
    "\n",
    "# median filter data\n",
    "cb.filter_data()\n",
    "\n",
    "# \n",
    "cb.reject_outliers()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [03:29<00:00, 34.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DONE Generating 2-point ground truth datasets for imputation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################   \n",
    "####### GENERATE PAIR-WISE CENTRE DATASETS #######   \n",
    "################################################## \n",
    "\n",
    "# \n",
    "cb.parallel = True\n",
    "\n",
    "# for each recording centre/align every pair of data\n",
    "#     TODO: make a single file otherwise generating 15 files per recording\n",
    "#      TODO : OR MAKE A SINGLE STACK OF DATA\n",
    "cb.centre_and_align_all_pairs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (218641, 6, 2)\n",
      " male:                               (94647, 6, 2)\n",
      " pup1:                               (132861, 6, 2)\n",
      " pup2:                               (176982, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "#################################################        \n",
    "#### TRAIN PAIRWISE MODELS MISSING FEATURES #####\n",
    "#################################################                       \n",
    "\n",
    "# pass cb object into Impute object\n",
    "I = Impute(cb)\n",
    "I.parallel = False\n",
    "I.n_cores = 4\n",
    "\n",
    "# Select best model; \n",
    "#  [\"BayesianRidge\",          0\n",
    "#   \"DecisionTreeRegressor\",  1 \n",
    "#   \"ExtraTreesRegressor\",    2  <--- best performing when tested on female data; but large data, 2.5GB /model\n",
    "#   \"KNeighborsRegressor\"]    3  <--- 2nd best\n",
    "#  VAE also evaluated; but not coded\n",
    "models = [0]\n",
    "for animal_id in I.animal_ids:\n",
    "    I.animal_id = animal_id\n",
    "    for model in models:\n",
    "        I.model_type = model\n",
    "\n",
    "        # this will generate 4 animals x 15 pairwise models = 60 models\n",
    "        I.generate_imputation_models_all_pairs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################################################    \n",
    "# #### LOAD GT DATA AND PREDICT USING SPECIFIC MODEL ####\n",
    "# #######################################################\n",
    "# # select a particular animal\n",
    "# I = Impute(cb)\n",
    "# I.parallel = True\n",
    "# I.n_cores = 4\n",
    "# I.model_type = 0 \n",
    "\n",
    "# #\n",
    "# I.animals_selected = [0]\n",
    "# I.animal_id = 0\n",
    "# I.generate_random_drops = True     # flag used to indicate \n",
    "\n",
    "# # this generates random drops file + evaluates how the trained model does\n",
    "# #I.predict_imputation_ground_truth_all_pairs()\n",
    "\n",
    "# # plot violion plots of errors\n",
    "# #plot_errors(I)\n",
    "\n",
    "# print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #########################################################    \n",
    "# #### LOAD REAL DATA AND PREDICT USING SPECIFIC MODEL ####\n",
    "# #########################################################\n",
    "# # select a particular animal\n",
    "# I = Impute(cb)\n",
    "# I.parallel = False\n",
    "# I.n_cores = 8\n",
    "# I.model_type = 0\n",
    "\n",
    "# # \n",
    "# I.animals_selected = [0]\n",
    "# I.generate_random_drops = False     # flag used to indicate \n",
    "\n",
    "# # \n",
    "# # I.predict_novel_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 14, 2)\n",
      " male:                               (2069710, 14, 2)\n",
      " pup1:                               (2069710, 14, 2)\n",
      " pup2:                               (2069710, 14, 2)\n",
      "(2069710, 14, 2)\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "#### MAKE ALL_DATA DATASETS ####\n",
    "################################\n",
    "\n",
    "# TODO: EMBED THIS INTO ANOTHER FUNCTION EARLY IN PROCESSING\n",
    "#      TODO: probably better to process each hour of data as stand alone - don't want concatenation artifacts etc.\n",
    "\n",
    "def make_this_into_a_function()\n",
    "    f1 = None\n",
    "    f2 = None\n",
    "    feats = load_processed_data_stand_alone(f1,f2,I.March16_file_order, I.root_dir, I.animal_ids, data_type=1, remove_nans=False)\n",
    "    print (np.vstack(feats[0]).shape)\n",
    "    for k in range(I.animal_ids.shape[0]):\n",
    "        fname_out = I.root_dir+'/animalID_'+str(k)+'_alldata.npy'\n",
    "        if os.path.exists(fname_out)==False:\n",
    "            np.save(fname_out, np.vstack(feats[k]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710, 14, 2)\n",
      "INFO:numba.core.transforms:finding looplift candidates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/code/gerbil/movement_analysis/Imputation.py:609: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function parse_data_for_anchors failed at nopython mode lowering due to: \u001b[1m\u001b[1mnon-numeric type in Num\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 615:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "        # count # of non nan entries\n",
      "\u001b[1m        idx = np.where(np.isnan(feats[k,:,0])==False)[0]\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: lowering \"$24.17 = arrayexpr(expr=(<built-in function eq>, [(<ufunc 'isnan'>, [Var($24.14, Imputation.py:615)]), const(bool, False)]), ty=array(bool, 1d, C))\" at /home/cat/code/gerbil/movement_analysis/Imputation.py (615)\u001b[0m\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/cat/code/gerbil/movement_analysis/Imputation.py:609: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"parse_data_for_anchors\" failed type inference due to: \u001b[1m\u001b[1mCannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 613:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "    frame_ids = []\n",
      "\u001b[1m    for k in range(feats.shape[0]):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/cat/anaconda3/envs/gerbil/lib/python3.6/site-packages/numba/core/object_mode_passes.py:152: NumbaWarning: \u001b[1mFunction \"parse_data_for_anchors\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 612:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "\n",
      "\u001b[1m    frame_ids = []\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/home/cat/anaconda3/envs/gerbil/lib/python3.6/site-packages/numba/core/object_mode_passes.py:162: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 612:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "\n",
      "\u001b[1m    frame_ids = []\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/home/cat/code/gerbil/movement_analysis/Imputation.py:609: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"parse_data_for_anchors\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at /home/cat/code/gerbil/movement_analysis/Imputation.py (613)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 613:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "    frame_ids = []\n",
      "\u001b[1m    for k in range(feats.shape[0]):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/cat/anaconda3/envs/gerbil/lib/python3.6/site-packages/numba/core/object_mode_passes.py:152: NumbaWarning: \u001b[1mFunction \"parse_data_for_anchors\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 613:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "    frame_ids = []\n",
      "\u001b[1m    for k in range(feats.shape[0]):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/home/cat/anaconda3/envs/gerbil/lib/python3.6/site-packages/numba/core/object_mode_passes.py:162: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"Imputation.py\", line 613:\u001b[0m\n",
      "\u001b[1mdef parse_data_for_anchors(f1, f2, feats):\n",
      "    <source elided>\n",
      "    frame_ids = []\n",
      "\u001b[1m    for k in range(feats.shape[0]):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(628094,)\n",
      "(2069710, 14, 2)\n",
      "(518377,)\n",
      "(2069710, 14, 2)\n",
      "(409718,)\n",
      "(2069710, 14, 2)\n",
      "(246257,)\n",
      "(2069710, 14, 2)\n",
      "(230403,)\n",
      "(2069710, 14, 2)\n",
      "(565952,)\n",
      "(2069710, 14, 2)\n",
      "(453972,)\n",
      "(2069710, 14, 2)\n",
      "(274308,)\n",
      "(2069710, 14, 2)\n",
      "(248357,)\n",
      "(2069710, 14, 2)\n",
      "(441885,)\n",
      "(2069710, 14, 2)\n",
      "(260741,)\n",
      "(2069710, 14, 2)\n",
      "(237260,)\n",
      "(2069710, 14, 2)\n",
      "(269522,)\n",
      "(2069710, 14, 2)\n",
      "(244677,)\n",
      "(2069710, 14, 2)\n",
      "(264280,)\n",
      "(2069710, 14, 2)\n",
      "(363199,)\n",
      "(2069710, 14, 2)\n",
      "(203186,)\n",
      "(2069710, 14, 2)\n",
      "(151170,)\n",
      "(2069710, 14, 2)\n",
      "(118263,)\n",
      "(2069710, 14, 2)\n",
      "(120073,)\n",
      "(2069710, 14, 2)\n",
      "(252295,)\n",
      "(2069710, 14, 2)\n",
      "(174017,)\n",
      "(2069710, 14, 2)\n",
      "(142856,)\n",
      "(2069710, 14, 2)\n",
      "(153324,)\n",
      "(2069710, 14, 2)\n",
      "(160547,)\n",
      "(2069710, 14, 2)\n",
      "(116635,)\n",
      "(2069710, 14, 2)\n",
      "(117849,)\n",
      "(2069710, 14, 2)\n",
      "(128634,)\n",
      "(2069710, 14, 2)\n",
      "(123964,)\n",
      "(2069710, 14, 2)\n",
      "(178110,)\n",
      "(2069710, 14, 2)\n",
      "(461638,)\n",
      "(2069710, 14, 2)\n",
      "(302560,)\n",
      "(2069710, 14, 2)\n",
      "(216636,)\n",
      "(2069710, 14, 2)\n",
      "(146693,)\n",
      "(2069710, 14, 2)\n",
      "(176257,)\n",
      "(2069710, 14, 2)\n",
      "(313498,)\n",
      "(2069710, 14, 2)\n",
      "(223687,)\n",
      "(2069710, 14, 2)\n",
      "(150173,)\n",
      "(2069710, 14, 2)\n",
      "(173131,)\n",
      "(2069710, 14, 2)\n",
      "(212970,)\n",
      "(2069710, 14, 2)\n",
      "(145606,)\n",
      "(2069710, 14, 2)\n",
      "(162704,)\n",
      "(2069710, 14, 2)\n",
      "(155983,)\n",
      "(2069710, 14, 2)\n",
      "(150906,)\n",
      "(2069710, 14, 2)\n",
      "(154460,)\n",
      "(2069710, 14, 2)\n",
      "(427591,)\n",
      "(2069710, 14, 2)\n",
      "(322197,)\n",
      "(2069710, 14, 2)\n",
      "(273405,)\n",
      "(2069710, 14, 2)\n",
      "(206672,)\n",
      "(2069710, 14, 2)\n",
      "(220905,)\n",
      "(2069710, 14, 2)\n",
      "(363293,)\n",
      "(2069710, 14, 2)\n",
      "(306520,)\n",
      "(2069710, 14, 2)\n",
      "(241306,)\n",
      "(2069710, 14, 2)\n",
      "(245837,)\n",
      "(2069710, 14, 2)\n",
      "(312305,)\n",
      "(2069710, 14, 2)\n",
      "(230111,)\n",
      "(2069710, 14, 2)\n",
      "(217139,)\n",
      "(2069710, 14, 2)\n",
      "(274359,)\n",
      "(2069710, 14, 2)\n",
      "(245646,)\n",
      "(2069710, 14, 2)\n",
      "(279656,)\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "#### FIND FRAMES WHICH HAVE F1/F2 ANCHORS #####\n",
    "###############################################\n",
    "\n",
    "# parse the data and resave chunks containing centre/anchor point pairs\n",
    "for animal_id in I.animal_ids:\n",
    "    I.animal_id = animal_id\n",
    "    for f1 in range(I.feature_ids.shape[0]):\n",
    "        for f2 in range(f1+1, I.feature_ids.shape[0],1):\n",
    "            break_features_pairs(f1,f2, I)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230403/230403 [00:06<00:00, 34747.42it/s]\n",
      "100%|██████████| 246257/246257 [00:06<00:00, 35555.36it/s]\n",
      "100%|██████████| 274308/274308 [00:09<00:00, 28151.59it/s]\n",
      "100%|██████████| 409718/409718 [00:14<00:00, 27510.26it/s]\n",
      "100%|██████████| 453972/453972 [00:15<00:00, 29237.15it/s]\n",
      "100%|██████████| 248357/248357 [00:08<00:00, 28130.07it/s]\n",
      "100%|██████████| 518377/518377 [00:19<00:00, 27118.90it/s]\n",
      "100%|██████████| 565952/565952 [00:19<00:00, 28429.88it/s]\n",
      "100%|██████████| 260741/260741 [00:09<00:00, 27350.35it/s]\n",
      "100%|██████████| 441885/441885 [00:15<00:00, 28697.51it/s]\n",
      "100%|██████████| 237260/237260 [00:07<00:00, 29740.36it/s]\n",
      "100%|██████████| 244677/244677 [00:07<00:00, 31652.43it/s]\n",
      "100%|██████████| 269522/269522 [00:08<00:00, 30631.89it/s]\n",
      "100%|██████████| 264280/264280 [00:06<00:00, 40528.51it/s]\n",
      "100%|██████████| 628094/628094 [00:36<00:00, 17128.65it/s]\n",
      "100%|██████████| 120073/120073 [00:02<00:00, 42265.02it/s]\n",
      "100%|██████████| 118263/118263 [00:02<00:00, 41218.24it/s]\n",
      "100%|██████████| 151170/151170 [00:03<00:00, 40562.91it/s]\n",
      "100%|██████████| 142856/142856 [00:04<00:00, 30855.03it/s]\n",
      "100%|██████████| 203186/203186 [00:05<00:00, 39043.18it/s]\n",
      "100%|██████████| 174017/174017 [00:05<00:00, 31013.02it/s]\n",
      "100%|██████████| 252295/252295 [00:07<00:00, 31608.42it/s]\n",
      "100%|██████████| 116635/116635 [00:03<00:00, 31735.43it/s]\n",
      "100%|██████████| 153324/153324 [00:04<00:00, 30948.14it/s]\n",
      "100%|██████████| 160547/160547 [00:04<00:00, 32138.95it/s]\n",
      "100%|██████████| 117849/117849 [00:03<00:00, 32294.23it/s]\n",
      "100%|██████████| 128634/128634 [00:03<00:00, 34966.85it/s]\n",
      "100%|██████████| 123964/123964 [00:03<00:00, 35773.81it/s]\n",
      "100%|██████████| 178110/178110 [00:03<00:00, 57217.80it/s]\n",
      "100%|██████████| 363199/363199 [00:18<00:00, 19727.20it/s]\n",
      "100%|██████████| 146693/146693 [00:03<00:00, 37232.02it/s]\n",
      "100%|██████████| 150173/150173 [00:05<00:00, 29949.85it/s]\n",
      "100%|██████████| 176257/176257 [00:05<00:00, 29611.19it/s]\n",
      "100%|██████████| 216636/216636 [00:06<00:00, 35528.93it/s]\n",
      "100%|██████████| 223687/223687 [00:07<00:00, 28138.90it/s]\n",
      "100%|██████████| 313498/313498 [00:11<00:00, 27967.61it/s]\n",
      "100%|██████████| 302560/302560 [00:12<00:00, 25174.64it/s]\n",
      "100%|██████████| 173131/173131 [00:07<00:00, 23808.38it/s]\n",
      "100%|██████████| 145606/145606 [00:06<00:00, 23347.11it/s]\n",
      "100%|██████████| 162704/162704 [00:06<00:00, 23987.38it/s]\n",
      "100%|██████████| 155983/155983 [00:05<00:00, 29945.89it/s]\n",
      "100%|██████████| 212970/212970 [00:08<00:00, 24150.44it/s]\n",
      "100%|██████████| 150906/150906 [00:04<00:00, 37093.93it/s]\n",
      "100%|██████████| 154460/154460 [00:04<00:00, 38403.71it/s]\n",
      "100%|██████████| 461638/461638 [00:25<00:00, 18136.34it/s]\n",
      "100%|██████████| 206672/206672 [00:05<00:00, 40963.92it/s]\n",
      "100%|██████████| 220905/220905 [00:05<00:00, 39331.98it/s]\n",
      "100%|██████████| 273405/273405 [00:07<00:00, 38994.25it/s]\n",
      "100%|██████████| 241306/241306 [00:07<00:00, 30450.25it/s]\n",
      "100%|██████████| 322197/322197 [00:08<00:00, 37273.22it/s]\n",
      "100%|██████████| 306520/306520 [00:10<00:00, 29962.40it/s]\n",
      "100%|██████████| 363293/363293 [00:12<00:00, 30231.58it/s]\n",
      "100%|██████████| 245837/245837 [00:08<00:00, 29649.99it/s]\n",
      "100%|██████████| 230111/230111 [00:07<00:00, 29979.43it/s]\n",
      "100%|██████████| 217139/217139 [00:07<00:00, 30607.73it/s]\n",
      "100%|██████████| 312305/312305 [00:10<00:00, 31011.63it/s]\n",
      "100%|██████████| 274359/274359 [00:08<00:00, 33871.75it/s]\n",
      "100%|██████████| 245646/245646 [00:06<00:00, 35189.50it/s]\n",
      "100%|██████████| 279656/279656 [00:06<00:00, 42862.95it/s]\n",
      "100%|██████████| 427591/427591 [00:24<00:00, 17604.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "#### CENTRE AND ROTATE F1/F2 FRAMES #####\n",
    "#########################################\n",
    "''' This step takes all f1/f2 eligible frames\n",
    "'''\n",
    "# \n",
    "for animal_id in I.animal_ids:\n",
    "    I.animal_id = animal_id\n",
    "    I.parallel = True\n",
    "    centre_rotate_features_pairs(I)\n",
    "            \n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "0 1  frame_ids with min 3 present features in animal:  0  is:  (628094,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 628094/628094 [00:06<00:00, 99136.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 1  frame_ids with min 3 present features in animal:  1  is:  (363199,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363199/363199 [00:03<00:00, 105458.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 1  frame_ids with min 3 present features in animal:  2  is:  (461638,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461638/461638 [00:04<00:00, 100733.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 1  frame_ids with min 3 present features in animal:  3  is:  (427591,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 427591/427591 [00:04<00:00, 93543.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "0 2  frame_ids with min 3 present features in animal:  0  is:  (518377,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 518377/518377 [00:04<00:00, 104198.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/203186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2  frame_ids with min 3 present features in animal:  1  is:  (203186,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203186/203186 [00:01<00:00, 101935.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/302560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2  frame_ids with min 3 present features in animal:  2  is:  (302560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 302560/302560 [00:02<00:00, 101685.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/322197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2  frame_ids with min 3 present features in animal:  3  is:  (322197,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322197/322197 [00:03<00:00, 99489.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "0 3  frame_ids with min 3 present features in animal:  0  is:  (409718,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 409718/409718 [00:03<00:00, 106488.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 3  frame_ids with min 3 present features in animal:  1  is: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6017/151170 [00:00<00:02, 60159.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (151170,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151170/151170 [00:01<00:00, 100695.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 3  frame_ids with min 3 present features in animal:  2  is:  (216636,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216636/216636 [00:02<00:00, 96256.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/273405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3  frame_ids with min 3 present features in animal:  3  is:  (273405,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273405/273405 [00:02<00:00, 101872.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5112/246257 [00:00<00:04, 51115.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4  frame_ids with min 3 present features in animal:  0  is:  (246257,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246257/246257 [00:02<00:00, 99558.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 4  frame_ids with min 3 present features in animal:  1  is:  (118263,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118263/118263 [00:01<00:00, 95985.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 4  frame_ids with min 3 present features in animal:  2  is:  (146693,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146693/146693 [00:01<00:00, 96037.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5855/206672 [00:00<00:03, 58547.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4  frame_ids with min 3 present features in animal:  3  is:  (206672,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206672/206672 [00:02<00:00, 102203.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/230403 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5  frame_ids with min 3 present features in animal:  0  is:  (230403,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230403/230403 [00:02<00:00, 102073.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 5  frame_ids with min 3 present features in animal:  1  is:  (120073,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120073/120073 [00:01<00:00, 101516.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/176257 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5  frame_ids with min 3 present features in animal:  2  is:  (176257,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176257/176257 [00:01<00:00, 100329.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6641/220905 [00:00<00:03, 66402.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5  frame_ids with min 3 present features in animal:  3  is:  (220905,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220905/220905 [00:02<00:00, 96961.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "1 2  frame_ids with min 3 present features in animal:  0  is:  (565952,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 565952/565952 [00:05<00:00, 96823.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 2  frame_ids with min 3 present features in animal:  1  is:  (252295,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 252295/252295 [00:02<00:00, 104086.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 2  frame_ids with min 3 present features in animal:  2  is:  (313498,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313498/313498 [00:03<00:00, 96048.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 2  frame_ids with min 3 present features in animal:  3  is:  (363293,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363293/363293 [00:03<00:00, 97102.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "1 3  frame_ids with min 3 present features in animal:  0  is:  (453972,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 453972/453972 [00:04<00:00, 101667.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 3  frame_ids with min 3 present features in animal:  1  is:  (174017,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174017/174017 [00:02<00:00, 85407.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/223687 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3  frame_ids with min 3 present features in animal:  2  is:  (223687,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223687/223687 [00:02<00:00, 100238.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/306520 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3  frame_ids with min 3 present features in animal:  3  is:  (306520,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306520/306520 [00:03<00:00, 97400.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/274308 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4  frame_ids with min 3 present features in animal:  0  is:  (274308,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274308/274308 [00:02<00:00, 101267.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 4  frame_ids with min 3 present features in animal:  1  is:  (142856,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142856/142856 [00:01<00:00, 102151.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 4  frame_ids with min 3 present features in animal:  2  is:  (150173,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150173/150173 [00:01<00:00, 96728.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/241306 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4  frame_ids with min 3 present features in animal:  3  is:  (241306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241306/241306 [00:02<00:00, 100272.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5234/248357 [00:00<00:04, 52336.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5  frame_ids with min 3 present features in animal:  0  is:  (248357,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248357/248357 [00:02<00:00, 92665.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 5  frame_ids with min 3 present features in animal:  1  is:  (153324,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153324/153324 [00:01<00:00, 100143.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 5  frame_ids with min 3 present features in animal:  2  is:  (173131,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173131/173131 [00:01<00:00, 98825.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 5  frame_ids with min 3 present features in animal:  3  is:  (245837,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245837/245837 [00:02<00:00, 102357.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n",
      "2 3  frame_ids with min 3 present features in animal:  0  is:  (441885,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441885/441885 [00:04<00:00, 100983.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4931/160547 [00:00<00:03, 49302.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3  frame_ids with min 3 present features in animal:  1  is:  (160547,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160547/160547 [00:01<00:00, 96200.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/212970 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3  frame_ids with min 3 present features in animal:  2  is:  (212970,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212970/212970 [00:02<00:00, 104239.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 3  frame_ids with min 3 present features in animal:  3  is:  (312305,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312305/312305 [00:03<00:00, 101386.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/260741 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4  frame_ids with min 3 present features in animal:  0  is:  (260741,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260741/260741 [00:02<00:00, 97602.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 4  frame_ids with min 3 present features in animal:  1  is:  (116635,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116635/116635 [00:01<00:00, 97682.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 4  frame_ids with min 3 present features in animal:  2  is:  (145606,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145606/145606 [00:01<00:00, 100237.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4970/230111 [00:00<00:04, 49646.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  frame_ids with min 3 present features in animal:  3  is:  (230111,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230111/230111 [00:02<00:00, 101969.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/237260 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 5  frame_ids with min 3 present features in animal:  0  is:  (237260,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237260/237260 [00:02<00:00, 103726.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 5  frame_ids with min 3 present features in animal:  1  is:  (117849,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117849/117849 [00:01<00:00, 93283.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 5  frame_ids with min 3 present features in animal:  2  is:  (162704,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162704/162704 [00:01<00:00, 95618.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 5  frame_ids with min 3 present features in animal:  3  is: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5138/217139 [00:00<00:04, 51376.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (217139,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217139/217139 [00:02<00:00, 96440.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5128/269522 [00:00<00:05, 51273.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4  frame_ids with min 3 present features in animal:  0  is:  (269522,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269522/269522 [00:02<00:00, 100012.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3 4  frame_ids with min 3 present features in animal:  1  is:  (128634,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128634/128634 [00:01<00:00, 96190.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3 4  frame_ids with min 3 present features in animal:  2  is:  (155983,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155983/155983 [00:01<00:00, 91621.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/274359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4  frame_ids with min 3 present features in animal:  3  is:  (274359,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274359/274359 [00:02<00:00, 101089.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244677 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5  frame_ids with min 3 present features in animal:  0  is:  (244677,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244677/244677 [00:02<00:00, 96313.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6480/123964 [00:00<00:01, 64793.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5  frame_ids with min 3 present features in animal:  1  is:  (123964,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123964/123964 [00:01<00:00, 97792.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 7741/150906 [00:00<00:01, 77396.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5  frame_ids with min 3 present features in animal:  2  is:  (150906,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150906/150906 [00:01<00:00, 103396.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/245646 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5  frame_ids with min 3 present features in animal:  3  is:  (245646,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245646/245646 [00:02<00:00, 100476.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 6, 2)\n",
      " male:                               (2069710, 6, 2)\n",
      " pup1:                               (2069710, 6, 2)\n",
      " pup2:                               (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/264280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5  frame_ids with min 3 present features in animal:  0  is:  (264280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264280/264280 [00:02<00:00, 101885.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6746/178110 [00:00<00:02, 67454.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5  frame_ids with min 3 present features in animal:  1  is:  (178110,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178110/178110 [00:01<00:00, 102012.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4 5  frame_ids with min 3 present features in animal:  2  is:  (154460,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154460/154460 [00:01<00:00, 103522.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/279656 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5  frame_ids with min 3 present features in animal:  3  is:  (279656,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279656/279656 [00:02<00:00, 100786.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#### IMPUTE MISSING DATA ON THE ROTATED FRAMES ONLY #####\n",
    "#########################################################\n",
    "\n",
    "#  This function loads all data (including nans), + an f1/f2 model, and imputes \n",
    "#  missing data for frames that have at least 3 features including the f1/f2 points\n",
    "# \n",
    "I = Impute(cb)\n",
    "I.parallel = True\n",
    "I.n_cores = 4\n",
    "I.model_type = 0 \n",
    "\n",
    "# for animal_id in I.animal_ids:\n",
    "#     I.animal_id = animal_id\n",
    "I.animal_ids = np.arange(4)\n",
    "I.parallel = False\n",
    "impute_real_data_stand_alone(I)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 22.56it/s]\n",
      "  0%|          | 4700/2069710 [00:00<00:43, 46973.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_a:  (2069710, 6, 2)\n",
      "feats_imputed:  (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [04:03<00:00, 8510.15it/s] \n",
      "100%|██████████| 6/6 [00:00<00:00, 37.18it/s]\n",
      "  0%|          | 5148/2069710 [00:00<00:40, 51477.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_a:  (2069710, 6, 2)\n",
      "feats_imputed:  (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [02:34<00:00, 13371.50it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 34.64it/s]\n",
      "  0%|          | 3497/2069710 [00:00<00:59, 34886.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_a:  (2069710, 6, 2)\n",
      "feats_imputed:  (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [02:45<00:00, 12497.11it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 27.50it/s]\n",
      "  0%|          | 898/2069710 [00:00<03:50, 8978.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_a:  (2069710, 6, 2)\n",
      "feats_imputed:  (2069710, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [03:04<00:00, 11218.43it/s]\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "#### REPLACE MISSING DATA WITH MODELS WITH NEARBY FEATURES #####\n",
    "################################################################\n",
    "\n",
    "I = Impute(cb)\n",
    "I.parallel = True\n",
    "I.n_cores = 4\n",
    "I.model_type = 0 \n",
    "\n",
    "I.animal_ids = np.arange(4)\n",
    "I.parallel = False\n",
    "\n",
    "# figure out which model is most optimal for each missing feature\n",
    "# e.g. missing feature 0 ideal model is 1/2 \n",
    "best_models = [              # missing feature index\n",
    "[[1,2],[1,3]],               # 0\n",
    "[[0,2],[0,3],[2,3]],         # 1\n",
    "[[1,3],[1,4],[0,3],[0,1]],         # 2\n",
    "[[2,4],[2,5],[1,4],[1,2]],   # 3\n",
    "[[3,5],[2,5],[2,3]],         # 4\n",
    "[[3,4],[2,4]]                # 5\n",
    "]\n",
    "print (len(best_models))\n",
    "\n",
    "#########################################################\n",
    "animal_ids = np.arange(4)\n",
    "for animal_id in animal_ids:\n",
    "\n",
    "    #####################################################\n",
    "    # load all imputations for that animal_id\n",
    "    feats_imputed_array = []\n",
    "    feats_frames_array = []\n",
    "    for f1 in range(6):\n",
    "        feats_imputed_array.append([])\n",
    "        feats_frames_array.append([])\n",
    "        for f2 in range(6):\n",
    "            feats_imputed_array[f1].append([])\n",
    "            feats_frames_array[f1].append([])\n",
    "\n",
    "    # fill the lists with imputed data\n",
    "    for f1 in trange(6):\n",
    "        for f2 in range(f1+1, 6, 1):\n",
    "\n",
    "            fname_imputed = os.path.join(I.root_dir, 'centre_rotated_animalID_'+str(animal_id)+\n",
    "                                 \"_\"+str(f1)+\"_\"+str(f2)+\"_imputed_original_locations.npz\")\n",
    "\n",
    "            data = np.load(fname_imputed)\n",
    "            temp1 = data['imputed_translated']\n",
    "            temp2 = data['imputed_frames']\n",
    "\n",
    "            feats_imputed_array[f1][f2]= temp1\n",
    "            feats_frames_array[f1][f2]= temp2\n",
    "\n",
    "\n",
    "    #####################################################\n",
    "    # load raw unrotated data\n",
    "    feats = np.load(os.path.join(I.root_dir,'animalID_'+str(animal_id)+\"_alldata.npy\"))\n",
    "    feats_a = feats[:,I.feature_ids]\n",
    "    print (\"feats_a: \", feats_a.shape)\n",
    "\n",
    "    # initialize imputed array \n",
    "    feats_imputed = np.zeros(feats_a.shape,'float32')+np.nan\n",
    "    print (\"feats_imputed: \", feats_imputed.shape)\n",
    "\n",
    "    # loop over all frames\n",
    "    fname_out = os.path.join(I.root_dir, 'animalID_'+str(animal_id)+\"_alldata_imputed.npy\")\n",
    "\n",
    "    #if os.path.exists(fname_out)==False:\n",
    "    verbose=False\n",
    "    if True:\n",
    "\n",
    "        all_feats = np.arange(6)\n",
    "        for f in trange(feats_a.shape[0]):\n",
    "            feats_orig = feats_a[f]\n",
    "            feats_imputed[f] = feats_orig\n",
    "\n",
    "            # grab indexes for nans \n",
    "            idxnan = np.where(np.isnan(feats_orig[:,0]))[0]\n",
    "            idx = np.delete(all_feats, idxnan)    \n",
    "            #print (\"frame: \", f, \" idx: \", idxnan)\n",
    "\n",
    "            # if less than 2 anchors skip frame\n",
    "            if idx.shape[0]<=1:\n",
    "                continue\n",
    "            \n",
    "            # loop over all missing pieces; replace all nans with data from best model regardless of how many nans are present\n",
    "            for id_ in idxnan:\n",
    "                if verbose:\n",
    "                    print (\"frame: \", f, \"missing feature id: \", id_, \"  available features: \", idx)\n",
    "\n",
    "                # search for the best model in order of best fit (as listed above)\n",
    "                models1 = best_models[id_]\n",
    "                for mod in models1:\n",
    "\n",
    "                    # if model is found (i.e. the anchor points are availble): load files and replace data\n",
    "                    if np.intersect1d(mod,idx).shape[0]==2:\n",
    "                        #print (\"MODEL FOUND: \", mod)\n",
    "\n",
    "                        #################################\n",
    "                        frames = feats_frames_array[mod[0]][mod[1]]\n",
    "\n",
    "                        # some of the models were not used to impute \n",
    "                        try:\n",
    "                            idx_local = np.where(frames==f)[0][0]\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        temp = feats_imputed_array[mod[0]][mod[1]]\n",
    "                        temp = temp[idx_local][id_] \n",
    "\n",
    "                        feats_imputed[f,id_] = temp\n",
    "                        \n",
    "                        if verbose:\n",
    "                            print (\"Grabbing model \", mod, \" imputation results at location: \", id_, \" temp: \", temp)\n",
    "\n",
    "                        # do not look for other models to impute at this location;\n",
    "                        break\n",
    "            if verbose:\n",
    "                print ('')\n",
    "        np.save(fname_out, feats_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [00:19<00:00, 105671.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069710/2069710 [00:19<00:00, 106272.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1748543/2069710 [00:16<00:03, 95667.83it/s] "
     ]
    }
   ],
   "source": [
    "#\n",
    "animal_ids = np.arange(4)\n",
    "for animal_id in animal_ids:\n",
    "    plt.subplot(2,2,animal_id+1)\n",
    "    feature_ids = np.array([0,5,6,7,8,9])\n",
    "    d = np.load('/media/cat/1TB/dan/cohort1/slp/animalID_'+str(animal_id)+'_alldata.npy')[:,feature_ids]\n",
    "    d_imp = np.load('/media/cat/1TB/dan/cohort1/slp/animalID_'+str(animal_id)+'_alldata_imputed.npy')\n",
    "\n",
    "    n_feats = []\n",
    "    n_feats_imp = []\n",
    "    for k in trange(d.shape[0]):\n",
    "        idx = np.array(np.where(np.isnan(d[k,:,0])==False)[0])\n",
    "        idx2 = np.array(np.where(np.isnan(d_imp[k,:,0])==False)[0])\n",
    "\n",
    "        #print (k, idx, idx.shape)\n",
    "        n_feats.append(idx.shape[0])\n",
    "        n_feats_imp.append(idx2.shape[0])\n",
    "\n",
    "    n_feats = np.array(n_feats)\n",
    "    print (n_feats.shape)\n",
    "    n_feats_imp = np.array(n_feats_imp)\n",
    "\n",
    "    width = 1\n",
    "    bins = np.arange(-0.5,7,width)\n",
    "\n",
    "    y = np.histogram(n_feats,bins=bins)\n",
    "    y2 = np.histogram(n_feats_imp, bins=bins)\n",
    "\n",
    "    plt.plot(y[1][1:]-0.5,y[0],c='black', label = 'Sleap')\n",
    "    plt.plot(y2[1][1:]-0.5,y2[0],c='blue', label = 'Imputation')\n",
    "\n",
    "    cumsum = np.cumsum(y[0][::-1])\n",
    "    plt.plot(y[1][1:][::-1]-0.5,cumsum, c= 'red', label = \"Sleap - cumulative sum\",\n",
    "            linewidth=5)\n",
    "    cumsum = np.cumsum(y2[0][::-1])\n",
    "    plt.plot(y[1][1:][::-1]-0.5,cumsum, '--', c= 'red', label = \"Imputation - cumulative sum\",\n",
    "            linewidth=5)\n",
    "    \n",
    "    #plt.semilogy()\n",
    "    plt.xlim(0.5,6.5)\n",
    "    plt.ylim(0,750000)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.title(\"animal id: \"+ str(animal_id))\n",
    "    plt.ylabel(\"# frames\")\n",
    "    plt.xlabel(\"# of features in frame\")\n",
    "    plt.plot([3,3],[0,750000],'--',c='black',linewidth=3,alpha=.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1243944   86107  160024  146467  182678   31808  218682]\n",
      "[ 218682  250490  433168  579635  739659  825766 2069710]\n"
     ]
    }
   ],
   "source": [
    "print(y[0])\n",
    "print (np.cumsum(y[0][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710,)\n"
     ]
    }
   ],
   "source": [
    "n_feats = np.array(n_feats)\n",
    "print (n_feats.shape)\n",
    "n_feats_imp = np.array(n_feats_imp)\n",
    "\n",
    "width = 1\n",
    "bins = np.arange(0.5,7,width)\n",
    "\n",
    "y = np.histogram(n_feats,bins=bins)\n",
    "y2 = np.histogram(n_feats_imp, bins=bins)\n",
    "\n",
    "plt.plot(y[1][1:]+0.5,y[0],c='black', label = 'Sleap')\n",
    "plt.plot(y2[1][1:]+0.5,y2[0],c='blue', label = 'Sleap + imputation')\n",
    "    \n",
    "#plt.semilogy()\n",
    "plt.xlim(1,7)\n",
    "plt.ylim(bottom=0)\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"animal id: \"+ str(animal_id))\n",
    "plt.ylabel(\"# frames\")\n",
    "# \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 815.5662    248.4631  ]\n",
      "  [ 828.0727    212.18002 ]\n",
      "  [ 856.01      204.01614 ]\n",
      "  [ 865.5865    185.22838 ]\n",
      "  [ 864.8135    163.06822 ]\n",
      "  [ 858.07983   144.82709 ]]\n",
      "\n",
      " [[ 815.54205   248.4631  ]\n",
      "  [ 828.0727    212.19121 ]\n",
      "  [ 855.9853    204.01614 ]\n",
      "  [ 865.57605   185.23795 ]\n",
      "  [ 864.8342    163.0905  ]\n",
      "  [ 858.12427   144.85498 ]]\n",
      "\n",
      " [[ 815.54205   248.4631  ]\n",
      "  [ 828.0727    212.24358 ]\n",
      "  [ 855.9771    204.01614 ]\n",
      "  [ 865.5792    185.2284  ]\n",
      "  [ 864.85626   163.09923 ]\n",
      "  [ 858.176     144.87238 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1003.80945   123.85146 ]\n",
      "  [ 976.056     120.63238 ]\n",
      "  [ 943.31604   132.44987 ]\n",
      "  [ 920.0462    124.01467 ]\n",
      "  [ 904.6494    111.888695]\n",
      "  [ 893.4489    107.69545 ]]\n",
      "\n",
      " [[ 940.41614    99.940254]\n",
      "  [ 915.248     123.777016]\n",
      "  [ 907.865     144.44054 ]\n",
      "  [ 886.83026   155.86105 ]\n",
      "  [ 867.07166   164.44434 ]\n",
      "  [ 858.3316    174.203   ]]\n",
      "\n",
      " [[ 939.6487     99.35089 ]\n",
      "  [ 915.185     123.777016]\n",
      "  [ 907.865     144.2303  ]\n",
      "  [ 887.1728    156.26631 ]\n",
      "  [ 867.86      165.56894 ]\n",
      "  [ 859.4652    175.70676 ]]]\n"
     ]
    }
   ],
   "source": [
    "feature_ids = np.array([0,5,6,7,8,9])\n",
    "d = np.load('/media/cat/1TB/dan/cohort1/slp/animalID_0_alldata.npy')[:,feature_ids]\n",
    "d_imp = np.load('/media/cat/1TB/dan/cohort1/slp/animalID_0_alldata_imputed.npy')\n",
    "\n",
    "\n",
    "idx_all = np.arange(d.shape[0])\n",
    "ctr=0\n",
    "sizes = (np.arange(1,7,1)*0.1)[::-1]\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "while ctr<10:\n",
    "#while True:\n",
    "    idx = np.random.choice(idx_all, 1)[0]\n",
    "    idx2 = np.where(np.isnan(d[idx][:,0])==False)[0]\n",
    "    idx3 = np.where(np.isnan(d_imp[idx,:,0])==False)[0]\n",
    "\n",
    "    if idx2.shape[0] != idx3.shape[0] and idx2.shape[0]>=5:\n",
    "\n",
    "    #if idx2.shape[0]>=2:\n",
    "\n",
    "        #idx3 = np.where(np.isnan(d_imp[idx,:,0])==False)[0]\n",
    "\n",
    "        print (idx, idx2, idx3, sizes[idx2])\n",
    "\n",
    "        print (\"preimupted: \", d[idx])\n",
    "\n",
    "        plt.subplot(2,5,ctr+1)\n",
    "        ss = np.zeros((6))+np.nan\n",
    "        ss[idx3] = sizes[idx3]\n",
    "        plt.scatter(d_imp[idx,:,0],\n",
    "                    d_imp[idx,:,1],\n",
    "                    s=ss,\n",
    "                    c='blue')\n",
    "\n",
    "        ss = np.zeros((6))+np.nan\n",
    "        ss[idx2] = sizes[idx2]\n",
    "        print (\"sizes: \", ss)\n",
    "        plt.scatter(d[idx,:,0],\n",
    "                    d[idx,:,1],\n",
    "                    s=ss,\n",
    "                    c='black')\n",
    " \n",
    "        ctr+=1\n",
    "        plt.title(str(idx)+ \" \" +str(idx2), fontsize=3, pad=0.8)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.xlim(0,1280)\n",
    "        plt.ylim(0,1280)\n",
    "\n",
    "if True:\n",
    "    plt.savefig('/home/cat/impute.png', dpi=300)\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#### VISUALIZE IMPUTATIONS + MOVIES #####\n",
    "#########################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80630288 (89989, 4, 14, 2) 80630144\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "data = np.load('/media/cat/1TB/dan/cohort1/slp/2020_3_16_12_57_12_418305_compressed.npy')\n",
    "print (getsizeof(data), data.shape, data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069710, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/media/cat/1TB/dan/cohort1/slp/centre_rotated_animalID_0_0_1.npz', allow_pickle=True)\n",
    "\n",
    "\n",
    "feats = data['feats_rotated']\n",
    "print (feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################    \n",
    "#### UNSHIFT/UNROTATE RESULTS ##\n",
    "################################\n",
    "\n",
    "# visualize before and after results in video form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89988, 4, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/media/cat/1TB/dan/cohort1/slp/2020_3_16_01_57_27_327194_compressed_median_filtered_outliers_centre_aligned_0_1.npz',\n",
    "              allow_pickle=True)\n",
    "\n",
    "feats = data['features_full']\n",
    "print (feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   note: pipeline currently applied only to Cohort1 March 16th datasets\n",
      " DATA SIZES: \n",
      " female [n_samples, n_featres, xy]:  (2069710, 14, 2)\n",
      " male:                               (2069710, 14, 2)\n",
      " pup1:                               (2069710, 14, 2)\n",
      " pup2:                               (2069710, 14, 2)\n",
      "(2069710, 14, 2)\n"
     ]
    }
   ],
   "source": [
    "f1 = 0\n",
    "f2 = 1\n",
    "feats = load_processed_data_stand_alone(f1,f2,I.March16_file_order, I.root_dir, I.animal_ids, data_type=1, remove_nans=False)\n",
    "print (np.vstack(feats[0]).shape)\n",
    "for k in range(I.animal_ids.shape[0]):\n",
    "    np.save(I.root_dir+'/animalID_'+str(k)+'_alldata.npy', np.vstack(feats[k]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5856  9187  9188 ... 60156 60157 60158] (9581,)\n",
      "(9581, 4, 6, 2)\n",
      "[[[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [-2.6053378e-16 -2.7597610e+01]\n",
      "   [ 4.1872730e+00 -4.4353676e+01]\n",
      "   [ 1.4419242e+01 -5.2421986e+01]\n",
      "   [ 2.2772881e+01 -7.9629517e+01]\n",
      "   [ 1.8599001e+01 -8.9770401e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]\n",
      "\n",
      "\n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.1549951e-15 -3.3143169e+01]\n",
      "   [ 1.9924431e+01 -6.0728550e+01]\n",
      "   [ 4.1260765e+01 -7.2759247e+01]\n",
      "   [ 6.9983749e+01 -9.3388031e+01]\n",
      "   [ 9.0890884e+01 -9.2662331e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]\n",
      "\n",
      "\n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [ 6.4845387e-15 -2.9197412e+01]\n",
      "   [ 2.1278805e+01 -5.5735901e+01]\n",
      "   [ 4.5587433e+01 -5.7687469e+01]\n",
      "   [ 8.0397346e+01 -6.4214302e+01]\n",
      "   [ 9.9035080e+01 -5.4713242e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.6115594e-15 -2.8648689e+01]\n",
      "   [-7.4477320e+00 -4.7606289e+01]\n",
      "   [-1.1588045e+01 -6.8303955e+01]\n",
      "   [-2.6754072e+01 -8.3746643e+01]\n",
      "   [-5.0876167e+01 -8.2087845e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]\n",
      "\n",
      "\n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [ 7.3422713e-15 -2.8082731e+01]\n",
      "   [-3.0128274e+00 -4.8088001e+01]\n",
      "   [-5.2030911e+00 -6.9082230e+01]\n",
      "   [-1.5235621e+01 -8.7014023e+01]\n",
      "   [-4.3044250e+01 -8.6452248e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]\n",
      "\n",
      "\n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.8554778e-15 -3.1283270e+01]\n",
      "   [-4.7501010e-01 -4.8179947e+01]\n",
      "   [-1.5560009e+00 -6.9260033e+01]\n",
      "   [-1.0629916e+01 -8.7695892e+01]\n",
      "   [-3.8429516e+01 -8.8600060e+01]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]\n",
      "\n",
      "  [[           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]\n",
      "   [           nan            nan]]]]\n"
     ]
    }
   ],
   "source": [
    "idx = np.unique(np.where(np.isnan(feats)==False)[0])\n",
    "print (idx, idx.shape)\n",
    "feats2 = feats[idx]\n",
    "print (feats2.shape)\n",
    "print (feats2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # load filtered + outliner triaged data with Nans removed\n",
    "# I.cb.load_processed_data(f1, f2,\n",
    "#                          data_type=0,\n",
    "#                          remove_nans=True)\n",
    "        \n",
    "        \n",
    "# I.load_models()\n",
    "\n",
    "\n",
    "# # test against ground truth/cleand data \n",
    "# I.fname_dropout = '/home/cat/feats_dropout.tsv'\n",
    "# res, idx_drop = I.predict_imputation_ground_truth(drops=np.arange(3,6,1)) # drops = 'fixed' or None\n",
    "\n",
    "# # check missing features in the data\n",
    "# # I.calculate_missing_features()\n",
    "\n",
    "# # \n",
    "# # I.plot_imputation_results(features_array, animal_id, idx_test, res, idx_drop)\n",
    "# plt.suptitle(\"animal \"+str(animal_id)+ \" imputed vs. ground truth\",fontsize=20)\n",
    "\n",
    "# # \n",
    "# I.evaluate_imputation_error(features_array, animal_id, res, idx_train, idx_test)\n",
    "# plt.suptitle(\"animal \"+str(animal_id)+ \"  Egocentric (fixed nose) errors (pixels)\",fontsize=20)\n",
    "# #plt.suptitle(\"animal \"+str(animal_id)+ \" NON-Egocentric (fixed nose) errors (pixels)\",fontsize=20)\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 5 4]\n",
      " [0 5 1]\n",
      " [2 4 0]\n",
      " ...\n",
      " [0 4 1]\n",
      " [4 5 0]\n",
      " [4 1 5]]\n",
      "(109565,)\n",
      "(109445,)\n",
      "(44043,)\n",
      "[[5 1 2]\n",
      " [1 2 0]\n",
      " [4 1 2]\n",
      " ...\n",
      " [1 5 2]\n",
      " [5 2 1]\n",
      " [1 4 2]]\n"
     ]
    }
   ],
   "source": [
    "# select some random drops for each\n",
    "drops = np.load('/home/cat/temp_f1f2_drops.npy')\n",
    "print (drops)\n",
    "\n",
    "idx1 = np.where(drops==1)[0]\n",
    "idx2 = np.where(drops==2)[0]\n",
    "print (idx1.shape)\n",
    "print (idx2.shape)\n",
    "\n",
    "idx3 = np.intersect1d(idx1, idx2)\n",
    "print (idx3.shape)\n",
    "print (drops[idx3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "random_sample() takes at most 1 positional argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9a00fd32ea32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.sample\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.random_sample\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: random_sample() takes at most 1 positional argument (2 given)"
     ]
    }
   ],
   "source": [
    "idx = np.random.sample(np.arange(6), 1)\n",
    "print (idx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9f4b180bc87c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute the error vs. ground truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_imputation_multivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# VAE CODE NOT USED NOW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/gerbil/movement_analysis/Imputation.py\u001b[0m in \u001b[0;36mevaluate_imputation_multivariate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0mtdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mtdiff\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m                     \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compute the error vs. ground truth\n",
    "I.evaluate_imputation_multivariate()\n",
    "\n",
    "\n",
    "# VAE CODE NOT USED NOW \n",
    "# make_vae_data()\n",
    "\n",
    "# df1 = evaluate_imputation_vae()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218641, 12)\n",
      "(1093205, 12)\n",
      "(218641, 12)\n",
      "(218641, 12)\n",
      "(1093205, 12)\n",
      "(218641, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n",
      "match_drop: [0 1 2 3 4 5]\n",
      "(5, 12)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "dropped_features= [0,1,2]\n",
    "I.plot_vae_scatter(dropped_features)  \n",
    "    \n",
    "#        \n",
    "I.plot_multiple_imputation_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "from scipy.spatial import cKDTree\n",
    "import joblib\n",
    "\n",
    "def knn_triage(th, pca_wf):\n",
    "    tree = cKDTree(pca_wf)\n",
    "    dist, ind = tree.query(pca_wf, k=6)\n",
    "    dist = np.sum(dist, 1)\n",
    "    idx_keep1 = dist <= np.percentile(dist, th)\n",
    "    return idx_keep1\n",
    "\n",
    "\n",
    "\n",
    "# Fit the PCA object, but do not transform the data\n",
    "for k in range(4):\n",
    "    ax=plt.subplot(2,2,k+1)\n",
    "    \n",
    "    temp = features_array[k]\n",
    "    d = []\n",
    "    clrs = []\n",
    "    for p in range(len(temp)):\n",
    "        d.append(temp[p])\n",
    "        clrs.extend(np.zeros(temp[p].shape[0])+p)\n",
    "    \n",
    "    clrs = np.array(clrs)\n",
    "    d = np.vstack(d)\n",
    "    print (\"D: \", d.shape)\n",
    "    d = d.reshape(d.shape[0],-1)\n",
    "    continue\n",
    "    #d = sklearn.preprocessing.normalize(d)\n",
    "\n",
    "    # remove 1% of outliers\n",
    "    if True:\n",
    "        th = 95  # % of data to keep\n",
    "        idx_keep = knn_triage(th, d)\n",
    "        print (\" d before traige: \", d.shape)\n",
    "        d = d[idx_keep]\n",
    "        print (\" d after traige: \", d.shape)\n",
    "        clrs = clrs[idx_keep]\n",
    "    \n",
    "    \n",
    "    if False:\n",
    "        pca = PCA(2)\n",
    "\n",
    "        print (\"... data into pca: \", d.shape)\n",
    "\n",
    "        feats_pca = pca.fit_transform(d)\n",
    "        print (feats_pca.shape)\n",
    "\n",
    "        # \n",
    "        plt.scatter(feats_pca[::5,0],\n",
    "           feats_pca[::5,1],\n",
    "            #c=np.arange(feats_pca.shape[0])[::5],\n",
    "            c=clrs[::5],\n",
    "            alpha=.05)\n",
    "        \n",
    "    if True:\n",
    "        \n",
    "#         import gpumap\n",
    "#         #from sklearn.datasets import load_digits\n",
    "\n",
    "#         #digits = load_digits()\n",
    "#         print (\"Data into gpumap: \", d.shape)\n",
    "#         feats_pca = gpumap.GPUMAP().fit_transform(d)\n",
    "#         print (\"Data out of gpumap: \", feats_pca.shape)\n",
    "\n",
    "        import umap\n",
    "    \n",
    "        umap = umap.UMAP(n_components=2,\n",
    "                        init='random',\n",
    "                        random_state=0)\n",
    "        \n",
    "        d = d[::2]\n",
    "        clrs = clrs[::2]\n",
    "        \n",
    "        print (\"... data into umap: \", d.shape)\n",
    "        \n",
    "        if False:\n",
    "            umap_ = umap.fit(d) #[::10])\n",
    "            feats_pca = umap_.transform(d)\n",
    "        else:\n",
    "            feats_pca = umap.fit_transform(d) #[::10])\n",
    "        \n",
    "        \n",
    "            # remove 1% of outliers\n",
    "        if True:\n",
    "            th = 90  # % of data to keep\n",
    "            idx_keep = knn_triage(th, feats_pca)\n",
    "            print (\" d before traige: \", feats_pca.shape)\n",
    "            feats_pca = feats_pca[idx_keep]\n",
    "            print (\" d after traige: \", feats_pca.shape)\n",
    "            clrs = clrs[idx_keep]\n",
    "        \n",
    "        plt.scatter(feats_pca[:,0],\n",
    "               feats_pca[:,1],\n",
    "                #c=np.arange(feats_pca.shape[0])[::5],\n",
    "                c=clrs,\n",
    "                alpha=.05)\n",
    "    if False:\n",
    "        \n",
    "        #from openTSNE import TSNE\n",
    "        #print (\"... data into tsne: \", d.shape)\n",
    "        #feats_pca = TSNE().fit(d)\n",
    "        \n",
    "        \n",
    "        from fastTSNE import TSNE\n",
    "\n",
    "        tsne = TSNE(\n",
    "            n_components=2, perplexity=30, learning_rate=100, early_exaggeration=12,\n",
    "            n_jobs=4, \n",
    "            #angle=0.5, \n",
    "            initialization='random', metric='euclidean',\n",
    "            n_iter=750, early_exaggeration_iter=250, neighbors='exact',\n",
    "            negative_gradient_method='bh', min_num_intervals=10,\n",
    "            #ints_in_inverval=2, \n",
    "            #late_exaggeration_iter=100, \n",
    "            #late_exaggeration=4,\n",
    "        )\n",
    "        \n",
    "        # \n",
    "        feats_pca = tsne.fit(d)\n",
    "\n",
    "        print (\" output: \", feats_pca.shape)\n",
    "\n",
    "\n",
    "        plt.scatter(feats_pca[:,0],\n",
    "            feats_pca[:,1],\n",
    "            #c=np.arange(feats_pca.shape[0])[::5],\n",
    "            c=clrs,\n",
    "            alpha=.05)\n",
    "\n",
    "    # \n",
    "    plt.title(\"Animal:\"+str(k))\n",
    "    \n",
    "    \n",
    "plt.suptitle(\"Static vertically aligned postures\",fontsize=20)\n",
    "plt.show()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.57  4.58  6.43  8.56]\n"
     ]
    }
   ],
   "source": [
    "lens = [218641, 94647, 132861, 176982]\n",
    "\n",
    "lens = np.array(lens)\n",
    "print (np.round(lens/(23*89900)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 6. 12.]\n",
      " [ 3.  6.]]\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "############### IMPUTE MISSING DATA #############\n",
    "#################################################\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp.fit([[1, 2], [3, 6], [4, 8], [np.nan, 3], [7, np.nan]])\n",
    "X_test = [[np.nan, 2], [6, np.nan], [np.nan, 6]]\n",
    "# the model learns that the second feature is double the first\n",
    "\n",
    "print(np.round(imp.transform(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "########## FEATURIZE BEHAVIOR CHUNKS #########\n",
    "##############################################\n",
    "from sklearn import decomposition\n",
    "import sklearn\n",
    "\n",
    "fig = plt.figure()\n",
    "X_all = []\n",
    "n_events = []\n",
    "for animal_id in animal_ids:\n",
    "    X = X4[animal_id].copy()\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    print (X.shape)\n",
    "    X_all.append(X)\n",
    "    n_events.append(X.shape[0])\n",
    "\n",
    "#     \n",
    "X_all = np.vstack(X_all)\n",
    "print (X_all.shape)\n",
    "X = sklearn.preprocessing.normalize(X_all)\n",
    "\n",
    "#\n",
    "if True:\n",
    "    pca = decomposition.PCA(n_components=3)\n",
    "\n",
    "    X_pca = pca.fit_transform(X_all)\n",
    "    print (X_pca.shape)\n",
    "    \n",
    "if False:\n",
    "    import umap\n",
    "    umap = umap.UMAP(n_components=2,\n",
    "                    init='random',\n",
    "                    random_state=0)\n",
    "\n",
    "    umap_ = umap.fit(X_all[::10])\n",
    "\n",
    "    X_pca = umap_.transform(X_all)\n",
    "        \n",
    "\n",
    "print (\"plotting: \", X_pca.shape)\n",
    "\n",
    "\n",
    "print (n_events)\n",
    "fig=plt.figure()\n",
    "for k in range(4):\n",
    "    ax = plt.subplot(2,2,k+1)\n",
    "    start = np.int32(n_events[:k]).sum()\n",
    "    end = np.int32(n_events[:k+1]).sum()\n",
    "    print (start, end)\n",
    "    plt.scatter(X_pca[start:end,0],\n",
    "                X_pca[start:end,1],\n",
    "               alpha=.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
