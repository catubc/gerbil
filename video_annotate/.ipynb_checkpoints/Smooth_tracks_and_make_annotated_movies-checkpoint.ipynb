{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "from tqdm import trange\n",
    "\n",
    "#import glob2\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import h5py\n",
    "#import hdf5storage\n",
    "import csv\n",
    "import sleap\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/cat/code/gerbil/')\n",
    "\n",
    "\n",
    "from utils.visualize import visualize as Visualize\n",
    "#from utils.track import track as Track\n",
    "from simba_tools.track_simba import track as Track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE...\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "###################################################\n",
    "###################################################\n",
    "# \n",
    "def save_two_animal_slp(animal_ids, fname_slp):\n",
    "    \n",
    "    \n",
    "    #\n",
    "    fname_out = fname_slp[:-4] + \"_\"+str(animal_ids[0])+\"_\"+str(animal_ids[1])+\".slp\"\n",
    "    \n",
    "    #\n",
    "    if os.path.exists(fname_out):\n",
    "        return\n",
    "    \n",
    "    # select first to animals\n",
    "    labels = sleap.load_file(fname_slp)\n",
    "\n",
    "    # Change this to specify which pair of tracks to save:\n",
    "    keep_tracks = [labels.tracks[animal_ids[0]], labels.tracks[animal_ids[1]]]\n",
    "\n",
    "    # Remove instances that aren't in keep_tracks\n",
    "    for lf in labels:\n",
    "        lf.instances = [inst for inst in lf.instances if inst.track in keep_tracks]\n",
    "\n",
    "    # Keep only those tracks in the labels\n",
    "    labels.tracks = keep_tracks\n",
    "\n",
    "    # Remove frames that are now empty due to the track filtering\n",
    "    labels.remove_empty_frames()\n",
    "\n",
    "    # Save the result with the specified tracks in the filename\n",
    "    labels.save(fname_out)\n",
    "    \n",
    "#\n",
    "#fname_slp = '/media/cat/256GB/dan/simba/2020_07_31_20_15_17_668937_compressed_defished_shrink_cropped.slp'\n",
    "#fname_vid = '/media/cat/256GB/dan/simba/2020_07_31_20_15_17_668937_compressed_defished_shrink_cropped.mp4'\n",
    "\n",
    "#\n",
    "fname_slp = '/mnt/b3a68699-495d-4ebb-9ab1-ac74f11c68c5/gerbil/cohort2/features/2020_07_31_11_22_34_209876_compressed_Day.slp'\n",
    "fname_vid = '/home/cat/Downloads/2020_07_31_11_22_34_209876_compressed_defished_shrink_cropped.mp4'\n",
    "\n",
    "\n",
    "#\n",
    "animal_ids = [1,3]\n",
    "save_two_animal_slp(animal_ids, fname_slp)\n",
    "\n",
    "#\n",
    "print (\"DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING...\n",
      "... npy missing, converting...\n",
      "... h5 file missing, converting now...\n",
      "... done loading slp\n",
      "\n",
      "Exporting to SLEAP Analysis file...\n",
      "\ttrack_names: 2\n",
      "\tnode_names: 6\n",
      "\tedge_names: 5\n",
      "\tedge_inds: 5\n",
      "\ttracks: (28802, 6, 2, 2)\n",
      "\ttrack_occupancy: (2, 28802)\n",
      "\tpoint_scores: (28802, 6, 2)\n",
      "\tinstance_scores: (28802, 2)\n",
      "\ttracking_scores: (28802, 2)\n",
      "\tlabels_path: None\n",
      "\tvideo_path: /vast/cm5635/cohort2/videos/2020_07_31_11_22_34_209876_compressed_defished_shrink_cropped.mp4\n",
      "\tvideo_ind: 0\n",
      "\tprovenance: {}\n",
      "Saved as /mnt/b3a68699-495d-4ebb-9ab1-ac74f11c68c5/gerbil/cohort2/features/2020_07_31_11_22_34_209876_compressed_Day_1_3.h5\n",
      "... done loading h5\n",
      "group2:  <HDF5 dataset \"tracks\": shape (2, 2, 6, 28802), type \"<f8\">\n",
      "... done loading npy\n",
      "... slp file loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 28425/28425 [00:00<00:00, 70445.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Making tracks chunks...\n",
      "Deleting chunks <  5\n",
      "... Fixing tracks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x4745504d/'MPEG' is not supported with codec id 2 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATING TRACKS\n",
      "input tracks size:  (28802, 2, 2)\n",
      "width, heigh:  900.0 700.0\n",
      "Histories:  (2, 24, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 99/99 [00:01<00:00, 76.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################## \n",
    "############## GENERATE FIXED TRACK MOVIE ##############\n",
    "########################################################\n",
    "print (\"STARTING...\")\n",
    "#fps = 25\n",
    "shrink = 1 # shrink image factor\n",
    "fname_video_out = str(animal_ids)\n",
    "fname_video = fname_vid #'/media/cat/256GB/dan/simba/2020_07_31_20_15_17_668937_compressed_defished_shrink_cropped.mp4'\n",
    "\n",
    "# \n",
    "fname_slp_in = fname_slp[:-4] + \"_\"+str(animal_ids[0])+\"_\"+str(animal_ids[1])+\".slp\"\n",
    "fname_slp_clean = fname_slp_in.replace('.slp','_cleaned.npy')\n",
    "#fname_slp = '/media/cat/256GB/dan/simba/2020_07_31_20_15_17_668937_compressed_defished_shrink_cropped_0_1.slp'\n",
    "\n",
    "#\n",
    "track = Track.Track(fname_slp_in)\n",
    "track.track_type = \"features\"\n",
    "track.exclude_huddles = False\n",
    "track.use_dynamic_centroid = True\n",
    "\n",
    "\n",
    "#\n",
    "#track.animal_ids = [0,1,2,3,4,5]\n",
    "track.animal_ids = [0,1]\n",
    "#track.animal_ids = animal_ids\n",
    "track.tracks_names = ['female','male','pup1','pup2','pup3','pup4']\n",
    "track.recompute_spine_centres=True\n",
    "track.verbose = True                         # gives additional printouts\n",
    "track.n_animals = len(track.animal_ids)      # number of animals\n",
    "track.filter_width = 10                      # this is the median filter width in frames; e.g. 10 ~=0.4 seconds\n",
    "                                             # higher values provide more stability, but less temporally precise locations\n",
    "# \n",
    "track.load_tracks()\n",
    "\n",
    "####################################################\n",
    "### OPTIONAL - MEDIAN FILTER ALL TRACKS ############\n",
    "####################################################\n",
    "if True:\n",
    "    track.filter_tracks()\n",
    "    #track.filter_tracks_spines()\n",
    "            \n",
    "####################################################\n",
    "### OPTIONAL - ALGORITHM TO REASSIGN CHUNKING ######\n",
    "####################################################\n",
    "if True:\n",
    "\n",
    "    # makes scores based on .slp output? (to check)\n",
    "    track.get_scores()\n",
    "\n",
    "    # uses track_spines to break up all the data into continuous chunks\n",
    "    track.max_jump_single_frame = 30  # max distance in pixels (?) that an animal can move in a single frame\n",
    "    track.make_tracks_chunks()        \n",
    "\n",
    "    # deletig very short chunks of track that are orphaned..\n",
    "    min_chunk_len = 5\n",
    "    track.del_short_chunks(min_chunk_len)\n",
    "\n",
    "    ############## FIX TRACKS PARAMS #############\n",
    "    track.time_threshold = 25       # window to search for nearest chunks, about 1sec seems fair...\n",
    "    track.safe_chunk_length = 15    # chunks this long will not change id\n",
    "    track.min_chunk_len = 4         # min length of chukn to be used for anchoring/correcting\n",
    "    track.max_distance_merge = 75   # max pix diff allowed for merging when using model; not just for neighbouring frames\n",
    "    # track.memory_length = 25      # how many frames back is it ok to remember a prev animal\n",
    "    track.verbose = False\n",
    "    track.update_tracks = True\n",
    "    \n",
    "    # parameters for fixing track chunking\n",
    "    track.max_time_automerge = 3      # time to automerget chunks from same animal ???\n",
    "    track.max_dist_automerge = 25     # distance to auto merge chunks from same animal separated by single time skip\n",
    "\n",
    "\n",
    "    track.fix_tracks()\n",
    "\n",
    "else:\n",
    "    # recompute spine centres from scratch\n",
    "    track.get_track_spine_centers()\n",
    "    \n",
    "    #\n",
    "    print (\"tracks loaded: \", track.tracks_spine.shape)\n",
    "    \n",
    "####################################################\n",
    "### OPTIONAL - MEDIAN FILTER SPINE CENTRES #########\n",
    "####################################################\n",
    "if False:\n",
    "    track.filter_tracks_spines() \n",
    "    \n",
    "#\n",
    "np.save(fname_slp_clean, track.tracks_spine)\n",
    "    \n",
    "####################################################\n",
    "########## MAKE MOVIES OF SPINE CENTRES ############\n",
    "####################################################\n",
    "vis = Visualize.Visualize()\n",
    "start = 0   # frame to start\n",
    "end = 28802     # frame to end\n",
    "end = 100\n",
    "fps = 24       # speed of video playback\n",
    "vis.history_len = 24\n",
    "vis.animal_ids = animal_ids\n",
    "\n",
    "#\n",
    "vis.make_video_centroid_velocity(track.tracks_spine,                # visualize centres locations\n",
    "                        fname_video,\n",
    "                        fname_video_out,\n",
    "                        start,\n",
    "                        end,\n",
    "                        fps,\n",
    "                        shrink) \n",
    "\n",
    "# \n",
    "print (\"DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING...\n",
      "... Making tracks chunks...\n",
      "Deleting chunks <  5\n",
      "... Fixing tracks...\n",
      "UPDATING TRACKS\n",
      "input tracks size:  (28802, 2, 2)\n",
      "width, heigh:  900.0 700.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x4745504d/'MPEG' is not supported with codec id 2 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histories:  (2, 24, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 999/999 [00:12<00:00, 82.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################## \n",
    "############## GENERATE FIXED TRACK MOVIE ##############\n",
    "########################################################\n",
    "print (\"STARTING...\")\n",
    "#fps = 25\n",
    "shrink = 1 # shrink image factor\n",
    "fname_video_out = str(animal_ids)\n",
    "fname_video = fname_vid #'/media/cat/256GB/dan/simba/2020_07_31_20_15_17_668937_compressed_defished_shrink_cropped.mp4'\n",
    "\n",
    "# \n",
    "fname_slp_in = fname_slp[:-4] + \"_\"+str(animal_ids[0])+\"_\"+str(animal_ids[1])+\".slp\"\n",
    "fname_slp_clean = fname_slp_in.replace('.slp','_cleaned.npy')\n",
    "#fname_slp = '/media/cat/256GB/dan/simba/2020_07_31_20_15_17_668937_compressed_defished_shrink_cropped_0_1.slp'\n",
    "\n",
    "#\n",
    "track = Track.Track(fname_slp_in)\n",
    "track.track_type = \"features\"\n",
    "track.exclude_huddles = False\n",
    "track.use_dynamic_centroid = True\n",
    "\n",
    "\n",
    "#\n",
    "#track.animal_ids = [0,1,2,3,4,5]\n",
    "track.animal_ids = [0,1]\n",
    "#track.animal_ids = animal_ids\n",
    "track.tracks_names = ['female','male','pup1','pup2','pup3','pup4']\n",
    "track.recompute_spine_centres=True\n",
    "track.verbose = True                         # gives additional printouts\n",
    "track.n_animals = len(track.animal_ids)      # number of animals\n",
    "track.filter_width = 10                      # this is the median filter width in frames; e.g. 10 ~=0.4 seconds\n",
    "                                             # higher values provide more stability, but less temporally precise locations\n",
    "# \n",
    "track.load_tracks()\n",
    "\n",
    "####################################################\n",
    "### OPTIONAL - MEDIAN FILTER ALL TRACKS ############\n",
    "####################################################\n",
    "if True:\n",
    "    track.filter_tracks()\n",
    "    #track.filter_tracks_spines()\n",
    "            \n",
    "####################################################\n",
    "### OPTIONAL - ALGORITHM TO REASSIGN CHUNKING ######\n",
    "####################################################\n",
    "if True:\n",
    "\n",
    "    # makes scores based on .slp output? (to check)\n",
    "    track.get_scores()\n",
    "\n",
    "    # uses track_spines to break up all the data into continuous chunks\n",
    "    track.max_jump_single_frame = 30  # max distance in pixels (?) that an animal can move in a single frame\n",
    "    track.make_tracks_chunks()        \n",
    "\n",
    "    # deletig very short chunks of track that are orphaned..\n",
    "    min_chunk_len = 5\n",
    "    track.del_short_chunks(min_chunk_len)\n",
    "\n",
    "    ############## FIX TRACKS PARAMS #############\n",
    "    track.time_threshold = 25       # window to search for nearest chunks, about 1sec seems fair...\n",
    "    track.safe_chunk_length = 15    # chunks this long will not change id\n",
    "    track.min_chunk_len = 4         # min length of chukn to be used for anchoring/correcting\n",
    "    track.max_distance_merge = 75   # max pix diff allowed for merging when using model; not just for neighbouring frames\n",
    "    # track.memory_length = 25      # how many frames back is it ok to remember a prev animal\n",
    "    track.verbose = False\n",
    "    track.update_tracks = True\n",
    "    \n",
    "    # parameters for fixing track chunking\n",
    "    track.max_time_automerge = 3      # time to automerget chunks from same animal ???\n",
    "    track.max_dist_automerge = 25     # distance to auto merge chunks from same animal separated by single time skip\n",
    "\n",
    "\n",
    "    track.fix_tracks()\n",
    "\n",
    "else:\n",
    "    # recompute spine centres from scratch\n",
    "    track.get_track_spine_centers()\n",
    "    \n",
    "    #\n",
    "    print (\"tracks loaded: \", track.tracks_spine.shape)\n",
    "    \n",
    "####################################################\n",
    "### OPTIONAL - MEDIAN FILTER SPINE CENTRES #########\n",
    "####################################################\n",
    "if False:\n",
    "    track.filter_tracks_spines() \n",
    "    \n",
    "#\n",
    "np.save(fname_slp_clean, track.tracks_spine)\n",
    "\n",
    "\n",
    "#\n",
    "track.smooth_angles = True\n",
    "track.compute_angles_from_features()\n",
    "np.save(fname_slp_clean[:-4]+\"_angles.npy\",\n",
    "        track.angles)    \n",
    "    \n",
    "    \n",
    "####################################################\n",
    "########## MAKE MOVIES OF SPINE CENTRES ############\n",
    "####################################################\n",
    "vis = Visualize.Visualize()\n",
    "start = 0   # frame to start\n",
    "end = 28802     # frame to end\n",
    "start = 16000\n",
    "end = 17000\n",
    "fps = 24       # speed of video playback\n",
    "vis.history_len = 24\n",
    "vis.animal_ids = animal_ids\n",
    "\n",
    "################## IF CHASING #####################\n",
    "vis.make_video_centroid_velocity(track.tracks_spine,                # visualize centres locations\n",
    "                        fname_video,\n",
    "                        fname_video_out,\n",
    "                        start,\n",
    "                        end,\n",
    "                        fps,\n",
    "                        shrink) \n",
    "\n",
    "############## IF APPROACH ################\n",
    "# vis.make_video_centroid(track.tracks_spine,                # visualize centres locations\n",
    "#                        fname_video,\n",
    "#                        fname_video_out,\n",
    "#                        start,\n",
    "#                        end,\n",
    "#                        fps,\n",
    "#                        shrink) \n",
    "\n",
    "# \n",
    "print (\"DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28802, 2, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 28802/28802 [00:31<00:00, 901.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28802, 2)\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "### OPTIONAL - MEDIAN FILTER SPINE CENTRES #########\n",
    "####################################################\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "print (track.angles.shape)\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(track.angles[:,0])\n",
    "plt.plot(track.angles[:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28802, 2)\n"
     ]
    }
   ],
   "source": [
    "print (track.angles.shape)\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(track.dists[:,0])\n",
    "plt.plot(track.dists[:,1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/89987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of lableed frames:  (292353,)\n",
      "Lenght of tracessx:  (89988, 70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89987/89987 [49:17<00:00, 30.43it/s]  \n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "###### MAKE HUNGARIAN ALGORITHM ASSEMBLED ANIMAL VIDEOS #########\n",
    "#################################################################\n",
    "\n",
    "#\n",
    "fname_traces_inferences = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences_0_89988.npz'\n",
    "reassembled = np.load(fname_traces_inferences)\n",
    "#reassembled = np.load('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/pickle/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_full_traces_inferences.npz')\n",
    "tracesx_re = reassembled['tracesx'].T\n",
    "tracesy_re = reassembled['tracesy'].T\n",
    "print (\"Lenght of tracessx: \", tracesx_re.shape)\n",
    "\n",
    "# OPTIONAL MAKE VIDEO TO REVIEW ASSEMBLED VS. INFERENCE LABELS (PRE-FIX)\n",
    "# colors have weird inversion; red is blue and cyan is yellow\n",
    "#colors_4 = ['blue','red','cyan','green','pink','orange']\n",
    "\n",
    "#          pup1     pup2    female  male\n",
    "colors_4= ['orange','green', 'blue', 'red', 'cyan']\n",
    "colors_5= ['red','blue', 'cyan', 'green', 'yellow']\n",
    "\n",
    "video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_54_07_193951_compressed/2020-3-16_12_54_07_193951_compressed.avi'\n",
    "#video_name = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/2020-3-16_12_57_12_418305_compressed.avi'\n",
    "original_vid = cv2.VideoCapture(video_name)\n",
    "\n",
    "# video sizes\n",
    "size_vid = np.array([1280,1024])\n",
    "scale = 1\n",
    "dot_size = 8//scale\n",
    "dot_size2 = 4//scale\n",
    "\n",
    "#\n",
    "\n",
    "#dot_size = 10//scale\n",
    "# setup cutoff \n",
    "pcutoff = 0.01\n",
    "\n",
    "# go through first videos\n",
    "from tqdm import trange\n",
    "\n",
    "start = 1\n",
    "end = tracesx_re.shape[0]\n",
    "#end = 1001\n",
    "n_networks = 5\n",
    "comments=False\n",
    "\n",
    "out_dir = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/2020-3-9_08_18_49_128168/'\n",
    "fname_out = video_name[:-4]+\"_CNN_\"+str(start)+\"_\"+str(end)+\".mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc('M','P','E','G')\n",
    "video_out = cv2.VideoWriter(fname_out,fourcc, 25, (size_vid[0]//scale,size_vid[1]//scale), True)\n",
    "original_vid.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "\n",
    "# LOOP \n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for n in trange(start,end, 1):\n",
    "    ret, frame = original_vid.read()\n",
    "    #print (n, frame.shape)\n",
    "    cv2.putText(frame, str(n), (50, 100), font, 5, (255, 255, 0), 5)\n",
    "    frame = frame[::scale, ::scale]\n",
    "        \n",
    "    animal_ids, animal_ids2, dirs = get_animal_ids(n,\n",
    "                                chain_ids,\n",
    "                                vals,\n",
    "                                classes,\n",
    "                                comments)\n",
    "    shift=20\n",
    "    #titles = np.zeros(n_networks)\n",
    "    for k in range(0, 14*n_networks,14):\n",
    "    #for k in range(14*n_networks):\n",
    "        y = tracesx_re[n,k:k+14]\n",
    "        x = tracesy_re[n,k:k+14]\n",
    "        \n",
    "        #if animal_ids[k//14]==None:\n",
    "        #    continue\n",
    "            \n",
    "        idx = np.where(np.isnan(x))[0]\n",
    "        x = np.delete(x,idx,0)\n",
    "        y = np.delete(y,idx,0)\n",
    "        idx = np.where(x==0)[0]\n",
    "        x = np.delete(x,idx,0)\n",
    "        y = np.delete(y,idx,0)\n",
    "        \n",
    "        #if np.isnan(x) or np.isnan(y):\n",
    "        #    continue\n",
    "        \n",
    "        if x.shape[0]==0:\n",
    "            continue\n",
    "        #print (x)\n",
    "        x1=np.int32(x)//scale\n",
    "        y1=np.int32(y)//scale\n",
    "        \n",
    "        flag=True\n",
    "        for x, y in zip(x1,y1):\n",
    "            if animal_ids[k//14]==1E10:\n",
    "                continue\n",
    "                \n",
    "            if animal_ids[k//14]!= None:\n",
    "                frame[x-dot_size:x+dot_size,y-dot_size:y+dot_size]= (np.float32(\n",
    "                    #matplotlib.colors.to_rgb(colors_4[k//14]))*255.).astype('uint8')\n",
    "                    #matplotlib.colors.to_rgb('white'))*255.).astype('uint8')\n",
    "                    matplotlib.colors.to_rgb(colors_5[animal_ids[k//14]]))*255.).astype('uint8')\n",
    "\n",
    "            if animal_ids2[k//14]!= None:\n",
    "                frame[x-dot_size2+shift:x+shift+dot_size2,y-dot_size2:y+dot_size2]= (np.float32(\n",
    "                    #matplotlib.colors.to_rgb(colors_4[k//14]))*255.).astype('uint8')\n",
    "                    #matplotlib.colors.to_rgb('white'))*255.).astype('uint8')\n",
    "                    matplotlib.colors.to_rgb(colors_5[animal_ids2[k//14]]))*255.).astype('uint8')\n",
    "        \n",
    "        #print (colors_4[k])\n",
    "        #frame[y-dot_size:y+dot_size,x-dot_size:x+dot_size]= (np.float32(\n",
    "        #    matplotlib.colors.to_rgb(colors_4[z//14]))*255.).astype('uint8')\n",
    "\n",
    "        #if titles[k//14]==0:\n",
    "            if flag:\n",
    "                cv2.putText(frame, str(dirs[k//14]), (y, x), font, 2, (255, 255, 0), 5)\n",
    "                flag=False\n",
    "    #print (\"\")\n",
    "    video_out.write(frame)\n",
    "\n",
    "    #print (\"\")\n",
    "\n",
    "video_out.release()\n",
    "original_vid.release()\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleap_new",
   "language": "python",
   "name": "sleap_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
