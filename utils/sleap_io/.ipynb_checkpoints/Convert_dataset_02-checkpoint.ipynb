{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ede1e45d-27c6-4461-8ec6-1664aa564795",
      "metadata": {
        "id": "ede1e45d-27c6-4461-8ec6-1664aa564795"
      },
      "outputs": [],
      "source": [
        "import sleap_io as sio\n",
        "import imageio.v3 as iio\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from rich.progress import track"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4d1f26c-ab92-47f5-8e6d-fb8ebe6d07ec",
      "metadata": {
        "id": "d4d1f26c-ab92-47f5-8e6d-fb8ebe6d07ec"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"datasets\"\n",
        "dataset_name = \"flies13\"\n",
        "\n",
        "labels_paths = {\n",
        "    \"train\": r\"D:\\sleap-data\\datasets\\wt_gold.13pt\\tracking_split2\\train.pkg.slp\",\n",
        "    \"val\": r\"D:\\sleap-data\\datasets\\wt_gold.13pt\\tracking_split2\\val.pkg.slp\",\n",
        "    \"test\": r\"D:\\sleap-data\\datasets\\wt_gold.13pt\\tracking_split2\\test.pkg.slp\",\n",
        "}\n",
        "\n",
        "symmetries = [\n",
        "    (\"wingL\", \"wingR\"),\n",
        "    (\"forelegL4\", \"forelegR4\"),\n",
        "    (\"midlegL4\", \"midlegR4\"),\n",
        "    (\"hindlegL4\", \"hindlegR4\"),\n",
        "    (\"eyeL\", \"eyeR\"),\n",
        "]\n",
        "\n",
        "class_index = 0\n",
        "quality = 90\n",
        "overwrite = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f64485da-b3bc-4c66-8d5a-b2400b2b5e0e",
      "metadata": {
        "id": "f64485da-b3bc-4c66-8d5a-b2400b2b5e0e"
      },
      "outputs": [],
      "source": [
        "def convert_instance(instance: sio.Instance, img_height: int, img_width: int, class_index: int = 0) -> str:\n",
        "    \"\"\"Convert a SLEAP Instance to a row in the Ultralytics pose format.\n",
        "\n",
        "    Args:\n",
        "        instance: A SLEAP Instance representing a single subject in a frame.\n",
        "        img_height: Height of the image this instance comes from in pixels.\n",
        "        img_width: Width of the image this instance comes from in pixels.\n",
        "        class_index: An integer representing the class of the object. Defaults\n",
        "            to 0.\n",
        "\n",
        "    Returns:\n",
        "        A string with the Ultralytics-formatted row.\n",
        "\n",
        "    Notes:\n",
        "        The row will be formatted as:\n",
        "        ```\n",
        "        <class-index> <x> <y> <width> <height> <px1> <py1> <p1-visibility> <px2> <py2> <p2-visibility> <pxn> <pyn> <p2-visibility>\n",
        "        ```\n",
        "\n",
        "        Reference: https://docs.ultralytics.com/datasets/pose/\n",
        "    \"\"\"\n",
        "    pts = instance.numpy()\n",
        "\n",
        "    x0, x1 = np.nanmin(pts[:, 0]), np.nanmax(pts[:, 0])\n",
        "    y0, y1 = np.nanmin(pts[:, 1]), np.nanmax(pts[:, 1])\n",
        "\n",
        "    bbox_midx = ((x0 + x1) / 2) / img_width\n",
        "    bbox_midy = ((y0 + y1) / 2) / img_height\n",
        "\n",
        "    bbox_width = (x1 - x0) / img_width\n",
        "    bbox_height = (y1 - y0) / img_height\n",
        "\n",
        "    row = [\n",
        "        f\"{class_index:d}\",\n",
        "        f\"{bbox_midx:.6f}\",\n",
        "        f\"{bbox_midy:.6f}\",\n",
        "        f\"{bbox_width:.6f}\",\n",
        "        f\"{bbox_height:.6f}\",\n",
        "    ]\n",
        "    for (px, py) in pts:\n",
        "        if np.isnan(px):\n",
        "            px, py, vis = 0., 0., 0\n",
        "        else:\n",
        "            px = px / img_width\n",
        "            py = py / img_height\n",
        "            vis = 1\n",
        "        row.extend([\n",
        "            f\"{px:.6f}\",\n",
        "            f\"{py:.6f}\",\n",
        "            f\"{vis:d}\",\n",
        "        ])\n",
        "    row = \" \".join(row)\n",
        "    return row\n",
        "\n",
        "\n",
        "def convert_frames(labels: sio.Labels, save_folder: str, class_index: int = 0, quality: int = 90, overwrite: bool = False):\n",
        "    \"\"\"Generate images and text files for individual labeled frames.\n",
        "\n",
        "    Args:\n",
        "        labels: SLEAP Labels object.\n",
        "        save_folder: Folder that will contain images and text files.\n",
        "        class_index: An integer representing the class of the object. Defaults\n",
        "            to 0.\n",
        "        quality: Image compression quality to save at. Defaults to 90.\n",
        "        overwrite: If False (the default), skip frames that already have saved data.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        iter_labels = track(enumerate(labels), total=len(labels))\n",
        "    except:\n",
        "        iter_labels = enumerate(labels)\n",
        "    for i, lf in iter_labels:\n",
        "        name = f\"{i:06d}\"\n",
        "        save_folder = Path(save_folder)\n",
        "        img_path = (save_folder / (name + \".jpg\"))\n",
        "        txt_path = (save_folder / (name + \".txt\"))\n",
        "\n",
        "        if (not overwrite) and img_path.exists() and txt_path.exists():\n",
        "            continue\n",
        "\n",
        "        img = lf.image.squeeze()\n",
        "        img_height, img_width = img.shape[:2]\n",
        "        instances = \"\\n\".join([\n",
        "            convert_instance(instance, img_height, img_width, class_index=class_index)\n",
        "            for instance in lf.user_instances\n",
        "        ])\n",
        "\n",
        "        save_folder.mkdir(exist_ok=True, parents=True)\n",
        "        iio.imwrite(img_path, img, quality=quality)\n",
        "        with open(txt_path, \"w\") as f:\n",
        "            f.write(instances)\n",
        "\n",
        "\n",
        "def parse_skeleton(skel: sio.Skeleton, symmetries: list = None):\n",
        "    \"\"\"Return number of nodes and symmetries.\"\"\"\n",
        "    n_nodes = len(skel)\n",
        "\n",
        "    if symmetries is None:\n",
        "        symmetries = skel.symmetries\n",
        "\n",
        "    flip_idx = np.arange(n_nodes)\n",
        "\n",
        "    if len(symmetries) > 0:\n",
        "        symmetry_inds = np.array([(skel.index(a), skel.index(b)) for a, b in symmetries])\n",
        "        flip_idx[symmetry_inds[:, 0]] = symmetry_inds[:, 1]\n",
        "        flip_idx[symmetry_inds[:, 1]] = symmetry_inds[:, 0]\n",
        "\n",
        "    flip_idx = flip_idx.tolist()\n",
        "\n",
        "    return n_nodes, flip_idx\n",
        "\n",
        "\n",
        "def write_dataset_yaml(dataset_path, dataset_name, n_nodes, flip_idx):\n",
        "    dataset_path = Path(dataset_path)\n",
        "    dataset_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    dataset_yaml_path = dataset_path / dataset_name / f\"{dataset_name}.yaml\"\n",
        "\n",
        "    with open(dataset_yaml_path, \"w\") as f:\n",
        "        f.write(\n",
        "f\"\"\"# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
        "path: {dataset_name}  # dataset root dir\n",
        "train: train  # train images (relative to 'path')\n",
        "val: val  # val images (relative to 'path')\n",
        "test: test  # test images (optional)\n",
        "\n",
        "# Keypoints\n",
        "kpt_shape: [{n_nodes}, 3]  # number of keypoints, number of dims (2 for x,y or 3 for x,y,visible)\n",
        "flip_idx: {flip_idx}\n",
        "\n",
        "# Classes dictionary\n",
        "names:\n",
        "  0: instance\n",
        "\"\"\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "939e40a2-19af-44e2-84ab-0ce2b4ac275c",
      "metadata": {
        "id": "939e40a2-19af-44e2-84ab-0ce2b4ac275c",
        "outputId": "020bc1d9-b34a-49fd-8d04-32daad3e5468"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Working... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:04</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Working... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:04\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset_path = Path(dataset_path)\n",
        "\n",
        "n_nodes = None\n",
        "for split_name, labels_path in labels_paths.items():\n",
        "    labels = sio.load_slp(labels_path)\n",
        "\n",
        "    if n_nodes is None:\n",
        "        n_nodes, flip_idx = parse_skeleton(labels.skeletons[0], symmetries)\n",
        "\n",
        "    img_folder = dataset_path / dataset_name / split_name\n",
        "\n",
        "    convert_frames(labels, save_folder=img_folder, class_index=class_index, quality=quality, overwrite=overwrite)\n",
        "\n",
        "write_dataset_yaml(dataset_path, dataset_name, n_nodes, flip_idx)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}