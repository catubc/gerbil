{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2043adaf-0330-4103-ba6f-c659d69340d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/miniconda3/envs/sleap_new/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# \n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "\n",
    "from utils import plot_me, smooth_traces, generate_track_interactions\n",
    "from track import Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40b5fbaa-5f5e-4e6b-b6de-1986480d3823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "####################### HELPER FUNCTIONS #################################\n",
    "##########################################################################\n",
    "\n",
    "#\n",
    "def parse_spreadsheet_return_unique_vids_and_starts_ends(header, \n",
    "                                                         dataframe):\n",
    "\n",
    "    # get animal ids first\n",
    "    animal_labels = []\n",
    "    for k in range(1,len(header),2):\n",
    "        temp = header[k]\n",
    "        animal_labels.append(temp)\n",
    "\n",
    "    #print (\"animal_labels: \", animal_labels)\n",
    "\n",
    "    # get starts and ends next\n",
    "    starts_ends = []\n",
    "    video_names = []\n",
    "    animal_ids = []\n",
    "    data_npy = dataframe.to_numpy()\n",
    "    #print (data_npy.shape)\n",
    "\n",
    "    #\n",
    "    for k in range(data_npy.shape[0]):\n",
    "        vid_name = data_npy[k][0]\n",
    "        for p in range(1,data_npy.shape[1],2):\n",
    "            #print (data_npy[k,p])\n",
    "            if data_npy[k,p]!=0:\n",
    "                starts_ends.append([data_npy[k,p],data_npy[k,p+1]])\n",
    "                video_names.append(vid_name)\n",
    "                animal_ids.append(animal_labels[p//2])\n",
    "\n",
    "    #\n",
    "    video_names = np.array(video_names)\n",
    "    starts_ends = np.array(starts_ends)\n",
    "    animal_ids = np.array(animal_ids)\n",
    "\n",
    "    # #\n",
    "    # for k in range(len(starts_ends)):\n",
    "    #     print (video_names[k], \n",
    "    #            starts_ends[k],\n",
    "    #            animal_ids[k])\n",
    "\n",
    "    # gather all video-animal pairs that are the same \n",
    "    unique_vids = np.unique(video_names)\n",
    "    unique_ids = np.unique(animal_ids)\n",
    "    #print (unique_ids)\n",
    "\n",
    "    # \n",
    "    ctr=0\n",
    "    final_arrays= []\n",
    "    final_arrays.append([])\n",
    "    for unique_vid in unique_vids:\n",
    "        for unique_id in unique_ids:\n",
    "           \n",
    "            \n",
    "            # loop over all vids\n",
    "            se_array = []\n",
    "            for k in range(starts_ends.shape[0]):\n",
    "                if video_names[k] == unique_vid:\n",
    "                    if animal_ids[k] == unique_id:\n",
    "                        se_array.append(starts_ends[k])\n",
    "            #\n",
    "            if len(se_array)>0:\n",
    "                final_arrays[ctr].append(unique_vid)\n",
    "                final_arrays[ctr].append(unique_id)\n",
    "                final_arrays[ctr].append(np.vstack(se_array).squeeze())\n",
    "                final_arrays.append([])\n",
    "                ctr+=1\n",
    "    \n",
    "    if len(final_arrays[-1])==0:\n",
    "        del(final_arrays[-1])\n",
    "\n",
    "    # \n",
    "    print (\"                                UNIQUE VIDEO ID           ANIMAL IDS      STARTS-ENDS ARRAYS\")\n",
    "    for k in range(len(final_arrays)):\n",
    "        print (\" unique video - pair: #\", k, \": \", final_arrays[k])\n",
    "\n",
    "    return final_arrays\n",
    "\n",
    "#\n",
    "def make_pairwise_npy_files_for_simba(final_arrays,\n",
    "                                     root_dir):\n",
    "    #\n",
    "    for dataset in final_arrays:\n",
    "\n",
    "        #\n",
    "        fname = dataset[0]\n",
    "\n",
    "        #\n",
    "        animal_ids = np.int32([dataset[1][0],dataset[1][2]])\n",
    "\n",
    "        #\n",
    "        starts_ends = dataset[2]\n",
    "\n",
    "        fname_out = os.path.join(root_dir+'/pairwise'+\n",
    "                            fname+\"_animals_\"+str(animal_ids[0])+\"_\"+str(animal_ids[1])+'.npy')\n",
    "        \n",
    "        #\n",
    "        if os.path.exists(fname_out):\n",
    "            continue\n",
    "        \n",
    "        #\n",
    "        print (\"PROCESSING: \")\n",
    "        print (fname)\n",
    "        print (animal_ids)\n",
    "        print (starts_ends)\n",
    "        \n",
    "        #\n",
    "        track = Track(os.path.join(root_dir, \n",
    "                                   fname+'_compressed_Day.slp'))\n",
    "        track.animal_ids = animal_ids\n",
    "        track.tracks_names = ['female','male','pup1','pup2','pup3','pup4']\n",
    "        track.recompute_spine_centres=True\n",
    "        track.verbose = True                         # gives additional printouts\n",
    "        track.n_animals = len(track.animal_ids)      # number of animals\n",
    "        track.filter_width = 10                      # this is the median filter width in frames; e.g. 10 ~=0.4 seconds\n",
    "                                                     # higher values provide more stability, but less temporally precise locations\n",
    "        # \n",
    "        track.load_tracks()\n",
    "\n",
    "        #\n",
    "        data_out = np.zeros((track.tracks_spine.shape[0],\n",
    "                             2,2,2))\n",
    "\n",
    "        #\n",
    "        data_out[:,:,:,0] = track.tracks_spine[:,animal_ids]\n",
    "\n",
    "        #\n",
    "        try:\n",
    "            for se in starts_ends:\n",
    "                data_out[int(se[0]):int(se[1]),:,:,1]=1\n",
    "        except:\n",
    "            print (\"single exmaple only\")\n",
    "            data_out[int(starts_ends[0]):int(starts_ends[1]),:,:,1]=1\n",
    "\n",
    "        #\n",
    "        np.save(fname_out, data_out)\n",
    "        \n",
    "        ####################################################\n",
    "        ############# MAKE ANIMAL ANGLES ###################\n",
    "        ####################################################\n",
    "        \n",
    "        track.smooth_angles = True\n",
    "        track.compute_angles_from_features(fname_out)\n",
    "        np.save(fname_out[:-4]+\"_angles.npy\",\n",
    "                track.angles)    \n",
    "        \n",
    "        #\n",
    "        print (\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1e7b1-bf0f-405f-a9a4-f59f9ff9ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "def make_pairwise_npy_files_for_simba_single_file(fname_in,\n",
    "                                                   root_dir):\n",
    "   \n",
    "\n",
    "    dataset = \n",
    "\n",
    "        #\n",
    "        fname = dataset[0]\n",
    "\n",
    "        #\n",
    "        animal_ids = np.int32([dataset[1][0],dataset[1][2]])\n",
    "\n",
    "        #\n",
    "        starts_ends = dataset[2]\n",
    "\n",
    "        fname_out = os.path.join(root_dir+'/pairwise'+\n",
    "                            fname+\"_animals_\"+str(animal_ids[0])+\"_\"+str(animal_ids[1])+'.npy')\n",
    "        \n",
    "        #\n",
    "        if os.path.exists(fname_out):\n",
    "            continue\n",
    "        \n",
    "        #\n",
    "        print (\"PROCESSING: \")\n",
    "        print (fname)\n",
    "        print (animal_ids)\n",
    "        print (starts_ends)\n",
    "        \n",
    "        #\n",
    "        track = Track(os.path.join(root_dir, \n",
    "                                   fname+'_compressed_Day.slp'))\n",
    "        track.animal_ids = animal_ids\n",
    "        track.tracks_names = ['female','male','pup1','pup2','pup3','pup4']\n",
    "        track.recompute_spine_centres=True\n",
    "        track.verbose = True                         # gives additional printouts\n",
    "        track.n_animals = len(track.animal_ids)      # number of animals\n",
    "        track.filter_width = 10                      # this is the median filter width in frames; e.g. 10 ~=0.4 seconds\n",
    "                                                     # higher values provide more stability, but less temporally precise locations\n",
    "        # \n",
    "        track.load_tracks()\n",
    "\n",
    "        #\n",
    "        data_out = np.zeros((track.tracks_spine.shape[0],\n",
    "                             2,2,2))\n",
    "\n",
    "        #\n",
    "        data_out[:,:,:,0] = track.tracks_spine[:,animal_ids]\n",
    "\n",
    "        #\n",
    "        try:\n",
    "            for se in starts_ends:\n",
    "                data_out[int(se[0]):int(se[1]),:,:,1]=1\n",
    "        except:\n",
    "            print (\"single exmaple only\")\n",
    "            data_out[int(starts_ends[0]):int(starts_ends[1]),:,:,1]=1\n",
    "\n",
    "        #\n",
    "        np.save(fname_out, data_out)\n",
    "        \n",
    "        ####################################################\n",
    "        ############# MAKE ANIMAL ANGLES ###################\n",
    "        ####################################################\n",
    "        \n",
    "        track.smooth_angles = True\n",
    "        track.compute_angles_from_features(fname_out)\n",
    "        np.save(fname_out[:-4]+\"_angles.npy\",\n",
    "                track.angles)    \n",
    "        \n",
    "        #\n",
    "        print (\"\")\n",
    "        \n",
    "        \n",
    "#\n",
    "fname = '/home/cat/Downloads/approach/2020_07_28_17_11_05_340439_compressed_Day_0_1_cleaned.npy'\n",
    "\n",
    "#\n",
    "make_pairwise_npy_files_for_simba_single_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dedc797d-3677-4a89-a612-6d08a4b9c8cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "################# LOAD DATA FRAME AND ID PAIRS ###############\n",
    "##############################################################\n",
    "\n",
    "# these are the ids of the gerbils that Lisa and Jennifer decided to label\n",
    "# ids 0->5 correspond to female->pup4\n",
    "id_pairs = [\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [4,5],\n",
    "    [5,4],\n",
    "    [0,2],\n",
    "    [2,0],\n",
    "    [1,3],\n",
    "    [3,1]\n",
    "]\n",
    "\n",
    "fname = \"/mnt/b3a68699-495d-4ebb-9ab1-ac74f11c68c5/simba/approach.csv\"\n",
    "\n",
    "#\n",
    "dataframe = pd.read_csv(fname)\n",
    "header = dataframe.columns.tolist()\n",
    "\n",
    "#\n",
    "# dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d98503-3fe1-45f0-8373-d1c3c01365ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "################# CONVERT SPREADSHEET TO 2 COLUMN VERSION ###############\n",
    "#########################################################################\n",
    "final_arrays = parse_spreadsheet_return_unique_vids_and_starts_ends(header, dataframe)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39eb274c-11d1-4c82-bbed-778de76dada4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING: \n",
      "2020_08_03_19_13_00_372474\n",
      "[0 2]\n",
      "[[23842 23853]\n",
      " [ 5046  5073]]\n",
      "... npy missing, converting...\n",
      "... h5 file missing, converting now...\n",
      "... done loading slp\n",
      "\n",
      "Exporting to SLEAP Analysis file...\n",
      "\ttrack_names: 6\n",
      "\tnode_names: 6\n",
      "\tedge_names: 5\n",
      "\tedge_inds: 5\n",
      "\ttracks: (28802, 6, 2, 6)\n",
      "\ttrack_occupancy: (6, 28802)\n",
      "\tpoint_scores: (28802, 6, 6)\n",
      "\tinstance_scores: (28802, 6)\n",
      "\ttracking_scores: (28802, 6)\n",
      "\tlabels_path: None\n",
      "\tvideo_path: /vast/cm5635/cohort2/videos/2020_08_03_19_13_00_372474_compressed_defished_shrink_cropped.mp4\n",
      "\tvideo_ind: 0\n",
      "\tprovenance: {}\n",
      "Saved as /mnt/b3a68699-495d-4ebb-9ab1-ac74f11c68c5/simba/2020_08_03_19_13_00_372474_compressed_Day.h5\n",
      "... done loading h5\n",
      "group2:  <HDF5 dataset \"tracks\": shape (6, 2, 6, 28802), type \"<f8\">\n",
      "... done loading npy\n",
      "(28802, 2, 2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 28802/28802 [00:01<00:00, 14751.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROCESSING: \n",
      "2020_08_03_19_13_00_372474\n",
      "[1 3]\n",
      "[[ 7931  7944]\n",
      " [11571 11587]\n",
      " [16077 16090]]\n",
      "(28802, 2, 2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 28802/28802 [00:02<00:00, 13450.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROCESSING: \n",
      "2020_08_03_19_13_00_372474\n",
      "[2 0]\n",
      "[2407 2418]\n",
      "single exmaple only\n",
      "(28802, 2, 2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 28802/28802 [00:02<00:00, 13813.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROCESSING: \n",
      "2020_08_03_19_13_00_372474\n",
      "[5 4]\n",
      "[[  59   71]\n",
      " [5029 5039]]\n",
      "(28802, 2, 2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 28802/28802 [00:01<00:00, 15154.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################\n",
    "########## GENERATE .NPY FILES FROM .SLP FOR EACH UNIQUE VID-PAIR AND NUMPY ARRAYS ########\n",
    "###########################################################################################\n",
    "\n",
    "##############################################################\n",
    "root_dir = '/mnt/b3a68699-495d-4ebb-9ab1-ac74f11c68c5/simba'\n",
    "\n",
    "# break\n",
    "make_pairwise_npy_files_for_simba(final_arrays,\n",
    "                                     root_dir)  \n",
    "print (\"DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b626464-3746-4910-befb-fb49def724c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# frames, # animals, x-y, locations and behavior yes/no\n",
      "(28802, 2, 2, 2)\n",
      "frame:  20280 animal id:  0 : locations:  [544.71557617 563.74786377]\n",
      "frame:  20280 animal id:  0 : behavior state:  [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/mnt/b3a68699-495d-4ebb-9ab1-ac74f11c68c5/simba/2020_08_01_11_02_57_239373/2020_08_01_11_02_57_239373_animals_5_4.npy')\n",
    "\n",
    "print (\"# frames, # animals, x-y, locations and behavior yes/no\")\n",
    "print (data.shape)\n",
    "\n",
    "frame_id = 20280  #<--- example of on behavior\n",
    "animal_id = 0\n",
    "print (\"frame: \", frame_id, \"animal id: \", animal_id, \": locations: \", data[frame_id,animal_id,:,0])\n",
    "print (\"frame: \", frame_id, \"animal id: \", animal_id, \": behavior state: \", data[frame_id,animal_id,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768dd8ef-5bda-4a48-970f-f80ee9936826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2517d8-093e-4c49-8153-8575df45a3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleap_new",
   "language": "python",
   "name": "sleap_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
