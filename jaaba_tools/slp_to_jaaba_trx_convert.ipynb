{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# \n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "# \n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import trange\n",
    "import parmap\n",
    "import glob\n",
    "\n",
    "# \n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "\n",
    "# \n",
    "from Convert import Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#############################################\n",
    "#############################################\n",
    "\n",
    "\n",
    "\n",
    "def load_slp(self):\n",
    "\n",
    "    self.slp = sleap.load_file(fname_slp)\n",
    "\n",
    "def slp_to_h5(self):\n",
    "\n",
    "    fname_h5 = self.fname_slp[:-4] + \".h5\"\n",
    "    if self.slp is None:\n",
    "        #print(\"... slp file not loaded, loading now...\")\n",
    "        self.load_slp()\n",
    "        if self.verbose:\n",
    "            print(\"... done loading slp\")\n",
    "\n",
    "    self.slp.export(fname_h5)\n",
    "\n",
    "def slp_to_npy(self):\n",
    "\n",
    "    fname_h5 = self.fname_slp[:-4] + \".h5\"\n",
    "    if os.path.exists(fname_h5) == False:\n",
    "        if self.verbose:\n",
    "            print(\"... h5 file missing, converting now...\")\n",
    "        self.slp_to_h5()\n",
    "        if self.verbose:\n",
    "            print(\"... done loading h5\")\n",
    "\n",
    "    #\n",
    "    hf = h5py.File(fname_h5, 'r')\n",
    "\n",
    "    keys = hf.keys()\n",
    "    group2 = hf.get('tracks')\n",
    "    print (\"group2: \", group2)\n",
    "    tracks = []\n",
    "    for k in range(len(group2)):\n",
    "        tracks.append(group2[k])\n",
    "\n",
    "    tracks = np.array(tracks).transpose(3, 0, 2, 1)\n",
    "\n",
    "    #\n",
    "    fname_npy = self.fname_slp[:-4] + \".npy\"\n",
    "    np.save(fname_npy, tracks)\n",
    "\n",
    "    \n",
    "      \n",
    "    \n",
    "def run_trx_parallel(fname, root_dir):\n",
    "     #\n",
    "    #fname1 = root_dir + fname\n",
    "    fname1 = fname\n",
    "    print (fname1)\n",
    "    convert = Convert(fname1)\n",
    "\n",
    "    # \n",
    "    # convert.sexes = ['F','M','M','M']\n",
    "    convert.sexes = [0,1,1,1]\n",
    "    convert.fps = 25\n",
    "    convert.start = 0 #int(0*60*convert.fps)\n",
    "    convert.end = None #None #int(1*60*convert.fps)\n",
    "\n",
    "    # start = 0\n",
    "    # end = None\n",
    "    \n",
    "    convert.apply_median_filter = True\n",
    "    convert.dtype = 'double'\n",
    "    convert.animal_ids = np.arange(4)\n",
    "    convert.scale = 1\n",
    "    convert.make_movie = False\n",
    "    #convert.axes_scale = 4\n",
    "\n",
    "    # \n",
    "    convert.extension = '.avi'\n",
    "    convert.convert_npy_to_jaaba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28802/28802 [00:00<00:00, 169893.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/cat/1TB/dan/cohort2/2020_07_21_11_26_07_855478/2020_07_21_11_26_07_855478_compressed.npy\n",
      " full features track data:  (28802, 6, 6, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 28802/28802 [00:00<00:00, 177251.50it/s]\n",
      "100%|██████████| 28802/28802 [00:00<00:00, 182630.39it/s]\n",
      "100%|██████████| 28802/28802 [00:00<00:00, 190827.26it/s]\n",
      "100%|██████████| 28802/28802 [00:00<00:00, 184346.58it/s]\n",
      "100%|██████████| 28802/28802 [00:00<00:00, 182379.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# select training set data only\n",
    "root_dir = '/media/cat/256GB/dan/cohort1/cohort1_training_daytime_processed/'\n",
    "fnames = [\n",
    "'/2020-3-6_0day_5mins_compressedTalmo_fixed.npy',\n",
    "'/2020-3-7_daytime_0_300sec_compressedTalmo_fixed.npy',\n",
    "'/2020-3-8_0day_5mins_compressedTalmo_fixed.npy',\n",
    "'/2020-3-9_1day_5mins_compressedTalmo_fixed.npy',\n",
    "'/2020-3-10_daytime_5mins_compressedTalmo_fixed.npy',\n",
    "'/2020-3-11_day_5mins_compressedTalmo_fixed.npy',\n",
    "'/2020-3-12_day_5mins_compressedTalmo_fixed.npy',\n",
    "'/2020-3-13_day_5mins_compressedTalmo_fixed.npy',\n",
    "'/2020-3-14_day_5mins_compressedTalmo_fixed.npy',\n",
    "'/2020-3-15_day_5mins_compressedTalmo_fixed.npy',\n",
    "'/2020-3-16_day_5mins_compressedTalmo_fixed.npy',\n",
    "]\n",
    "\n",
    "fnames = np.loadtxt('/media/cat/1TB/dan/cohort1/slp.txt',\n",
    "                   dtype='str')    \n",
    "\n",
    "\n",
    "fnames = [\n",
    "    '/media/cat/1TB/dan/cohort2/2020_07_21_11_26_07_855478/2020_07_21_11_26_07_855478_compressed.npy'\n",
    "]\n",
    "    \n",
    "##########################################\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "if False:\n",
    "    parmap.map(run_trx_parallel,\n",
    "              fnames,root_dir,\n",
    "              pm_processes=4,\n",
    "              pm_pbar=True)\n",
    "else:\n",
    "    \n",
    "    for fname in fnames:\n",
    "        run_trx_parallel(fname,\n",
    "                        root_dir)\n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/cat/256GB/dan/cohort1/cohort1_training_daytime_processed/2020-3-12_day_5mins_compressedTalmo.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3bd092341080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/cat/256GB/dan/cohort1/cohort1_training_daytime_processed/2020-3-12_day_5mins_compressedTalmo.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md_fixed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/cat/256GB/dan/cohort1/cohort1_training_daytime_processed/2020-3-12_day_5mins_compressedTalmo_fixed.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/cat/4TBSSD/anaconda3/envs/gerbil/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/cat/256GB/dan/cohort1/cohort1_training_daytime_processed/2020-3-12_day_5mins_compressedTalmo.npy'"
     ]
    }
   ],
   "source": [
    "data = np.load('/media/cat/256GB/dan/cohort1/cohort1_training_daytime_processed/2020-3-12_day_5mins_compressedTalmo.npy')\n",
    "print (data.shape)\n",
    "\n",
    "d_fixed = np.load('/media/cat/256GB/dan/cohort1/cohort1_training_daytime_processed/2020-3-12_day_5mins_compressedTalmo_fixed.npy')\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-be46bc469ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#plt.xticks([])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "clrs = ['red','blue','cyan','green']\n",
    "\n",
    "frame = 3245\n",
    "\n",
    "fig = plt.figure()\n",
    "for p in range(20):\n",
    "    ax=plt.subplot(4,10,p+1)\n",
    "    for k in range(4):\n",
    "        plt.scatter(data[frame+p,k,:,0], data[frame+p,k,:,1],c=clrs[k])\n",
    "    plt.title(str(frame+p))\n",
    "    #plt.xticks([])\n",
    "    #plt.yticks([])\n",
    "    \n",
    "for p in range(20,40,1):\n",
    "    ax=plt.subplot(4,10,p+1)\n",
    "    for k in range(4):\n",
    "        plt.scatter(d_fixed[frame+p,k,:,0], data[frame+p,k,:,1],c=clrs[k])\n",
    "    plt.title(str(frame+p))\n",
    "    #plt.xticks([])\n",
    "    #plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/cat/4TBSSD/anaconda3/envs/gerbil/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in less\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove outliars\n",
    "def reject_outliers(data, m = 4.):  # number of deviations away\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    \n",
    "    print (mdev)\n",
    "    if mdev:\n",
    "        s = d/mdev \n",
    "    else:\n",
    "        s = 0.\n",
    "    \n",
    "    idx = np.where(s<m)[0]\n",
    "    return idx\n",
    "\n",
    "\n",
    "x = np.array([0,2,4,5,50, np.nan])\n",
    "\n",
    "reject_outliers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "19\n",
      "(array([[796.33959961, 799.7789917 , 799.82263184, ..., 784.55865479,\n",
      "        815.82635498, 812.80975342]]), array([[271.59109497, 271.86141968, 271.94561768, ..., 284.5559082 ,\n",
      "        277.05532837, 277.10379028]]), array([[-0.05180243, -0.19633077, -0.1984491 , ..., -0.65860766,\n",
      "        -0.506515  , -0.52507293]], dtype=float32), array([[103.545685, 103.53456 , 103.32587 , ..., 104.99651 ,  88.57386 ,\n",
      "         85.40443 ]], dtype=float32), array([[43.991497, 36.096703, 36.092815, ..., 79.368355, 18.490385,\n",
      "        18.395884]], dtype=float32), array([[7500]], dtype=uint16), array([[1]], dtype=uint8), array([[7500]], dtype=uint16), array([[0]]), array([[1]]), array([[398., 399., 399., ..., 392., 407., 406.]]), array([[135., 135., 135., ..., 142., 138., 138.]]), array([[-0.05180243, -0.19633077, -0.1984491 , ..., -0.65860766,\n",
      "        -0.506515  , -0.52507293]], dtype=float32), array([[51., 51., 51., ..., 52., 44., 42.]], dtype=float32), array([[21., 18., 18., ..., 39.,  9.,  9.]], dtype=float32), array([[0]]), array([[1, 1, 1, ..., 1, 1, 1]], dtype=uint8), array([[25]]), array([[0.00000000e+00, 4.62962963e-07, 9.25925926e-07, ...,\n",
      "        3.47083333e-03, 3.47129630e-03, 3.47175926e-03]]))\n",
      "(7500,)\n"
     ]
    }
   ],
   "source": [
    "fname = '/media/cat/4TBSSD/dan/cohort1/jaaba_test/movie1/trx.mat'\n",
    "\n",
    "data = loadmat(fname)\n",
    "print (len(data))\n",
    "print (len(data['trx'][0][0]))\n",
    "print (data['trx'][0][0])\n",
    "theta = data['trx'][0][2][2].squeeze()\n",
    "print (theta.shape)\n",
    "plt.plot(theta)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 15624.04it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 15434.59it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 16661.58it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 24303.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 4, 14, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from math import *\n",
    "PI = 3.1415926535\n",
    "\n",
    "def angle_trunc(a):\n",
    "    while a < 0.0:\n",
    "        a += pi * 2\n",
    "    return a\n",
    "\n",
    "def getAngleBetweenPoints(x_orig, y_orig, x_landmark, y_landmark):\n",
    "    deltaY = y_landmark - y_orig\n",
    "    deltaX = x_landmark - x_orig\n",
    "    return angle_trunc(atan2(deltaY, deltaX)) #* 180 / PI\n",
    "\n",
    "\n",
    "# \n",
    "tracks = np.load('/media/cat/4TBSSD/dan/cohort1/cohort1_training_daytime_processed/2020-3-6_0day_5mins_compressedTalmo_fixed.npy')\n",
    "print (tracks.shape)\n",
    "\n",
    "# \n",
    "start =0\n",
    "end = 1000\n",
    "\n",
    "# \n",
    "angles = np.zeros((end-start,\n",
    "                        tracks.shape[1]),\n",
    "                        'float32')+np.nan\n",
    "axes = np.zeros((end-start,\n",
    "                          tracks.shape[1],\n",
    "                          2),\n",
    "                            'float32')+np.nan\n",
    "intercepts = np.zeros((end-start,\n",
    "                        tracks.shape[1]),\n",
    "                        'float32')+np.nan\n",
    "\n",
    "#\n",
    "deg_scale = 180/3.1415926\n",
    "#deg_scale = 1\n",
    "        \n",
    "#      \n",
    "for a in range(tracks.shape[1]):\n",
    "    for k in tqdm(range(start, end,1)):\n",
    "        #x = self.tracks[k,a,:,0]\n",
    "        #y = self.tracks[k,a,:,1]\n",
    "        x = tracks[k,a,5:10,0]\n",
    "        y = tracks[k,a,5:10,1]\n",
    "        idx = np.where(np.isnan(x)==False)[0]\n",
    "        if idx.shape[0]>0:\n",
    "            x=x[idx]\n",
    "            y=y[idx]\n",
    "            \n",
    "            if x.shape[0]>=2:\n",
    "                angle = getAngleBetweenPoints(x[0], y[0], \n",
    "                                              x[-1], y[-1])\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            angles[k,a] = angle\n",
    "            #intercepts[k,a] = \n",
    "            # stack locations\n",
    "            locs = np.vstack((x,y)).T\n",
    "\n",
    "            # rotate\n",
    "            theta = np.radians(angle)\n",
    "            c, s = np.cos(theta), np.sin(theta)\n",
    "            R = np.array(((c, -s), (s, c)))\n",
    "            locs_r = locs@R\n",
    "\n",
    "            \n",
    "#             # Reject outliers that are substantially outside of data\n",
    "#             x = reject_outliers(locs_r[:,0])\n",
    "#             y = reject_outliers(locs_r[:,1])\n",
    "\n",
    "#             axes[k,a,0] = np.max(x)-np.min(x)\n",
    "#             axes[k,a,1] = np.max(y)-np.min(y)\n",
    "\n",
    "\n",
    "#             self.angles[k,a] = np.arctan(m)*deg_scale\n",
    "    while True:\n",
    "        idx = np.where(np.isnan(angles[:,a]))[0]\n",
    "        if idx.shape[0]==0:\n",
    "            break\n",
    "        angles[idx,a] = angles[idx-1,a]\n",
    "    \n",
    "    angles[:,a] = scipy.ndimage.median_filter(angles[:,a], size=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(angles[:,0]*180/pi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(np.arange(1000), 10)\n",
    "ctr=0\n",
    "import math\n",
    "for k in idx:\n",
    "    ax=plt.subplot(2,5,ctr+1)\n",
    "\n",
    "    for a in range(4):\n",
    "        x = tracks[k,a,5:10,0]\n",
    "        y = tracks[k,a,5:10,1]\n",
    "        idx = np.where(np.isnan(x)==False)[0]\n",
    "        if idx.shape[0]>0:\n",
    "            x=x[idx]\n",
    "            y=y[idx]\n",
    "            \n",
    "            #x = x-x[0]\n",
    "            \n",
    "            intercept = 0\n",
    "            #print (math.radians(angles[k,a])*x,angles[k,a]*x )\n",
    "            fit_eq = math.radians(angles[k,a])*x + y #-y[-1]\n",
    "            \n",
    "            \n",
    "            #Plotting the data\n",
    "            ax.plot(x, fit_eq, color = 'r', alpha = 0.5, label = 'Linear fit')\n",
    "\n",
    "            plt.scatter(x,y)\n",
    "    \n",
    "    ctr+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get length\n",
    "temp = data['allScores'][0][0][0][0][0].squeeze()\n",
    "length = temp.shape[0]\n",
    "\n",
    "# get starts/ends\n",
    "t0s = data['allScores'][0][0][5].squeeze()\n",
    "#print (t0s.shape)\n",
    "t1s = data['allScores'][0][0][6].squeeze()\n",
    "\n",
    "img = np.zeros((4,length),'float32')\n",
    "img1 = np.zeros((4,length),'float32')\n",
    "for k in trange(t0s.shape[0]):\n",
    "#for k in [0]:\n",
    "    starts = t0s[k].squeeze()\n",
    "    ends = t1s[k].squeeze()\n",
    "    #print (k,starts.shape)\n",
    "    for p in range(starts.shape[0]):\n",
    "        img[k,starts[p]:ends[p]]+=k+1\n",
    "        img1[k,starts[p]:ends[p]]+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 15.98it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 16.20it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 16.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 16.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 15.66it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 15.38it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 15.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 15.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 15.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "clrs = ['red','blue','green','cyan']\n",
    "\n",
    "dirs = np.sort(glob.glob('/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/trx_files/'+\n",
    "                \"*\"))\n",
    "\n",
    "imgs=[]\n",
    "imgs1 = []\n",
    "for dir_ in dirs:\n",
    "    fname_mat = '/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/trx_files/2020-3-16_01_54_23_358257_compressed.avi.predictions.analysis_traces_reassembled_centres/scores_run.mat'\n",
    "    data =loadmat(fname_mat)\n",
    "    \n",
    "    # get length\n",
    "    temp = data['allScores'][0][0][0][0][0].squeeze()\n",
    "    length = temp.shape[0]\n",
    "\n",
    "    # get starts/ends\n",
    "    t0s = data['allScores'][0][0][5].squeeze()\n",
    "    #print (t0s.shape)\n",
    "    t1s = data['allScores'][0][0][6].squeeze()\n",
    "    \n",
    "    img = np.zeros((4,length),'float32')\n",
    "    img1 = np.zeros((4,length),'float32')\n",
    "    for k in trange(t0s.shape[0]):\n",
    "    #for k in [0]:\n",
    "        starts = t0s[k].squeeze()\n",
    "        ends = t1s[k].squeeze()\n",
    "        #print (k,starts.shape)\n",
    "        for p in range(starts.shape[0]):\n",
    "            img[k,starts[p]:ends[p]]+=k+1\n",
    "            img1[k,starts[p]:ends[p]]+=1\n",
    "            \n",
    "    idx = np.where(img==0)\n",
    "    img[idx]=np.nan\n",
    "    imgs.append(img)\n",
    "    imgs1.append(img1)\n",
    "    \n",
    "imgs=np.hstack(imgs)\n",
    "imgs1=np.hstack(imgs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 899880)\n",
      "(899880,)\n"
     ]
    }
   ],
   "source": [
    "matplotlib.use('Agg')\n",
    "\n",
    "fig = plt.figure(figsize=(100,5))\n",
    "ax=plt.subplot(2,1,1)\n",
    "\n",
    "\n",
    "plt.xticks([])\n",
    "print (imgs.shape)\n",
    "names = ['female','male','pup1','pup2']\n",
    "clrs = ['red','blue','magenta','green']\n",
    "plt.yticks(np.arange(4),names)\n",
    "from matplotlib import colors\n",
    "cmap = colors.ListedColormap(clrs)\n",
    "\n",
    "plt.imshow(imgs,aspect='auto',interpolation='none',\n",
    "          cmap=cmap)\n",
    "\n",
    "ax=plt.subplot(2,1,2)\n",
    "sums = np.nansum(imgs1, axis= 0)\n",
    "print (sums.shape)\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    #y_smooth = np.convolve(y, box, mode='same')\n",
    "    y_smooth = np.convolve(y,np.ones(box_pts,dtype=int),'same')\n",
    "    \n",
    "    return y_smooth\n",
    "\n",
    "window = 60\n",
    "t = np.arange(imgs.shape[1])/25./window\n",
    "img2 = np.zeros((4,imgs.shape[1]))\n",
    "for k in range(4):\n",
    "    temp = imgs1[k]\n",
    "    temp = smooth(temp,25*window)    \n",
    "    #img2[k]=temp\n",
    "    #temp = smooth(temp,25)    \n",
    "    \n",
    "    plt.plot(t,temp,clrs[k])\n",
    "\n",
    "#plt.imshow(img2,aspect='auto',interpolation='none')#    cmap=cmap)    \n",
    "plt.xticks(np.arange(0,600,10))\n",
    "plt.xlim(t[0],t[-1])\n",
    "plt.xlabel(\"Time (minutes)\")\n",
    "plt.suptitle(\"Run behaviors for all animals (\"+str(window)+ \"sec smoothing window)\", fontsize=20)\n",
    "plt.savefig('/home/cat/fig.png')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89988,)\n"
     ]
    }
   ],
   "source": [
    "temp = data['allScores'][0][0][0][0][k].squeeze()\n",
    "print(temp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "t0s = data['allScores'][0][0][5].squeeze()\n",
    "print (t0s.shape)\n",
    "t1s = data['allScores'][0][0][6].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_mat = '/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_16/2020_3_15_11_53_51_617746_compressed/jaaba/trx_all_21300_21500.mat'\n",
    "data = loadmat(fname_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "(1, 200)\n",
      "44.0\n"
     ]
    }
   ],
   "source": [
    "print (data['trx'].shape)\n",
    "print (data['trx'][0][0][1].shape)\n",
    "\n",
    "data['trx'][0][0][1][0][0] = 44\n",
    "data['trx'][0][0][1][0] = np.array(data['trx'][0][0][1][0],dtype)\n",
    "\n",
    "print (data['trx'][0][0][1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "from numpy.core.records import fromarrays\n",
    "from scipy.io import savemat\n",
    "\n",
    "names = [\n",
    " 'x',\n",
    " 'y',\n",
    " 'theta',\n",
    " 'a',\n",
    " 'b',\n",
    " 'nframes',\n",
    " 'firstframe',\n",
    " 'endframe',\n",
    " 'off',\n",
    " 'id',\n",
    " 'x_mm',\n",
    " 'y_mm',\n",
    " 'theta_mm',\n",
    " 'a_mm',\n",
    " 'b_mm',\n",
    " 'sex',\n",
    " 'dt',\n",
    " 'fps',\n",
    " 'timestamps']\n",
    "\n",
    "data = [\n",
    " x,\n",
    " y,\n",
    " theta,\n",
    " a,\n",
    " b,\n",
    " nframes,\n",
    " firstframe,\n",
    " endframe,\n",
    " off,\n",
    " id_,\n",
    " x_mm,\n",
    " y_mm,\n",
    " theta_mm,\n",
    " a_mm,\n",
    " b_mm,\n",
    " sex,\n",
    " dt,\n",
    " fps,\n",
    " timestamps\n",
    "]\n",
    "\n",
    "\n",
    "            \n",
    "#myrec = fromarrays([[1, 10], [2, 20]], names=['field1', 'field2'])\n",
    "#savemat('p.mat', {'myrec': myrec})\n",
    "\n",
    "myrec = fromarrays(data, \n",
    "                   names=names)\n",
    "#savemat('p.mat', {'myrec': myrec})\n",
    "\n",
    "\n",
    "savemat(\"/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_16/2020_3_15_11_53_51_617746_compressed/jaaba/trx.mat\", \n",
    "        {'myrec':myrec})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 89988, 2)\n",
      "(4, 89985, 2)\n",
      "(4, 89987, 2)\n",
      "(4, 89988, 2)\n",
      "(4, 89987, 2)\n",
      "(4, 89987, 2)\n",
      "(4, 89988, 2)\n",
      "(4, 89989, 2)\n",
      "(4, 89976, 2)\n",
      "(4, 89988, 2)\n"
     ]
    }
   ],
   "source": [
    "fnames = glob.glob('/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_16/post_processing/*.npy')\n",
    "\n",
    "for fname in fnames:\n",
    "    data = np.load(fname)\n",
    "    \n",
    "    data2 = []\n",
    "    for f in range(0,56,14):\n",
    "        temp = data[:,f:f+14]\n",
    "        temp = np.nanmedian(temp,axis=1)\n",
    "        data2.append(temp)\n",
    "        \n",
    "    data2=np.array(data2)\n",
    "    np.save(fname[:-4]+'_centres.npy',data2)\n",
    "    print (data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        PC1       PC2       PC2       PC3\n",
      "sepal length (cm)  0.521066  0.377418 -0.719566 -0.261286\n",
      "sepal width (cm)  -0.269347  0.923296  0.244382  0.123510\n",
      "petal length (cm)  0.580413  0.024492  0.142126  0.801449\n",
      "petal width (cm)   0.564857  0.066942  0.634273 -0.523597\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# load iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = scale(iris.data)\n",
    "y = iris.target\n",
    "\n",
    "# apply PCA\n",
    "pca = decomposition.PCA(n_components=4)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "loadings = pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2', \"PC2\", \"PC3\"], index=iris.feature_names)\n",
    "print (loadings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89989, 4, 14, 2)\n"
     ]
    }
   ],
   "source": [
    "d1 = np.load('/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_16/2020_3_16_08_59_17_534732_compressed/2020_3_16_08_59_17_534732_compressed_fixed.npy')\n",
    "print (d1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:06<00:00, 1578.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# angles = np.zeros((track.tracks.shape[0], \n",
    "#                    track.tracks.shape[1], \n",
    "#                    'float32'))\n",
    "\n",
    "angles = np.zeros((d1.shape[0], \n",
    "                   d1.shape[1]), \n",
    "                   'float32')\n",
    "\n",
    "deg_scale = 180/3.1415926\n",
    "\n",
    "for k in trange(10000):\n",
    "    for a in range(d1.shape[1]):\n",
    "        x = d1[k,a,:,0]\n",
    "        y = d1[k,a,:,1]\n",
    "        idx = np.where(np.isnan(x)==False)[0]\n",
    "        if idx.shape[0]>0:\n",
    "            x=x[idx]\n",
    "            y=y[idx]\n",
    "            m,b = np.polyfit(x, y, 1)\n",
    "            #print (\"slope :\", m, \"  intercept: \", b)\n",
    "            angle = np.arctan(m)*deg_scale\n",
    "            angles[k,a] = angle\n",
    "            #print (\"agnel: \", angle)      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle:  155.36937322044065\n",
      "angle:  156.3964094037172\n",
      "angle:  158.820461411969\n",
      "angle:  162.98178696290174\n",
      "angle:  163.0214896740499\n",
      "angle:  163.20703257794614\n",
      "angle:  163.1095933974912\n",
      "angle:  164.4740648932155\n",
      "angle:  165.45458477460073\n",
      "angle:  169.03968922275195\n"
     ]
    }
   ],
   "source": [
    "# remove outliars\n",
    "def reject_outliers(data, m = 20):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d/mdev if mdev else 0.\n",
    "    idx = np.where(s<m)[0]\n",
    "    \n",
    "    return idx\n",
    "    #return data[s<m]\n",
    "        \n",
    "deg_scale = 180/3.1415926\n",
    "\n",
    "k_start= 1060\n",
    "a = 0\n",
    "ctr=1\n",
    "for k in range(k_start,k_start+10,1):\n",
    "    #ax = plt.gca()\n",
    "    ax =plt.subplot(2,5,ctr)\n",
    "    x = d1[k,a,5:10,0]\n",
    "    y = d1[k,a,5:10,1]\n",
    "    idx = np.where(np.isnan(x)==False)[0]\n",
    "    if idx.shape[0]>0:\n",
    "        x=x[idx]\n",
    "        y=y[idx]\n",
    "        m,b = np.polyfit(y, x, 1)\n",
    "        angle = np.arctan(m)*deg_scale #+90\n",
    "        if x[0]<x[-1]:\n",
    "            angle+=180\n",
    "        print (\"angle: \", angle) \n",
    "        \n",
    "    plt.title(str(round(angle,1))+\" \"+str(k))\n",
    "\n",
    "    locs = np.vstack((x,y)).T\n",
    "    plt.scatter(locs[:,0],\n",
    "                locs[:,1],\n",
    "                c='blue',\n",
    "                label='original')\n",
    "    y_vals = np.array(ax.get_ylim())\n",
    "    x_vals = b + m * y_vals\n",
    "    plt.plot(x_vals, y_vals, '--')\n",
    "    plt.xlim(0,1280)\n",
    "    plt.ylim(1024,0)\n",
    "\n",
    "    # rotate the thang\n",
    "    if False:\n",
    "        theta = np.radians(angle)\n",
    "        c, s = np.cos(theta), np.sin(theta)\n",
    "        R = np.array(((c, -s), (s, c)))\n",
    "        print (locs.shape)\n",
    "        #locs = R*locs.T\n",
    "        locs = locs@R\n",
    "\n",
    "\n",
    "\n",
    "        # Reject outliers that are substantially outside of data\n",
    "        x = reject_outliers(locs[:,0])\n",
    "        y = reject_outliers(locs[:,1])\n",
    "\n",
    "        major = np.max(x)-np.min(x)\n",
    "        minor = np.max(y)-np.min(y)\n",
    "        print (\"major: \", major, \"  minor: \", minor)\n",
    "\n",
    "        # \n",
    "        plt.scatter(locs[:,0], \n",
    "                    locs[:,1],\n",
    "                    c='red',\n",
    "                   label='rotated')\n",
    "    \n",
    "    ctr+=1\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['node_names', 'track_names', 'track_occupancy', 'tracks']>\n",
      "[b'nose', b'lefteye', b'righteye', b'leftear', b'rightear', b'spine1', b'spine2', b'spine3', b'spine4', b'spine5', b'tail1', b'tail2', b'tail3', b'tail4']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "filename = \"/media/cat/256GB/dan/cohort1/processed_h5/daytime/2020_3_2_10_40_52_836778_compressed.h5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[a_group_key])\n",
    "    \n",
    "    print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
